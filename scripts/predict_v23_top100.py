#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
v2.3.0æ¨¡å‹é¢„æµ‹è„šæœ¬

é¢„æµ‹æŒ‡å®šæ—¥æœŸæ”¶ç›˜åçš„è‚¡ç¥¨è¯„åˆ†ï¼Œè¾“å‡ºTop100
ç‰¹å¾å¤„ç†é€»è¾‘ä¸è®­ç»ƒ/è¯„ä¼°å®Œå…¨ä¸€è‡´
"""

import sys
import json
import warnings
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

import pandas as pd
import numpy as np
import xgboost as xgb
import joblib

PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

warnings.filterwarnings('ignore')

from src.utils.logger import log
from src.data.data_manager import DataManager


def load_model():
    """åŠ è½½v2.3.0æ¨¡å‹"""
    model_dir = PROJECT_ROOT / 'data' / 'models' / 'breakout_launch_scorer' / 'versions' / 'v2.3.0' / 'model'
    
    booster = xgb.Booster()
    booster.load_model(str(model_dir / 'model.json'))
    
    with open(model_dir / 'feature_names.json', 'r') as f:
        feature_names = json.load(f)
    
    calibrator = joblib.load(str(model_dir / 'calibrator.pkl'))
    
    return booster, feature_names, calibrator


def extract_features(df):
    """
    æå–ç‰¹å¾ï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼‰
    
    è¾“å…¥: å•åªè‚¡ç¥¨çš„æ—¥çº¿æ•°æ®DataFrame
    è¾“å‡º: åŒ…å«æ‰€æœ‰ç‰¹å¾çš„æœ€åä¸€è¡Œ
    """
    df = df.copy()
    
    # ========== åŸºç¡€å‡çº¿ ==========
    df['ma5'] = df['close'].rolling(5).mean()
    df['ma10'] = df['close'].rolling(10).mean()
    df['ma_20d'] = df['close'].rolling(20).mean()
    
    # ========== MACD ==========
    df['ema12'] = df['close'].ewm(span=12, adjust=False).mean()
    df['ema26'] = df['close'].ewm(span=26, adjust=False).mean()
    df['macd_dif'] = df['ema12'] - df['ema26']
    df['macd_dea'] = df['macd_dif'].ewm(span=9, adjust=False).mean()
    df['macd'] = 2 * (df['macd_dif'] - df['macd_dea'])
    
    # ========== RSI ==========
    delta = df['close'].diff()
    gain = delta.where(delta > 0, 0).rolling(6).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(6).mean()
    df['rsi_6'] = 100 - (100 / (1 + gain / (loss + 1e-10)))
    
    gain12 = delta.where(delta > 0, 0).rolling(12).mean()
    loss12 = (-delta.where(delta < 0, 0)).rolling(12).mean()
    df['rsi_12'] = 100 - (100 / (1 + gain12 / (loss12 + 1e-10)))
    
    gain24 = delta.where(delta > 0, 0).rolling(24).mean()
    loss24 = (-delta.where(delta < 0, 0)).rolling(24).mean()
    df['rsi_24'] = 100 - (100 / (1 + gain24 / (loss24 + 1e-10)))
    
    # ========== KDJ ==========
    low_9 = df['low'].rolling(9).min()
    high_9 = df['high'].rolling(9).max()
    rsv = (df['close'] - low_9) / (high_9 - low_9 + 1e-10) * 100
    df['kdj_k'] = rsv.ewm(com=2, adjust=False).mean()
    df['kdj_d'] = df['kdj_k'].ewm(com=2, adjust=False).mean()
    df['kdj_j'] = 3 * df['kdj_k'] - 2 * df['kdj_d']
    
    # ========== é‡æ¯” ==========
    df['volume_ratio'] = df['vol'] / (df['vol'].rolling(5).mean() + 1e-8)
    
    # ========== å¤šå‘¨æœŸç‰¹å¾ ==========
    for period in [8, 34, 55]:
        df[f'return_{period}d'] = df['close'].pct_change(period) * 100
        df[f'ma_{period}d'] = df['close'].rolling(period).mean()
        df[f'price_vs_ma_{period}d'] = (df['close'] - df[f'ma_{period}d']) / df[f'ma_{period}d'] * 100
        df[f'volatility_{period}d'] = df['pct_chg'].rolling(period).std()
        df[f'high_{period}d'] = df['high'].rolling(period).max()
        df[f'low_{period}d'] = df['low'].rolling(period).min()
        price_range = df[f'high_{period}d'] - df[f'low_{period}d']
        df[f'price_position_{period}d'] = (df['close'] - df[f'low_{period}d']) / (price_range + 1e-10)
        df[f'trend_slope_{period}d'] = df['close'].rolling(period).apply(
            lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) == period else 0, raw=False
        )
    
    # ========== åŠ¨é‡ ==========
    df['momentum_5d'] = df['close'].pct_change(5) * 100
    df['momentum_10d'] = df['close'].pct_change(10) * 100
    df['momentum_20d'] = df['close'].pct_change(20) * 100
    df['momentum_acceleration'] = df['momentum_5d'] - df['momentum_5d'].shift(5)
    
    # ========== ä»·é‡å…³ç³» ==========
    df['price_change'] = df['close'].diff()
    df['volume_change'] = df['vol'].diff()
    df['volume_price_corr_10d'] = df['close'].rolling(10).corr(df['vol'])
    df['volume_price_corr_20d'] = df['close'].rolling(20).corr(df['vol'])
    df['volume_price_match'] = ((df['price_change'] > 0) & (df['volume_change'] > 0)).astype(int)
    df['volume_price_match_sum_10d'] = df['volume_price_match'].rolling(10).sum()
    
    # ========== çªç ´ç‰¹å¾ ==========
    for period in [10, 20, 55]:
        df[f'prev_high_{period}d'] = df['high'].rolling(period).max().shift(1)
        df[f'breakout_high_{period}d'] = (df['close'] > df[f'prev_high_{period}d']).astype(int)
        df[f'resistance_{period}d'] = df['high'].rolling(period).max()
        df[f'support_{period}d'] = df['low'].rolling(period).min()
        df[f'dist_to_resistance_{period}d'] = (df[f'resistance_{period}d'] - df['close']) / df['close'] * 100
        df[f'dist_to_support_{period}d'] = (df['close'] - df[f'support_{period}d']) / df['close'] * 100
        df[f'support_strength_{period}d'] = (df['low'] - df[f'support_{period}d']).abs().rolling(period).mean()
        df[f'resistance_strength_{period}d'] = (df[f'resistance_{period}d'] - df['high']).abs().rolling(period).mean()
    
    df['channel_width_20d'] = (df['resistance_20d'] - df['support_20d']) / df['close'] * 100
    
    # ========== MAçªç ´ ==========
    df['ma_5d'] = df['close'].rolling(5).mean()
    df['breakout_ma5'] = (df['close'] > df['ma_5d']).astype(int)
    df['ma_10d'] = df['close'].rolling(10).mean()
    df['breakout_ma10'] = (df['close'] > df['ma_10d']).astype(int)
    df['breakout_ma20'] = (df['close'] > df['ma_20d']).astype(int)
    ma_55d = df['close'].rolling(55).mean()
    df['breakout_ma55'] = (df['close'] > ma_55d).astype(int)
    
    df['breakout_volume_ratio'] = df['vol'] / (df['vol'].rolling(20).mean() + 1e-8)
    df['high_volume_breakout'] = ((df['breakout_high_20d'] == 1) & (df['breakout_volume_ratio'] > 1.5)).astype(int)
    df['consecutive_new_high'] = df['breakout_high_10d'].rolling(5).sum()
    
    # ========== æˆäº¤é‡è¶‹åŠ¿ ==========
    df['volume_trend_slope_10d'] = df['vol'].rolling(10).apply(
        lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) == 10 else 0, raw=False
    )
    df['volume_trend_slope_20d'] = df['vol'].rolling(20).apply(
        lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) == 20 else 0, raw=False
    )
    df['volume_breakout_count_20d'] = (df['vol'] > df['vol'].rolling(20).mean() * 1.5).rolling(20).sum()
    
    # ========== é‡ä»·èƒŒç¦» ==========
    df['price_up_vol_down'] = ((df['price_change'] > 0) & (df['volume_change'] < 0)).astype(int)
    df['price_up_vol_down_count_10d'] = df['price_up_vol_down'].rolling(10).sum()
    df['price_down_vol_up'] = ((df['price_change'] < 0) & (df['volume_change'] > 0)).astype(int)
    df['price_down_vol_up_count_10d'] = df['price_down_vol_up'].rolling(10).sum()
    
    # ========== OBV ==========
    df['obv'] = (np.sign(df['close'].diff()) * df['vol']).fillna(0).cumsum()
    df['obv_calc'] = df['obv']
    df['obv_ma10'] = df['obv'].rolling(10).mean()
    df['obv_trend'] = (df['obv'] > df['obv_ma10']).astype(int)
    
    # ========== æˆäº¤é‡RSV ==========
    vol_low_20 = df['vol'].rolling(20).min()
    vol_high_20 = df['vol'].rolling(20).max()
    df['volume_rsv_20d'] = (df['vol'] - vol_low_20) / (vol_high_20 - vol_low_20 + 1e-10) * 100
    
    # ========== ä¹–ç¦»ç‡ ==========
    df['bias_short'] = (df['close'] - df['ma5']) / df['ma5'] * 100
    df['bias_mid'] = (df['close'] - df['ma10']) / df['ma10'] * 100
    df['bias_long'] = (df['close'] - df['ma_20d']) / df['ma_20d'] * 100
    
    # ========== EMA ==========
    df['ema_5'] = df['close'].ewm(span=5, adjust=False).mean()
    df['ema_10'] = df['close'].ewm(span=10, adjust=False).mean()
    df['ema_20'] = df['close'].ewm(span=20, adjust=False).mean()
    df['ema_60'] = df['close'].ewm(span=60, adjust=False).mean()
    
    # ========== é‡æ¯” ==========
    df['vol_ma5_ratio'] = df['vol'] / (df['vol'].rolling(5).mean() + 1e-8)
    df['vol_ma20_ratio'] = df['vol'] / (df['vol'].rolling(20).mean() + 1e-8)
    
    # ========== æ¶¨åœ ==========
    df['is_limit_up'] = (df['pct_chg'] >= 9.8).astype(int)
    
    # ========== å†å²ä½ç½® ==========
    df['price_vs_hist_mean'] = (df['close'] - df['close'].rolling(34).mean()) / df['close'].rolling(34).mean() * 100
    df['price_vs_hist_high'] = (df['close'] - df['close'].rolling(34).max()) / df['close'].rolling(34).max() * 100
    df['volatility_vs_hist'] = df['pct_chg'].rolling(10).std() / (df['pct_chg'].rolling(34).std() + 1e-8)
    
    # ========== å¸‚åœºç›¸å…³ï¼ˆå ä½ï¼‰ ==========
    df['market_pct_chg'] = 0
    df['market_return_34d'] = 0
    df['market_volatility_34d'] = 0
    df['market_trend'] = 0
    df['excess_return'] = df['pct_chg']
    df['excess_return_cumsum'] = df['pct_chg'].rolling(34).sum()
    
    # ========== é£é™©ç‰¹å¾ ==========
    # æœ€å¤§å›æ’¤
    for period in [10, 20, 55]:
        rolling_max = df['close'].rolling(period, min_periods=1).max()
        drawdown = (df['close'] - rolling_max) / rolling_max * 100
        df[f'max_drawdown_{period}d'] = drawdown.rolling(period, min_periods=1).min()
    
    # ATR
    prev_close = df['close'].shift(1)
    tr1 = df['high'] - df['low']
    tr2 = abs(df['high'] - prev_close)
    tr3 = abs(df['low'] - prev_close)
    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    
    df['atr_14'] = true_range.rolling(14, min_periods=1).mean()
    df['atr_ratio_14'] = df['atr_14'] / df['close'] * 100
    atr_mean = df['atr_14'].rolling(55, min_periods=14).mean()
    df['atr_expansion'] = df['atr_14'] / (atr_mean + 1e-10)
    
    # è·é«˜ç‚¹å¤©æ•°
    for period in [20, 55]:
        rolling_high = df['close'].rolling(period, min_periods=1).max()
        is_at_high = (df['close'] == rolling_high)
        days_list = []
        days_since_high = 0
        for is_high in is_at_high:
            if is_high:
                days_since_high = 0
            else:
                days_since_high += 1
            days_list.append(days_since_high)
        df[f'days_from_high_{period}d'] = days_list
    
    # æ¢å¤æ¯”ä¾‹
    rolling_low_20 = df['close'].rolling(20, min_periods=1).min()
    rolling_high_20 = df['close'].rolling(20, min_periods=1).max()
    price_range = rolling_high_20 - rolling_low_20
    df['recovery_ratio_20d'] = (df['close'] - rolling_low_20) / (price_range + 1e-10)
    
    return df


def calculate_risk_score(row):
    """è®¡ç®—é£é™©ç³»æ•°"""
    risk_score = 1.0
    reasons = []
    
    # 34æ—¥æ¶¨å¹…
    ret = row.get('return_34d', 0)
    if pd.notna(ret):
        if ret > 80:
            risk_score *= 0.3
            reasons.append(f'æ¶¨å¹…{ret:.0f}%')
        elif ret > 60:
            risk_score *= 0.5
            reasons.append(f'æ¶¨å¹…{ret:.0f}%')
        elif ret > 40:
            risk_score *= 0.7
            reasons.append(f'æ¶¨å¹…{ret:.0f}%')
    
    # æœ€å¤§å›æ’¤
    dd = row.get('max_drawdown_20d', 0)
    if pd.notna(dd) and dd < -30:
        risk_score *= 0.7
        reasons.append(f'å›æ’¤{dd:.0f}%')
    
    # ATR
    atr = row.get('atr_ratio_14', 0)
    if pd.notna(atr) and atr > 10:
        risk_score *= 0.7
        reasons.append(f'ATR{atr:.1f}%')
    
    return risk_score, '; '.join(reasons) if reasons else ''


def process_single_stock(dm, ts_code, name, predict_date, feature_names, booster, calibrator):
    """å¤„ç†å•åªè‚¡ç¥¨"""
    try:
        end_date = predict_date
        start_date = (datetime.strptime(predict_date, '%Y%m%d') - timedelta(days=200)).strftime('%Y%m%d')
        
        df = dm.get_daily_data(ts_code, start_date, end_date)
        if df is None or len(df) < 60:
            return None
        
        df = df.sort_values('trade_date').reset_index(drop=True)
        
        # æå–ç‰¹å¾
        df = extract_features(df)
        last_row = df.iloc[-1]
        
        # æ„å»ºç‰¹å¾å‘é‡
        feature_vector = []
        for fn in feature_names:
            val = last_row.get(fn, 0)
            if pd.isna(val):
                val = 0
            feature_vector.append(float(val))
        
        # é¢„æµ‹
        dmatrix = xgb.DMatrix([feature_vector], feature_names=feature_names)
        raw_prob = float(booster.predict(dmatrix)[0])
        cal_prob = float(calibrator.predict([raw_prob])[0])
        
        # é£é™©è¯„åˆ†
        risk_score, risk_reasons = calculate_risk_score(last_row)
        
        return {
            'ts_code': ts_code,
            'name': name,
            'close': last_row['close'],
            'pct_chg': last_row.get('pct_chg', 0),
            'raw_probability': raw_prob,
            'calibrated_probability': cal_prob,
            'risk_score': risk_score,
            'final_score': cal_prob * risk_score,
            'return_34d': last_row.get('return_34d', 0),
            'rsi_6': last_row.get('rsi_6', 0),
            'max_drawdown_20d': last_row.get('max_drawdown_20d', 0),
            'atr_ratio_14': last_row.get('atr_ratio_14', 0),
            'risk_reasons': risk_reasons
        }
    except Exception as e:
        return None


def main():
    parser = argparse.ArgumentParser(description='v2.3.0æ¨¡å‹é¢„æµ‹')
    parser.add_argument('--date', type=str, default='20251231', help='é¢„æµ‹æ—¥æœŸ (YYYYMMDD)')
    parser.add_argument('--top-n', type=int, default=100, help='è¾“å‡ºTop Nè‚¡ç¥¨æ•°é‡')
    args = parser.parse_args()
    
    predict_date = args.date
    top_n = args.top_n
    
    log.info("="*80)
    log.info(f"v2.3.0æ¨¡å‹é¢„æµ‹ - {predict_date}")
    log.info("="*80)
    
    # åˆå§‹åŒ–
    dm = DataManager()
    
    # åŠ è½½æ¨¡å‹
    log.info("\nğŸ“¦ åŠ è½½v2.3.0æ¨¡å‹...")
    booster, feature_names, calibrator = load_model()
    log.success(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ: {len(feature_names)} ç‰¹å¾")
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    stock_list = dm.get_stock_list()
    valid = stock_list[
        ~stock_list['name'].str.contains('ST|é€€', na=False) &
        ~stock_list['ts_code'].str.startswith('688') &
        ~stock_list['ts_code'].str.startswith('8')
    ].copy()
    log.info(f"ğŸ“Š æœ‰æ•ˆè‚¡ç¥¨: {len(valid)} åª")
    
    # æ‰¹é‡é¢„æµ‹
    log.info("\nğŸ”„ å¼€å§‹é¢„æµ‹...")
    results = []
    total = len(valid)
    processed = 0
    success = 0
    
    start_time = datetime.now()
    
    for idx, (_, row) in enumerate(valid.iterrows()):
        ts_code = row['ts_code']
        name = row['name']
        
        result = process_single_stock(dm, ts_code, name, predict_date, feature_names, booster, calibrator)
        
        processed += 1
        if result is not None:
            results.append(result)
            success += 1
        
        # è¿›åº¦æ˜¾ç¤º
        if processed % 200 == 0 or processed == total:
            elapsed = (datetime.now() - start_time).total_seconds()
            speed = processed / elapsed if elapsed > 0 else 0
            eta = (total - processed) / speed / 60 if speed > 0 else 0
            log.info(f"ğŸ“ˆ è¿›åº¦: {processed}/{total} ({processed/total*100:.1f}%) | æˆåŠŸ: {success} | é€Ÿåº¦: {speed:.1f}åª/ç§’ | é¢„è®¡å‰©ä½™: {eta:.1f}åˆ†é’Ÿ")
    
    log.success(f"\nâœ“ é¢„æµ‹å®Œæˆ: {success}/{total} åªè‚¡ç¥¨")
    
    # åˆ›å»ºDataFrameå¹¶æ’åº
    df_pred = pd.DataFrame(results)
    df_pred = df_pred.sort_values('final_score', ascending=False)
    
    # è¾“å‡ºTop N
    df_top = df_pred.head(top_n)
    
    log.info("\n" + "="*80)
    log.info(f"ğŸ“‹ Top {top_n} è‚¡ç¥¨é¢„æµ‹ç»“æœ")
    log.info("="*80)
    
    # ç»Ÿè®¡ä¿¡æ¯
    log.info(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    log.info(f"  æ ¡å‡†æ¦‚ç‡ - æœ€é«˜: {df_top['calibrated_probability'].max():.4f}, å¹³å‡: {df_top['calibrated_probability'].mean():.4f}")
    log.info(f"  é£é™©è¯„åˆ† - æœ€é«˜: {df_top['risk_score'].max():.2f}, å¹³å‡: {df_top['risk_score'].mean():.2f}")
    log.info(f"  æœ€ç»ˆå¾—åˆ† - æœ€é«˜: {df_top['final_score'].max():.4f}, å¹³å‡: {df_top['final_score'].mean():.4f}")
    
    # æŒ‰æ¦‚ç‡åˆ†å±‚ç»Ÿè®¡
    log.info(f"\nğŸ“ˆ Top {top_n} æ¦‚ç‡åˆ†å¸ƒ:")
    prob_bins = [(0.9, 1.0), (0.8, 0.9), (0.7, 0.8), (0.6, 0.7), (0.5, 0.6), (0.0, 0.5)]
    for low, high in prob_bins:
        count = ((df_top['calibrated_probability'] >= low) & (df_top['calibrated_probability'] < high)).sum()
        if count > 0:
            log.info(f"  æ¦‚ç‡[{low:.1f}, {high:.1f}): {count} åª")
    
    # æ˜¾ç¤ºTop 20
    log.info(f"\nğŸ† Top 20 è‚¡ç¥¨:")
    log.info("-" * 100)
    log.info(f"{'æ’å':>4} | {'ä»£ç ':>10} | {'åç§°':>8} | {'æ”¶ç›˜ä»·':>8} | {'æ ¡å‡†æ¦‚ç‡':>8} | {'é£é™©è¯„åˆ†':>8} | {'æœ€ç»ˆå¾—åˆ†':>8} | {'34æ—¥æ¶¨å¹…':>8}")
    log.info("-" * 100)
    
    for i, (_, row) in enumerate(df_top.head(20).iterrows()):
        log.info(f"{i+1:>4} | {row['ts_code']:>10} | {row['name']:>8} | {row['close']:>8.2f} | {row['calibrated_probability']:>8.4f} | {row['risk_score']:>8.2f} | {row['final_score']:>8.4f} | {row['return_34d']:>7.1f}%")
    
    # ä¿å­˜ç»“æœ
    output_dir = PROJECT_ROOT / 'data' / 'prediction' / 'results'
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜Top N
    output_file = output_dir / f'v2.3.0_top{top_n}_{predict_date}.csv'
    df_top.to_csv(output_file, index=False, encoding='utf-8-sig')
    log.success(f"\nğŸ’¾ Top {top_n} å·²ä¿å­˜: {output_file}")
    
    # ä¿å­˜å…¨é‡é¢„æµ‹ç»“æœ
    full_file = output_dir / f'v2.3.0_full_predictions_{predict_date}.csv'
    df_pred.to_csv(full_file, index=False, encoding='utf-8-sig')
    log.success(f"ğŸ’¾ å…¨é‡é¢„æµ‹å·²ä¿å­˜: {full_file}")
    
    log.info("\n" + "="*80)
    log.info("âœ… é¢„æµ‹ä»»åŠ¡å®Œæˆ!")
    log.info("="*80)


if __name__ == '__main__':
    main()

