#!/usr/bin/env python3
"""
å·¦ä¾§æ½œåŠ›ç‰›è‚¡æ¨¡å‹ - æ¨¡å‹éªŒè¯è„šæœ¬

å¯¹è®­ç»ƒå¥½çš„å·¦ä¾§æ¨¡å‹è¿›è¡Œå„ç§éªŒè¯æµ‹è¯•

ä½¿ç”¨æ–¹æ³•:
python scripts/validate_left_breakout_model.py

å¯é€‰å‚æ•°:
--walk-forward    æ‰§è¡ŒWalk-Forwardæ»šåŠ¨éªŒè¯
--robustness      æ‰§è¡Œé²æ£’æ€§æµ‹è¯•
--time-series-cv  æ‰§è¡Œæ—¶é—´åºåˆ—äº¤å‰éªŒè¯
--all            æ‰§è¡Œæ‰€æœ‰éªŒè¯ï¼ˆé»˜è®¤ï¼‰
--config-file     æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„
"""

import sys
import os
import argparse
import pandas as pd
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data.data_manager import DataManager
from src.models.stock_selection.left_breakout import LeftBreakoutModel
from src.models.stock_selection.left_breakout.left_validation import LeftBreakoutValidator
from config.config import load_config
from src.utils.logger import log


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å·¦ä¾§æ½œåŠ›ç‰›è‚¡æ¨¡å‹éªŒè¯')
    parser.add_argument('--walk-forward', action='store_true',
                       help='æ‰§è¡ŒWalk-Forwardæ»šåŠ¨éªŒè¯')
    parser.add_argument('--robustness', action='store_true',
                       help='æ‰§è¡Œé²æ£’æ€§æµ‹è¯•')
    parser.add_argument('--time-series-cv', action='store_true',
                       help='æ‰§è¡Œæ—¶é—´åºåˆ—äº¤å‰éªŒè¯')
    parser.add_argument('--all', action='store_true',
                       help='æ‰§è¡Œæ‰€æœ‰éªŒè¯ï¼ˆé»˜è®¤ï¼‰')
    parser.add_argument('--config-file', type=str, default='config/settings.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # å¦‚æœæ²¡æœ‰æŒ‡å®šå…·ä½“éªŒè¯ï¼Œé»˜è®¤æ‰§è¡Œæ‰€æœ‰éªŒè¯
    if not any([args.walk_forward, args.robustness, args.time_series_cv]):
        args.all = True

    try:
        log.info("="*60)
        log.info("ğŸ”¬ å·¦ä¾§æ½œåŠ›ç‰›è‚¡æ¨¡å‹ - æ¨¡å‹éªŒè¯")
        log.info("="*60)

        # 1. åŠ è½½é…ç½®
        log.info("ğŸ“‹ åŠ è½½é…ç½®...")
        config = load_config(args.config_file)

        # æ£€æŸ¥å·¦ä¾§æ¨¡å‹æ˜¯å¦å¯ç”¨
        if not config.get('left_breakout', {}).get('model', {}).get('enabled', True):
            log.warning("âš ï¸  å·¦ä¾§æ¨¡å‹æœªå¯ç”¨ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® left_breakout.model.enabled = true")
            return

        # 2. åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        log.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨...")
        dm = DataManager(config)

        # 3. åˆå§‹åŒ–å·¦ä¾§æ¨¡å‹
        log.info("ğŸ¤– åˆå§‹åŒ–å·¦ä¾§æ½œåŠ›ç‰›è‚¡æ¨¡å‹...")
        left_model = LeftBreakoutModel(dm, config.get('left_breakout', {}))

        # 4. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        if not left_model.load_model():
            log.error("âŒ æ— æ³•åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬")
            log.info("ğŸ’¡ è¿è¡Œå‘½ä»¤: python scripts/train_left_breakout_model.py")
            return

        # 5. å‡†å¤‡éªŒè¯æ•°æ®
        log.info("ğŸ“Š å‡†å¤‡éªŒè¯æ•°æ®...")

        # åŠ è½½ç‰¹å¾æ•°æ®
        features_file = 'data/training/features/left_breakout_features.csv'
        if not os.path.exists(features_file):
            log.error(f"âŒ ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {features_file}")
            log.info("ğŸ’¡ è¯·å…ˆè¿è¡Œæ ·æœ¬å‡†å¤‡å’Œè®­ç»ƒè„šæœ¬")
            return

        features_df = pd.read_csv(features_file)
        log.info(f"âœ… åŠ è½½ç‰¹å¾æ•°æ®: {len(features_df)} æ ·æœ¬")

        # 6. åˆå§‹åŒ–éªŒè¯å™¨
        log.info("ğŸ” åˆå§‹åŒ–éªŒè¯å™¨...")
        validator = LeftBreakoutValidator(left_model)

        # 7. æ‰§è¡ŒéªŒè¯
        validation_results = {}

        # Walk-ForwardéªŒè¯
        if args.walk_forward or args.all:
            log.info("\n" + "="*50)
            log.info("ğŸ“ˆ æ‰§è¡ŒWalk-Forwardæ»šåŠ¨éªŒè¯")
            log.info("="*50)

            wf_config = config.get('left_breakout', {}).get('validation', {}).get('walk_forward', {})
            wf_results = validator.walk_forward_validation(
                features_df,
                n_splits=wf_config.get('n_splits', 5),
                min_train_samples=wf_config.get('min_train_samples', 1000)
            )

            if wf_results:
                validation_results['walk_forward'] = wf_results
                display_walk_forward_results(wf_results)
            else:
                log.error("âŒ Walk-ForwardéªŒè¯å¤±è´¥")

        # é²æ£’æ€§æµ‹è¯•
        if args.robustness or args.all:
            log.info("\n" + "="*50)
            log.info("ğŸ›¡ï¸  æ‰§è¡Œé²æ£’æ€§æµ‹è¯•")
            log.info("="*50)

            rb_config = config.get('left_breakout', {}).get('validation', {}).get('robustness_test', {})
            rb_results = validator.robustness_test(
                features_df,
                n_bootstraps=rb_config.get('n_bootstraps', 50),
                sample_fraction=rb_config.get('sample_fraction', 0.8)
            )

            if rb_results:
                validation_results['robustness'] = rb_results
                display_robustness_results(rb_results)
            else:
                log.error("âŒ é²æ£’æ€§æµ‹è¯•å¤±è´¥")

        # æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
        if args.time_series_cv or args.all:
            log.info("\n" + "="*50)
            log.info("â° æ‰§è¡Œæ—¶é—´åºåˆ—äº¤å‰éªŒè¯")
            log.info("="*50)

            tscv_config = config.get('left_breakout', {}).get('validation', {}).get('time_series_cv', {})
            tscv_results = validator.time_series_cross_validation(
                features_df,
                initial_train_size=tscv_config.get('initial_train_size', 0.6),
                test_size=tscv_config.get('test_size', 0.2),
                step_size=tscv_config.get('step_size', 0.1)
            )

            if tscv_results:
                validation_results['time_series_cv'] = tscv_results
                display_time_series_cv_results(tscv_results)
            else:
                log.error("âŒ æ—¶é—´åºåˆ—äº¤å‰éªŒè¯å¤±è´¥")

        # 8. ä¿å­˜éªŒè¯æŠ¥å‘Š
        if validation_results:
            log.info("\n" + "="*50)
            log.info("ğŸ’¾ ä¿å­˜éªŒè¯æŠ¥å‘Š...")
            save_validation_summary_report(validation_results)

        # 9. è¾“å‡ºæ€»ç»“
        log.info("\n" + "="*60)
        log.info("ğŸ‰ æ¨¡å‹éªŒè¯å®Œæˆï¼")
        log.info("="*60)

        # æ€»ä½“è¯„ä¼°
        overall_assessment = assess_overall_performance(validation_results)
        log.info("ğŸ“Š æ€»ä½“è¯„ä¼°:")
        for key, value in overall_assessment.items():
            log.info(f"   â€¢ {key}: {value}")

        log.info("\nğŸ’¡ éªŒè¯æŠ¥å‘Šå·²ä¿å­˜è‡³: data/models/left_breakout/validation/")

    except Exception as e:
        log.error(f"âŒ éªŒè¯å¤±è´¥: {e}")
        import traceback
        log.error(traceback.format_exc())
        sys.exit(1)


def display_walk_forward_results(results):
    """æ˜¾ç¤ºWalk-ForwardéªŒè¯ç»“æœ"""
    summary = results.get('summary', {})
    fold_results = results.get('fold_results', [])

    log.info("ğŸ“ˆ Walk-ForwardéªŒè¯ç»“æœ:")
    log.info("-"*60)
    log.info("<8")
    log.info("-"*60)

    metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']
    for metric in metrics:
        mean_val = summary.get(f'{metric}_mean', 0)
        std_val = summary.get(f'{metric}_std', 0)
        stability = summary.get(f'{metric}_stability', 0)

        log.info("<8")
    log.info(f"ğŸ¯ æ•´ä½“è¯„çº§: {summary.get('overall_rating', 'N/A')}")

    log.info("
ğŸ“‹ å„æŠ˜è¯¦æƒ…:"    log.info("<6")
    log.info("-"*80)

    for result in fold_results:
        log.info("2d"
                 "<12"
                 "<10.4f"
                 "<10.4f"
                 "<10.4f"
                 "<10.4f"
                 "<10.4f"
                 "\n")


def display_robustness_results(results):
    """æ˜¾ç¤ºé²æ£’æ€§æµ‹è¯•ç»“æœ"""
    stats = results.get('statistics', {})

    log.info("ğŸ›¡ï¸  é²æ£’æ€§æµ‹è¯•ç»“æœ:")
    log.info("-"*60)
    log.info("<15")
    log.info("-"*60)

    metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']
    for metric in metrics:
        mean_val = stats.get(f'{metric}_mean', 0)
        std_val = stats.get(f'{metric}_std', 0)
        ci_lower = stats.get(f'{metric}_95_ci_lower', 0)
        ci_upper = stats.get(f'{metric}_95_ci_upper', 0)

        log.info("<15"
                 "<10.4f"
                 "<10.4f"
                 "<10.4f"
                 "<10.4f"
                 "\n")


def display_time_series_cv_results(results):
    """æ˜¾ç¤ºæ—¶é—´åºåˆ—äº¤å‰éªŒè¯ç»“æœ"""
    summary = results.get('summary', {})
    fold_results = results.get('fold_results', [])

    log.info("â° æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ç»“æœ:")
    log.info("-"*60)
    log.info("<8")
    log.info("-"*60)

    metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']
    for metric in metrics:
        mean_val = summary.get(f'{metric}_mean', 0)
        std_val = summary.get(f'{metric}_std', 0)

        log.info("<8")
    log.info(f"ğŸ“Š æ€»éªŒè¯è½®æ•°: {len(fold_results)}")


def assess_overall_performance(validation_results):
    """è¯„ä¼°æ€»ä½“æ€§èƒ½"""
    assessment = {}

    try:
        # Walk-Forwardè¯„ä¼°
        if 'walk_forward' in validation_results:
            wf_summary = validation_results['walk_forward'].get('summary', {})
            wf_rating = wf_summary.get('overall_rating', 'N/A')
            assessment['Walk-Forwardè¯„çº§'] = wf_rating

            auc_mean = wf_summary.get('auc_roc_mean', 0)
            auc_stability = wf_summary.get('auc_roc_stability', 0)

            if auc_mean > 0.75 and auc_stability > 10:
                assessment['ç¨³å®šæ€§è¯„ä¼°'] = 'ä¼˜ç§€'
            elif auc_mean > 0.70 and auc_stability > 5:
                assessment['ç¨³å®šæ€§è¯„ä¼°'] = 'è‰¯å¥½'
            else:
                assessment['ç¨³å®šæ€§è¯„ä¼°'] = 'éœ€æ”¹è¿›'

        # é²æ£’æ€§è¯„ä¼°
        if 'robustness' in validation_results:
            rb_stats = validation_results['robustness'].get('statistics', {})
            auc_std = rb_stats.get('auc_roc_std', 1)

            if auc_std < 0.05:
                assessment['é²æ£’æ€§è¯„ä¼°'] = 'ä¼˜ç§€'
            elif auc_std < 0.10:
                assessment['é²æ£’æ€§è¯„ä¼°'] = 'è‰¯å¥½'
            else:
                assessment['é²æ£’æ€§è¯„ä¼°'] = 'éœ€æ”¹è¿›'

        # ç»¼åˆå»ºè®®
        ratings = [v for k, v in assessment.items() if 'è¯„ä¼°' in k and v != 'éœ€æ”¹è¿›']
        if len(ratings) == 2 and all(r == 'ä¼˜ç§€' for r in ratings):
            assessment['ä½¿ç”¨å»ºè®®'] = 'æ¨¡å‹æ€§èƒ½ä¼˜ç§€ï¼Œå»ºè®®ç”¨äºå®é™…é¢„æµ‹'
        elif len(ratings) >= 1:
            assessment['ä½¿ç”¨å»ºè®®'] = 'æ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼Œå¯ä»¥è¯•ç”¨'
        else:
            assessment['ä½¿ç”¨å»ºè®®'] = 'å»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹å‚æ•°'

    except Exception as e:
        log.debug(f"æ€»ä½“è¯„ä¼°å¤±è´¥: {e}")
        assessment['è¯„ä¼°çŠ¶æ€'] = 'è¯„ä¼°è¿‡ç¨‹å‡ºé”™'

    return assessment


def save_validation_summary_report(validation_results):
    """ä¿å­˜éªŒè¯æ€»ç»“æŠ¥å‘Š"""
    try:
        report_dir = "data/models/left_breakout/validation"
        os.makedirs(report_dir, exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = os.path.join(report_dir, f"validation_summary_{timestamp}.txt")

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("å·¦ä¾§æ½œåŠ›ç‰›è‚¡æ¨¡å‹ - éªŒè¯æ€»ç»“æŠ¥å‘Š\n")
            f.write("="*80 + "\n\n")

            f.write(f"ğŸ“… éªŒè¯æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # Walk-Forwardç»“æœ
            if 'walk_forward' in validation_results:
                f.write("ğŸ“ˆ Walk-Forwardæ»šåŠ¨éªŒè¯\n")
                f.write("-"*50 + "\n")

                summary = validation_results['walk_forward'].get('summary', {})
                metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']

                f.write("<12")
                f.write("-"*50 + "\n")

                for metric in metrics:
                    mean_val = summary.get(f'{metric}_mean', 0)
                    std_val = summary.get(f'{metric}_std', 0)
                    stability = summary.get(f'{metric}_stability', 0)

                    f.write("<12")
                f.write(f"\næ•´ä½“è¯„çº§: {summary.get('overall_rating', 'N/A')}\n\n")

            # é²æ£’æ€§ç»“æœ
            if 'robustness' in validation_results:
                f.write("ğŸ›¡ï¸  é²æ£’æ€§æµ‹è¯•\n")
                f.write("-"*50 + "\n")

                rb_stats = validation_results['robustness'].get('statistics', {})

                f.write("<15")
                f.write("-"*50 + "\n")

                for metric in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']:
                    mean_val = rb_stats.get(f'{metric}_mean', 0)
                    std_val = rb_stats.get(f'{metric}_std', 0)
                    ci_lower = rb_stats.get(f'{metric}_95_ci_lower', 0)
                    ci_upper = rb_stats.get(f'{metric}_95_ci_upper', 0)

                    f.write("<15"
                           "<10.4f"
                           "<10.4f"
                           "<10.4f"
                           "<10.4f"
                           "\n")

            # æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ç»“æœ
            if 'time_series_cv' in validation_results:
                f.write("â° æ—¶é—´åºåˆ—äº¤å‰éªŒè¯\n")
                f.write("-"*50 + "\n")

                tscv_summary = validation_results['time_series_cv'].get('summary', {})

                f.write("<12")
                f.write("-"*50 + "\n")

                for metric in ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']:
                    mean_val = tscv_summary.get(f'{metric}_mean', 0)
                    std_val = tscv_summary.get(f'{metric}_std', 0)

                    f.write("<12")
                f.write(f"\næ€»éªŒè¯è½®æ•°: {validation_results['time_series_cv'].get('cv_config', {}).get('total_folds', 0)}\n\n")

            # æ€»ä½“è¯„ä¼°
            f.write("ğŸ“Š æ€»ä½“è¯„ä¼°\n")
            f.write("-"*50 + "\n")

            overall_assessment = assess_overall_performance(validation_results)
            for key, value in overall_assessment.items():
                f.write(f"â€¢ {key}: {value}\n")

            f.write("\nğŸ’¡ éªŒè¯å®Œæˆè¯´æ˜:\n")
            f.write("â€¢ Walk-ForwardéªŒè¯è¯„ä¼°äº†æ¨¡å‹åœ¨ä¸åŒæ—¶é—´æ®µçš„ç¨³å®šæ€§\n")
            f.write("â€¢ é²æ£’æ€§æµ‹è¯•è¯„ä¼°äº†æ¨¡å‹å¯¹æ•°æ®æ‰°åŠ¨çš„æŠµæŠ—åŠ›\n")
            f.write("â€¢ æ—¶é—´åºåˆ—äº¤å‰éªŒè¯æä¾›äº†é¢å¤–çš„ç¨³å®šæ€§éªŒè¯\n")
            f.write("â€¢ å»ºè®®å®šæœŸè¿›è¡ŒéªŒè¯ï¼Œç¡®ä¿æ¨¡å‹æŒç»­æœ‰æ•ˆæ€§\n")

        log.info(f"éªŒè¯æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        return True

    except Exception as e:
        log.error(f"ä¿å­˜éªŒè¯æ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    main()
