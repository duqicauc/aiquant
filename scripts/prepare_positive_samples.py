"""
å‡†å¤‡æ­£æ ·æœ¬æ•°æ®çš„ä¸»è„šæœ¬

è¿è¡Œæ­¥éª¤ï¼š
1. ç­›é€‰ç¬¦åˆæ¡ä»¶çš„æ­£æ ·æœ¬
2. æå–æ¯ä¸ªæ ·æœ¬T1å‰34å¤©çš„ç‰¹å¾æ•°æ®
3. ä¿å­˜ç»“æœ
"""
import sys
from pathlib import Path
import warnings

# è¿‡æ»¤ pandas FutureWarningï¼ˆæ¥è‡ª tushare åº“å†…éƒ¨ï¼Œä¸å½±å“åŠŸèƒ½ï¼‰
warnings.filterwarnings('ignore', category=FutureWarning, module='tushare')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.data.data_manager import DataManager
from src.strategy.screening.positive_sample_screener import PositiveSampleScreener
from src.utils.logger import log
from config.settings import settings
import pandas as pd
from datetime import datetime


def main():
    """ä¸»å‡½æ•°"""
    
    log.info("="*80)
    log.info("æ­£æ ·æœ¬æ•°æ®å‡†å¤‡æµç¨‹")
    log.info("="*80)
    
    # 1. åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    log.info("\n[æ­¥éª¤1] åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨...")
    dm = DataManager(source='tushare')
    
    # 2. åˆå§‹åŒ–ç­›é€‰å™¨
    log.info("\n[æ­¥éª¤2] åˆå§‹åŒ–æ­£æ ·æœ¬ç­›é€‰å™¨...")
    screener = PositiveSampleScreener(dm)
    
    # 3. ç­›é€‰æ­£æ ·æœ¬
    log.info("\n[æ­¥éª¤3] å¼€å§‹ç­›é€‰æ­£æ ·æœ¬ï¼ˆè¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰...")
    log.info("ç­›é€‰æ¡ä»¶ï¼š")
    log.info("  - å‘¨Kè¿ç»­ä¸‰å‘¨æ”¶é˜³çº¿")
    log.info("  - æ€»æ¶¨å¹…è¶…50%")
    log.info("  - æœ€é«˜æ¶¨å¹…è¶…70%")
    log.info("  - å‰”é™¤STè‚¡ç¥¨")
    log.info("  - ä¸Šå¸‚è¶…è¿‡åŠå¹´")
    log.info("")
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–æ—¥æœŸèŒƒå›´
    START_DATE = settings.get('data.sample_preparation.start_date', '20000101')
    END_DATE = settings.get('data.sample_preparation.end_date', None)
    
    log.info(f"ğŸ“… æ•°æ®èŒƒå›´é…ç½®ï¼š{START_DATE} - {END_DATE or 'ä»Šå¤©'}")
    log.info(f"ğŸ’¡ å¦‚éœ€ä¿®æ”¹ï¼Œè¯·ç¼–è¾‘ config/settings.yaml")
    
    try:
        df_samples = screener.screen_all_stocks(
            start_date=START_DATE,
            end_date=END_DATE
        )
        
        if df_samples.empty:
            log.error("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ­£æ ·æœ¬ï¼è¯·æ£€æŸ¥ç­›é€‰æ¡ä»¶æˆ–æ•°æ®è´¨é‡")
            return
        
        # ä¿å­˜æ­£æ ·æœ¬åˆ—è¡¨
        samples_file = PROJECT_ROOT / 'data' / 'training' / 'samples' / 'positive_samples.csv'
        samples_file.parent.mkdir(parents=True, exist_ok=True)
        df_samples.to_csv(samples_file, index=False, encoding='utf-8-sig')
        log.success(f"âœ“ æ­£æ ·æœ¬åˆ—è¡¨å·²ä¿å­˜: {samples_file}")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        log.info("\n" + "="*80)
        log.info("æ­£æ ·æœ¬ç»Ÿè®¡")
        log.info("="*80)
        log.info(f"æ ·æœ¬æ€»æ•°: {len(df_samples)}")
        log.info(f"è‚¡ç¥¨æ•°é‡: {df_samples['ts_code'].nunique()}")
        log.info(f"å¹³å‡æ€»æ¶¨å¹…: {df_samples['total_return'].mean():.2f}%")
        log.info(f"å¹³å‡æœ€é«˜æ¶¨å¹…: {df_samples['max_return'].mean():.2f}%")
        log.info(f"\nå‰5ä¸ªæ ·æœ¬:")
        print(df_samples.head())
        
        # 4. æå–ç‰¹å¾æ•°æ®
        log.info("\n[æ­¥éª¤4] æå–ç‰¹å¾æ•°æ®ï¼ˆT1å‰34å¤©ï¼‰...")
        
        df_features = screener.extract_features(
            df_samples,
            lookback_days=34
        )
        
        if df_features.empty:
            log.error("ç‰¹å¾æå–å¤±è´¥ï¼")
            return
        
        # ä¿å­˜ç‰¹å¾æ•°æ®
        features_file = PROJECT_ROOT / 'data' / 'processed' / 'feature_data_34d.csv'
        df_features.to_csv(features_file, index=False, encoding='utf-8-sig')
        log.success(f"âœ“ ç‰¹å¾æ•°æ®å·²ä¿å­˜: {features_file}")
        
        # ç‰¹å¾ç»Ÿè®¡
        log.info("\n" + "="*80)
        log.info("ç‰¹å¾æ•°æ®ç»Ÿè®¡")
        log.info("="*80)
        log.info(f"æ€»è®°å½•æ•°: {len(df_features)}")
        log.info(f"æ ·æœ¬æ•°: {df_features['sample_id'].nunique()}")
        log.info(f"æ¯æ ·æœ¬å¤©æ•°: {len(df_features) / df_features['sample_id'].nunique():.1f}")
        log.info(f"\næ•°æ®å­—æ®µ:")
        for col in df_features.columns:
            log.info(f"  - {col}")
        log.info(f"\næ•°æ®é¢„è§ˆ:")
        print(df_features.head(10))
        
        # 5. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        log.info("\n[æ­¥éª¤5] ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")
        
        stats = {
            'generation_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'date_range': f"{START_DATE} - {END_DATE or 'today'}",
            'total_samples': int(len(df_samples)),
            'unique_stocks': int(df_samples['ts_code'].nunique()),
            'avg_total_return': float(df_samples['total_return'].mean()),
            'avg_max_return': float(df_samples['max_return'].mean()),
            'feature_records': int(len(df_features)),
            'lookback_days': 34,
            'sample_files': {
                'positive_samples': str(samples_file),
                'feature_data': str(features_file)
            }
        }
        
        import json
        stats_file = PROJECT_ROOT / 'data' / 'processed' / 'sample_statistics.json'
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        log.success(f"âœ“ ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {stats_file}")
        
        # å®Œæˆ
        log.info("\n" + "="*80)
        log.success("âœ… æ­£æ ·æœ¬æ•°æ®å‡†å¤‡å®Œæˆï¼")
        log.info("="*80)
        log.info("\nç”Ÿæˆçš„æ–‡ä»¶:")
        log.info(f"  1. æ­£æ ·æœ¬åˆ—è¡¨: {samples_file}")
        log.info(f"  2. ç‰¹å¾æ•°æ®: {features_file}")
        log.info(f"  3. ç»Ÿè®¡æŠ¥å‘Š: {stats_file}")
        log.info("\nä¸‹ä¸€æ­¥:")
        log.info("  - æŸ¥çœ‹æ•°æ®è´¨é‡")
        log.info("  - å‡†å¤‡è´Ÿæ ·æœ¬")
        log.info("  - å¼€å§‹æ¨¡å‹è®­ç»ƒ")
        
    except Exception as e:
        log.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

