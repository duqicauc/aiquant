"""
ç¡¬è´Ÿæ ·æœ¬æ•°æ®å‡†å¤‡è„šæœ¬

ç­›é€‰"æ¥è¿‘ä½†æœªè¾¾æ ‡"çš„è‚¡ç¥¨ä½œä¸ºç¡¬è´Ÿæ ·æœ¬ï¼š
- 34æ—¥æ¶¨å¹…åœ¨20-45%ä¹‹é—´ï¼ˆæ¥è¿‘æ­£æ ·æœ¬çš„50%é˜ˆå€¼ï¼‰
- è¿™äº›è‚¡ç¥¨ç‰¹å¾ä¸æ­£æ ·æœ¬ç›¸ä¼¼ï¼Œç”¨äºæé«˜æ¨¡å‹åŒºåˆ†èƒ½åŠ›

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/prepare_hard_negatives.py
"""
import sys
import os
import warnings
import pandas as pd
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# å¿½ç•¥FutureWarning
warnings.filterwarnings('ignore', category=FutureWarning)

from src.data.data_manager import DataManager
from src.models.screening.hard_negative_screener import HardNegativeSampleScreener
from src.utils.logger import log


def main():
    """ä¸»å‡½æ•°"""
    log.info("="*80)
    log.info("ç¡¬è´Ÿæ ·æœ¬æ•°æ®å‡†å¤‡")
    log.info("="*80)
    
    # é…ç½®å‚æ•°
    MIN_RETURN = 20.0          # æœ€å°34æ—¥æ¶¨å¹…
    MAX_RETURN = 45.0          # æœ€å¤§34æ—¥æ¶¨å¹…ï¼ˆä½äºæ­£æ ·æœ¬çš„50%ï¼‰
    SAMPLES_PER_DATE = 3       # æ¯ä¸ªT1æ—¥æœŸé‡‡æ ·çš„ç¡¬è´Ÿæ ·æœ¬æ•°é‡
    RANDOM_SEED = 42
    
    POSITIVE_SAMPLES_FILE = 'data/training/samples/positive_samples.csv'
    OUTPUT_HARD_SAMPLES = 'data/training/samples/hard_negative_samples.csv'
    OUTPUT_HARD_FEATURES = 'data/training/features/hard_negative_feature_data_34d.csv'
    OUTPUT_STATS = 'data/training/samples/hard_negative_statistics.json'
    
    log.info(f"\nå½“å‰è®¾ç½®ï¼š")
    log.info(f"  æ–¹æ³•: ç¡¬è´Ÿæ ·æœ¬ç­›é€‰ï¼ˆ34æ—¥æ¶¨å¹…{MIN_RETURN}%-{MAX_RETURN}%ï¼‰")
    log.info(f"  æ­£æ ·æœ¬æ–‡ä»¶: {POSITIVE_SAMPLES_FILE}")
    log.info(f"  æ¯T1æ—¥æœŸé‡‡æ ·: {SAMPLES_PER_DATE} åª")
    log.info(f"  éšæœºç§å­: {RANDOM_SEED}")
    log.info("")
    
    # 1. åŠ è½½æ­£æ ·æœ¬æ•°æ®
    log.info("="*80)
    log.info("ç¬¬ä¸€æ­¥ï¼šåŠ è½½æ­£æ ·æœ¬æ•°æ®")
    log.info("="*80)
    
    try:
        df_positive_samples = pd.read_csv(POSITIVE_SAMPLES_FILE)
        log.success(f"âœ“ æ­£æ ·æœ¬åŠ è½½æˆåŠŸ: {len(df_positive_samples)} ä¸ª")
    except Exception as e:
        log.error(f"âœ— åŠ è½½æ­£æ ·æœ¬æ•°æ®å¤±è´¥: {e}")
        return
    
    # 2. åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨å’Œç­›é€‰å™¨
    log.info("\n" + "="*80)
    log.info("ç¬¬äºŒæ­¥ï¼šåˆå§‹åŒ–ç¡¬è´Ÿæ ·æœ¬ç­›é€‰å™¨")
    log.info("="*80)
    
    dm = DataManager()
    screener = HardNegativeSampleScreener(dm)
    
    log.success("âœ“ ç­›é€‰å™¨åˆå§‹åŒ–å®Œæˆ")
    
    # 3. ç­›é€‰ç¡¬è´Ÿæ ·æœ¬
    log.info("\n" + "="*80)
    log.info("ç¬¬ä¸‰æ­¥ï¼šç­›é€‰ç¡¬è´Ÿæ ·æœ¬")
    log.info("="*80)
    
    df_hard_samples = screener.screen_hard_negatives(
        positive_samples_df=df_positive_samples,
        min_return=MIN_RETURN,
        max_return=MAX_RETURN,
        samples_per_date=SAMPLES_PER_DATE,
        random_seed=RANDOM_SEED
    )
    
    if df_hard_samples.empty:
        log.error("âœ— æœªæ‰¾åˆ°ç¡¬è´Ÿæ ·æœ¬")
        return
    
    # 4. æå–ç¡¬è´Ÿæ ·æœ¬ç‰¹å¾
    log.info("\n" + "="*80)
    log.info("ç¬¬å››æ­¥ï¼šæå–ç¡¬è´Ÿæ ·æœ¬ç‰¹å¾æ•°æ®")
    log.info("="*80)
    
    df_hard_features = screener.extract_features(df_hard_samples)
    
    if df_hard_features.empty:
        log.error("âœ— ç‰¹å¾æå–å¤±è´¥")
        return
    
    # 4.1 æ•°æ®è´¨é‡å¤„ç†
    log.info("\n[æ­¥éª¤4.1] æ•°æ®è´¨é‡å¤„ç†...")
    
    # å®šä¹‰æ•°å€¼åˆ—
    numeric_cols = ['close', 'pct_chg', 'total_mv', 'circ_mv', 'ma5', 'ma10', 
                    'volume_ratio', 'macd_dif', 'macd_dea', 'macd', 
                    'rsi_6', 'rsi_12', 'rsi_24']
    numeric_cols = [col for col in numeric_cols if col in df_hard_features.columns]
    
    # ç¼ºå¤±å€¼å¡«å……
    df_hard_features[numeric_cols] = df_hard_features.groupby('sample_id')[numeric_cols].transform(
        lambda x: x.ffill().bfill()
    )
    
    # è¿‡æ»¤æ•°æ®ä¸è¶³çš„æ ·æœ¬
    min_days = 30
    days_per_sample = df_hard_features.groupby('sample_id').size()
    valid_samples = days_per_sample[days_per_sample >= min_days].index
    df_hard_features = df_hard_features[df_hard_features['sample_id'].isin(valid_samples)]
    
    # åŒæ­¥è¿‡æ»¤æ ·æœ¬åˆ—è¡¨
    valid_sample_ids = df_hard_features['sample_id'].unique()
    df_hard_samples = df_hard_samples[df_hard_samples.index.isin(valid_sample_ids)]
    
    log.success(f"âœ“ æ•°æ®è´¨é‡å¤„ç†å®Œæˆ")
    
    # 5. ä¿å­˜ç»“æœ
    log.info("\n" + "="*80)
    log.info("ç¬¬äº”æ­¥ï¼šä¿å­˜ç»“æœ")
    log.info("="*80)
    
    # ä¿å­˜ç¡¬è´Ÿæ ·æœ¬åˆ—è¡¨
    df_hard_samples.to_csv(OUTPUT_HARD_SAMPLES, index=False)
    log.success(f"âœ“ ç¡¬è´Ÿæ ·æœ¬åˆ—è¡¨å·²ä¿å­˜: {OUTPUT_HARD_SAMPLES}")
    
    # ä¿å­˜ç¡¬è´Ÿæ ·æœ¬ç‰¹å¾æ•°æ®
    df_hard_features.to_csv(OUTPUT_HARD_FEATURES, index=False)
    log.success(f"âœ“ ç¡¬è´Ÿæ ·æœ¬ç‰¹å¾æ•°æ®å·²ä¿å­˜: {OUTPUT_HARD_FEATURES}")
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'generation_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'method': 'ç¡¬è´Ÿæ ·æœ¬ç­›é€‰ï¼ˆ34æ—¥æ¶¨å¹…æ¥è¿‘é˜ˆå€¼ï¼‰',
        'total_hard_samples': len(df_hard_samples),
        'total_positive_samples': len(df_positive_samples),
        'hard_feature_records': len(df_hard_features),
        'feature_samples': int(df_hard_features['sample_id'].nunique()),
        'return_range': {
            'min': MIN_RETURN,
            'max': MAX_RETURN
        },
        'samples_per_date': SAMPLES_PER_DATE,
        'random_seed': RANDOM_SEED,
        'return_statistics': {
            'mean': float(df_hard_samples['return_34d'].mean()) if 'return_34d' in df_hard_samples.columns else None,
            'median': float(df_hard_samples['return_34d'].median()) if 'return_34d' in df_hard_samples.columns else None,
            'min': float(df_hard_samples['return_34d'].min()) if 'return_34d' in df_hard_samples.columns else None,
            'max': float(df_hard_samples['return_34d'].max()) if 'return_34d' in df_hard_samples.columns else None,
        },
        'files': {
            'hard_samples': OUTPUT_HARD_SAMPLES,
            'hard_features': OUTPUT_HARD_FEATURES,
            'positive_samples': POSITIVE_SAMPLES_FILE
        }
    }
    
    with open(OUTPUT_STATS, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    log.success(f"âœ“ ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {OUTPUT_STATS}")
    
    # 6. æœ€ç»ˆæ€»ç»“
    log.info("\n" + "="*80)
    log.success("âœ… ç¡¬è´Ÿæ ·æœ¬æ•°æ®å‡†å¤‡å®Œæˆï¼")
    log.info("="*80)
    log.info("")
    log.info(f"  1. ç¡¬è´Ÿæ ·æœ¬åˆ—è¡¨: {OUTPUT_HARD_SAMPLES}")
    log.info(f"  2. ç¡¬è´Ÿæ ·æœ¬ç‰¹å¾: {OUTPUT_HARD_FEATURES}")
    log.info(f"  3. ç»Ÿè®¡æŠ¥å‘Š: {OUTPUT_STATS}")
    log.info("")
    log.info("ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼š")
    log.info(f"  æ­£æ ·æœ¬æ•°: {len(df_positive_samples)}")
    log.info(f"  ç¡¬è´Ÿæ ·æœ¬æ•°: {len(df_hard_samples)}")
    log.info(f"  ç¡¬è´Ÿæ ·æœ¬ç‰¹å¾: {len(df_hard_features)} æ¡")
    if 'return_34d' in df_hard_samples.columns:
        log.info(f"\nğŸ“ˆ 34æ—¥æ¶¨å¹…åˆ†å¸ƒï¼š")
        log.info(f"  å‡å€¼: {df_hard_samples['return_34d'].mean():.2f}%")
        log.info(f"  ä¸­ä½æ•°: {df_hard_samples['return_34d'].median():.2f}%")
    log.info("")
    log.info("ğŸ’¡ ç¡¬è´Ÿæ ·æœ¬ç‰¹ç‚¹ï¼š")
    log.info("  - 34æ—¥æ¶¨å¹…åœ¨20-45%ä¹‹é—´ï¼ˆæ¥è¿‘æ­£æ ·æœ¬çš„50%é˜ˆå€¼ï¼‰")
    log.info("  - ç‰¹å¾ä¸æ­£æ ·æœ¬ç›¸ä¼¼ï¼Œä½†æœªè¾¾åˆ°æ­£æ ·æœ¬æ ‡å‡†")
    log.info("  - ç”¨äºæé«˜æ¨¡å‹åŒºåˆ†èƒ½åŠ›ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ")
    log.info("")
    log.info("ä¸‹ä¸€æ­¥ï¼š")
    log.info("  è¿è¡Œ python scripts/train_optimized_model.py è®­ç»ƒä¼˜åŒ–ç‰ˆæ¨¡å‹")
    log.info("")


if __name__ == '__main__':
    main()

