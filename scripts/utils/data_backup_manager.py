#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ•°æ®å¤‡ä»½ç®¡ç†å·¥å…·

åŠŸèƒ½ï¼š
1. å¯¼å‡ºSQLiteæ•°æ®åˆ°CSV
2. ä»CSVå¯¼å…¥æ•°æ®åˆ°SQLite
3. æŸ¥çœ‹å¤‡ä»½ç»Ÿè®¡
4. æ¸…ç†å¤‡ä»½æ•°æ®
"""

import argparse
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.data.storage.backup_cache_manager import BackupCacheManager
from src.utils.logger import log


def export_to_csv(args):
    """å¯¼å‡ºæ‰€æœ‰æ•°æ®åˆ°CSV"""
    log.info("="*80)
    log.info("ğŸ“¤ å¯¼å‡ºSQLiteæ•°æ®åˆ°CSV")
    log.info("="*80)
    
    cache = BackupCacheManager(enable_backup=True)
    
    # æŒ‡å®šæ•°æ®ç±»å‹
    data_types = None
    if args.data_type:
        data_types = [args.data_type]
    
    cache.export_all_to_csv(data_types=data_types)
    
    log.success("\nâœ… å¯¼å‡ºå®Œæˆï¼")
    log.info("\nğŸ’¡ æç¤ºï¼š")
    log.info("  - CSVæ–‡ä»¶ä½ç½®: data/backup/")
    log.info("  - å¯ä»¥ç›´æ¥ç”¨Excelæ‰“å¼€æŸ¥çœ‹")
    log.info("  - å¯ä»¥æ‰“åŒ…æ•´ä¸ªbackupç›®å½•è¿›è¡Œè¿ç§»")


def import_from_csv(args):
    """ä»CSVå¯¼å…¥æ•°æ®"""
    log.info("="*80)
    log.info("ğŸ“¥ ä»CSVå¯¼å…¥æ•°æ®åˆ°SQLite")
    log.info("="*80)
    
    cache = BackupCacheManager(enable_backup=True)
    
    # æŒ‡å®šæ•°æ®ç±»å‹
    data_types = None
    if args.data_type:
        data_types = [args.data_type]
    
    cache.import_from_csv(data_types=data_types)
    
    log.success("\nâœ… å¯¼å…¥å®Œæˆï¼")


def show_stats(args):
    """æ˜¾ç¤ºå¤‡ä»½ç»Ÿè®¡"""
    cache = BackupCacheManager(enable_backup=True)
    
    log.info("="*80)
    log.info("ğŸ“Š æ•°æ®å¤‡ä»½ç»Ÿè®¡")
    log.info("="*80)
    
    stats = cache.get_backup_stats()
    
    # SQLiteç»Ÿè®¡
    log.info("\nğŸ“ SQLiteç¼“å­˜:")
    if 'sqlite' in stats:
        for key, value in stats['sqlite'].items():
            log.info(f"  {key}: {value:,}")
    
    # CSVå¤‡ä»½ç»Ÿè®¡
    log.info("\nğŸ“„ CSVå¤‡ä»½:")
    if 'csv' in stats and stats['csv']:
        total_files = 0
        for data_type, count in stats['csv'].items():
            log.info(f"  {data_type}: {count:,} ä¸ªæ–‡ä»¶")
            total_files += count
        log.info(f"  æ€»è®¡: {total_files:,} ä¸ªæ–‡ä»¶")
    else:
        log.info("  (æ— CSVå¤‡ä»½)")
    
    # å¤‡ä»½ç´¢å¼•
    index_file = cache.backup_dir / 'metadata' / 'backup_index.json'
    if index_file.exists():
        import json
        with open(index_file, 'r', encoding='utf-8') as f:
            index = json.load(f)
        
        log.info("\nğŸ“‘ å¤‡ä»½ç´¢å¼•:")
        log.info(f"  å¤‡ä»½æ—¶é—´: {index.get('backup_time', 'N/A')}")
        log.info(f"  è‚¡ç¥¨æ€»æ•°: {index.get('total_stocks', 0):,}")
        log.info(f"  æ–‡ä»¶æ€»æ•°: {index.get('total_files', 0):,}")
    
    log.info("="*80)


def clear_backup(args):
    """æ¸…ç†å¤‡ä»½æ•°æ®"""
    cache = BackupCacheManager(enable_backup=True)
    
    if args.confirm != 'yes':
        log.error("âŒ éœ€è¦ç¡®è®¤æ‰èƒ½æ¸…ç†ï¼è¯·ä½¿ç”¨ --confirm yes")
        return
    
    log.warning("âš ï¸  è­¦å‘Šï¼šå³å°†æ¸…ç†å¤‡ä»½æ•°æ®ï¼")
    
    if args.ts_code:
        cache.clear_csv_backup(ts_code=args.ts_code, data_type=args.data_type)
        log.success(f"âœ“ å·²æ¸…ç† {args.ts_code} çš„å¤‡ä»½")
    else:
        cache.clear_csv_backup()
        log.success("âœ“ å·²æ¸…ç†æ‰€æœ‰CSVå¤‡ä»½")


def sync_data(args):
    """åŒæ­¥SQLiteå’ŒCSVæ•°æ®"""
    log.info("="*80)
    log.info("ğŸ”„ åŒæ­¥æ•°æ®")
    log.info("="*80)
    
    cache = BackupCacheManager(enable_backup=True)
    
    if args.direction == 'to_csv':
        log.info("ä»SQLiteåŒæ­¥åˆ°CSV...")
        cache.export_all_to_csv()
    elif args.direction == 'to_sqlite':
        log.info("ä»CSVåŒæ­¥åˆ°SQLite...")
        cache.import_from_csv()
    else:
        log.error(f"æœªçŸ¥çš„åŒæ­¥æ–¹å‘: {args.direction}")
        return
    
    log.success("âœ“ åŒæ­¥å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æ•°æ®å¤‡ä»½ç®¡ç†å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¯¼å‡ºæ‰€æœ‰æ•°æ®åˆ°CSV
  python scripts/utils/data_backup_manager.py export

  # å¯¼å‡ºæŒ‡å®šç±»å‹æ•°æ®
  python scripts/utils/data_backup_manager.py export --data-type daily_data

  # ä»CSVå¯¼å…¥æ•°æ®
  python scripts/utils/data_backup_manager.py import

  # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
  python scripts/utils/data_backup_manager.py stats

  # åŒæ­¥æ•°æ®
  python scripts/utils/data_backup_manager.py sync --direction to_csv

  # æ¸…ç†å¤‡ä»½ï¼ˆéœ€è¦ç¡®è®¤ï¼‰
  python scripts/utils/data_backup_manager.py clear --confirm yes
        """
    )
    
    subparsers = parser.add_subparsers(dest='action', help='æ“ä½œç±»å‹')
    
    # å¯¼å‡ºå‘½ä»¤
    parser_export = subparsers.add_parser('export', help='å¯¼å‡ºæ•°æ®åˆ°CSV')
    parser_export.add_argument('--data-type', choices=['daily_data', 'weekly_data', 'daily_basic', 'stk_factor'],
                              help='æŒ‡å®šæ•°æ®ç±»å‹ï¼ˆä¸æŒ‡å®šåˆ™å¯¼å‡ºå…¨éƒ¨ï¼‰')
    
    # å¯¼å…¥å‘½ä»¤
    parser_import = subparsers.add_parser('import', help='ä»CSVå¯¼å…¥æ•°æ®')
    parser_import.add_argument('--data-type', choices=['daily_data', 'weekly_data', 'daily_basic', 'stk_factor'],
                              help='æŒ‡å®šæ•°æ®ç±»å‹ï¼ˆä¸æŒ‡å®šåˆ™å¯¼å…¥å…¨éƒ¨ï¼‰')
    
    # ç»Ÿè®¡å‘½ä»¤
    parser_stats = subparsers.add_parser('stats', help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
    
    # æ¸…ç†å‘½ä»¤
    parser_clear = subparsers.add_parser('clear', help='æ¸…ç†å¤‡ä»½æ•°æ®')
    parser_clear.add_argument('--ts-code', help='è‚¡ç¥¨ä»£ç ï¼ˆä¸æŒ‡å®šåˆ™æ¸…ç†å…¨éƒ¨ï¼‰')
    parser_clear.add_argument('--data-type', choices=['daily_data', 'weekly_data', 'daily_basic', 'stk_factor'],
                             help='æ•°æ®ç±»å‹')
    parser_clear.add_argument('--confirm', help='ç¡®è®¤æ¸…ç†ï¼ˆå¿…é¡»è¾“å…¥yesï¼‰')
    
    # åŒæ­¥å‘½ä»¤
    parser_sync = subparsers.add_parser('sync', help='åŒæ­¥æ•°æ®')
    parser_sync.add_argument('--direction', choices=['to_csv', 'to_sqlite'], required=True,
                            help='åŒæ­¥æ–¹å‘')
    
    args = parser.parse_args()
    
    if not args.action:
        parser.print_help()
        return
    
    try:
        if args.action == 'export':
            export_to_csv(args)
        elif args.action == 'import':
            import_from_csv(args)
        elif args.action == 'stats':
            show_stats(args)
        elif args.action == 'clear':
            clear_backup(args)
        elif args.action == 'sync':
            sync_data(args)
    
    except KeyboardInterrupt:
        log.warning("\nâš ï¸  æ“ä½œå·²å–æ¶ˆ")
        sys.exit(1)
    
    except Exception as e:
        log.error(f"\nâŒ æ“ä½œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == '__main__':
    main()

