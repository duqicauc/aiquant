#!/usr/bin/env python3
"""
é¢„æµ‹æ•ˆæœåˆ†æè„šæœ¬
å¯¹æ¯”é¢„æµ‹æ—¥æœŸå’Œå®é™…æ—¥æœŸçš„è‚¡ç¥¨è¡¨ç°
"""
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import sys
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.data.data_manager import DataManager
from src.utils.logger import log

def analyze_prediction(pred_date: str, actual_date: str, top_n: int = 50):
    """
    åˆ†æé¢„æµ‹æ•ˆæœ
    
    Args:
        pred_date: é¢„æµ‹æ—¥æœŸ (YYYYMMDD)
        actual_date: å®é™…æ—¥æœŸ (YYYYMMDD)
        top_n: åˆ†æTop Nåªè‚¡ç¥¨
    """
    log.info("=" * 70)
    log.info(f"ğŸ“Š é¢„æµ‹æ•ˆæœåˆ†æï¼š{pred_date}é¢„æµ‹ vs {actual_date}å®é™…è¡¨ç°")
    log.info("=" * 70)
    
    # 1. åŠ è½½é¢„æµ‹ç»“æœ
    pred_file = PROJECT_ROOT / 'data' / 'prediction' / 'results' / f'stock_scores_advanced_{pred_date}.csv'
    if not pred_file.exists():
        log.error(f"é¢„æµ‹æ–‡ä»¶ä¸å­˜åœ¨: {pred_file}")
        return
    
    df_pred = pd.read_csv(pred_file)
    log.info(f"âœ“ åŠ è½½é¢„æµ‹æ•°æ®: {len(df_pred)} åªè‚¡ç¥¨")
    
    # 2. è·å–å®é™…ä»·æ ¼ï¼ˆåªåˆ†æTop Nï¼ŒåŠ å¿«é€Ÿåº¦ï¼‰
    log.info(f"\næ­£åœ¨è·å–å®é™…ä»·æ ¼æ•°æ®ï¼ˆåˆ†æTop {top_n}åªï¼‰...")
    dm = DataManager()
    
    # åªåˆ†æTop N
    df_pred_top = df_pred.nlargest(top_n, 'ç‰›è‚¡æ¦‚ç‡').copy()
    
    results = []
    for idx, (_, row) in enumerate(df_pred_top.iterrows()):
        ts_code = row['è‚¡ç¥¨ä»£ç ']
        pred_price = row['æœ€æ–°ä»·æ ¼']
        prob = row['ç‰›è‚¡æ¦‚ç‡']
        
        try:
            # è·å–å®é™…æ—¥æœŸçš„ä»·æ ¼
            df_actual = dm.get_daily_data(ts_code, actual_date, actual_date)
            if df_actual is not None and len(df_actual) > 0:
                actual_price = df_actual['close'].iloc[-1]
                return_pct = (actual_price - pred_price) / pred_price * 100
                
                results.append({
                    'è‚¡ç¥¨ä»£ç ': ts_code,
                    'è‚¡ç¥¨åç§°': row['è‚¡ç¥¨åç§°'],
                    'é¢„æµ‹æ¦‚ç‡': prob,
                    'é¢„æµ‹ä»·æ ¼': pred_price,
                    'å®é™…ä»·æ ¼': actual_price,
                    'æ”¶ç›Šç‡%': return_pct,
                    'æ˜¯å¦ä¸Šæ¶¨': 1 if return_pct > 0 else 0,
                    'æ˜¯å¦å¤§æ¶¨': 1 if return_pct > 10 else 0,
                })
        except Exception as e:
            log.warning(f"è·å– {ts_code} æ•°æ®å¤±è´¥: {e}")
            continue
        
        if (idx + 1) % 10 == 0:
            log.info(f"  è¿›åº¦: {idx+1}/{len(df_pred_top)}")
    
    if not results:
        log.error("æœªè·å–åˆ°ä»»ä½•å®é™…æ•°æ®")
        return
    
    df_results = pd.DataFrame(results)
    log.info(f"âœ“ æˆåŠŸè·å–: {len(df_results)} åªè‚¡ç¥¨çš„å®é™…æ•°æ®")
    
    # 3. åˆ†æé¢„æµ‹æ•ˆæœ
    log.info("\n" + "=" * 70)
    log.info("ã€é¢„æµ‹æ•ˆæœåˆ†æã€‘")
    log.info("=" * 70)
    
    # æ•´ä½“ç»Ÿè®¡
    log.info(f"\nğŸ“ˆ Top {top_n} æ•´ä½“è¡¨ç°ï¼š")
    log.info(f"  å¹³å‡æ”¶ç›Šç‡: {df_results['æ”¶ç›Šç‡%'].mean():.2f}%")
    log.info(f"  ä¸­ä½æ•°æ”¶ç›Šç‡: {df_results['æ”¶ç›Šç‡%'].median():.2f}%")
    log.info(f"  ä¸Šæ¶¨ç‡: {df_results['æ˜¯å¦ä¸Šæ¶¨'].mean()*100:.1f}%")
    log.info(f"  å¤§æ¶¨ç‡(>10%): {df_results['æ˜¯å¦å¤§æ¶¨'].mean()*100:.1f}%")
    log.info(f"  æœ€å¤§æ¶¨å¹…: {df_results['æ”¶ç›Šç‡%'].max():.2f}%")
    log.info(f"  æœ€å¤§è·Œå¹…: {df_results['æ”¶ç›Šç‡%'].min():.2f}%")
    log.info(f"  æ­£æ”¶ç›Šè‚¡ç¥¨æ•°: {(df_results['æ”¶ç›Šç‡%'] > 0).sum()}")
    log.info(f"  è´Ÿæ”¶ç›Šè‚¡ç¥¨æ•°: {(df_results['æ”¶ç›Šç‡%'] < 0).sum()}")
    
    # Top 10åˆ†æ
    if len(df_results) >= 10:
        log.info(f"\nğŸ¥‡ Top 10 è¡¨ç°ï¼š")
        top10 = df_results.nlargest(10, 'é¢„æµ‹æ¦‚ç‡')
        log.info(f"  å¹³å‡æ”¶ç›Šç‡: {top10['æ”¶ç›Šç‡%'].mean():.2f}%")
        log.info(f"  ä¸Šæ¶¨ç‡: {top10['æ˜¯å¦ä¸Šæ¶¨'].mean()*100:.1f}%")
        log.info(f"  å¤§æ¶¨ç‡(>10%): {top10['æ˜¯å¦å¤§æ¶¨'].mean()*100:.1f}%")
    
    # æŒ‰æ¦‚ç‡åŒºé—´åˆ†æ
    df_results['æ¦‚ç‡åŒºé—´'] = pd.cut(df_results['é¢„æµ‹æ¦‚ç‡'], 
                                bins=[0, 0.85, 0.90, 0.95, 1.0],
                                labels=['85-90%', '90-95%', '95-98%', 'â‰¥98%'])
    
    log.info(f"\nğŸ“Š æŒ‰é¢„æµ‹æ¦‚ç‡åˆ†ç»„è¡¨ç°ï¼š")
    group_stats = df_results.groupby('æ¦‚ç‡åŒºé—´').agg({
        'æ”¶ç›Šç‡%': ['count', 'mean', 'median'],
        'æ˜¯å¦ä¸Šæ¶¨': 'mean',
        'æ˜¯å¦å¤§æ¶¨': 'mean'
    }).round(2)
    
    for prob_range, stats in group_stats.iterrows():
        count = int(stats[('æ”¶ç›Šç‡%', 'count')])
        mean_return = stats[('æ”¶ç›Šç‡%', 'mean')]
        up_rate = stats[('æ˜¯å¦ä¸Šæ¶¨', 'mean')] * 100
        log.info(f"  {prob_range}: {count}åª, å¹³å‡æ”¶ç›Š{mean_return:.2f}%, ä¸Šæ¶¨ç‡{up_rate:.1f}%")
    
    # æœ€ä½³/æœ€å·®è¡¨ç°
    log.info(f"\nğŸ† æœ€ä½³è¡¨ç° Top 5ï¼š")
    best = df_results.nlargest(5, 'æ”¶ç›Šç‡%')
    for _, row in best.iterrows():
        log.info(f"  {row['è‚¡ç¥¨ä»£ç ']} {row['è‚¡ç¥¨åç§°']}: {row['æ”¶ç›Šç‡%']:.2f}% (é¢„æµ‹æ¦‚ç‡: {row['é¢„æµ‹æ¦‚ç‡']:.2%})")
    
    log.info(f"\nğŸ“‰ æœ€å·®è¡¨ç° Top 5ï¼š")
    worst = df_results.nsmallest(5, 'æ”¶ç›Šç‡%')
    for _, row in worst.iterrows():
        log.info(f"  {row['è‚¡ç¥¨ä»£ç ']} {row['è‚¡ç¥¨åç§°']}: {row['æ”¶ç›Šç‡%']:.2f}% (é¢„æµ‹æ¦‚ç‡: {row['é¢„æµ‹æ¦‚ç‡']:.2%})")
    
    # ä¿å­˜ç»“æœ
    output_file = PROJECT_ROOT / 'data' / 'prediction' / 'results' / f'prediction_analysis_{pred_date}_to_{actual_date}.csv'
    df_results.to_csv(output_file, index=False, encoding='utf-8-sig')
    log.success(f"\nâœ… è¯¦ç»†åˆ†æç»“æœå·²ä¿å­˜: {output_file}")
    
    return df_results


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='åˆ†æé¢„æµ‹æ•ˆæœ')
    parser.add_argument('--pred-date', type=str, required=True, help='é¢„æµ‹æ—¥æœŸ (YYYYMMDD)')
    parser.add_argument('--actual-date', type=str, required=True, help='å®é™…æ—¥æœŸ (YYYYMMDD)')
    parser.add_argument('--top-n', type=int, default=50, help='åˆ†æTop Nåªè‚¡ç¥¨ (é»˜è®¤50)')
    
    args = parser.parse_args()
    
    analyze_prediction(args.pred_date, args.actual_date, args.top_n)
