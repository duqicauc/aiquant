#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é¢„æµ‹æ•ˆæœå›é¡¾è„šæœ¬
è·Ÿè¸ªå†å²é¢„æµ‹çš„å®é™…è¡¨ç°ï¼Œè®¡ç®—èƒœç‡å’Œæ”¶ç›Š
"""

import os
import sys
import json
import argparse
from datetime import datetime, timedelta
from pathlib import Path
import pandas as pd
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.utils.logger import log
from src.data.data_manager import DataManager


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='é¢„æµ‹æ•ˆæœå›é¡¾')
    parser.add_argument('--period', type=str, default='1w',
                       help='å›é¡¾å‘¨æœŸ: 1w(1å‘¨), 2w(2å‘¨), 4w(4å‘¨), 6w(6å‘¨)')
    parser.add_argument('--prediction_date', type=str, default=None,
                       help='é¢„æµ‹æ—¥æœŸ (æ ¼å¼: YYYYMMDD)ï¼Œé»˜è®¤æœ€æ–°é¢„æµ‹')
    parser.add_argument('--top_n', type=int, default=50,
                       help='å›é¡¾Top Næ¨è')
    return parser.parse_args()


def get_latest_prediction():
    """è·å–æœ€æ–°çš„é¢„æµ‹è®°å½•"""
    index_file = project_root / 'data' / 'predictions' / 'index.json'
    
    if not index_file.exists():
        log.error("é¢„æµ‹ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        return None
    
    with open(index_file, 'r', encoding='utf-8') as f:
        index = json.load(f)
    
    if not index['predictions']:
        log.error("æ²¡æœ‰æ‰¾åˆ°é¢„æµ‹è®°å½•ï¼")
        return None
    
    return index['predictions'][0]  # æœ€æ–°çš„é¢„æµ‹


def load_prediction_data(prediction_date):
    """åŠ è½½é¢„æµ‹æ•°æ®"""
    pred_dir = project_root / 'data' / 'predictions' / prediction_date
    
    if not pred_dir.exists():
        log.error(f"é¢„æµ‹ç›®å½•ä¸å­˜åœ¨: {pred_dir}")
        return None
    
    # æŸ¥æ‰¾ top stocks æ–‡ä»¶
    import glob
    top_files = glob.glob(str(pred_dir / 'top_*.csv'))
    
    if not top_files:
        log.error(f"æ‰¾ä¸åˆ°æ¨èè‚¡ç¥¨æ–‡ä»¶: {pred_dir}")
        return None
    
    df = pd.read_csv(top_files[0])
    log.info(f"åŠ è½½é¢„æµ‹æ•°æ®: {len(df)} åªè‚¡ç¥¨")
    
    return df


def calculate_returns(df_predictions, period_weeks):
    """è®¡ç®—å®é™…æ”¶ç›Š"""
    log.info(f"\nè®¡ç®— {period_weeks} å‘¨æ”¶ç›Š...")
    
    dm = DataManager()
    
    results = []
    
    for idx, row in df_predictions.iterrows():
        stock_code = row['è‚¡ç¥¨ä»£ç ']
        stock_name = row['è‚¡ç¥¨åç§°']
        pred_price = row['æœ€æ–°ä»·æ ¼']
        pred_date = row['æ•°æ®æ—¥æœŸ']
        probability = row['ç‰›è‚¡æ¦‚ç‡']
        
        # è®¡ç®—ç»“æŸæ—¥æœŸ
        pred_dt = pd.to_datetime(pred_date)
        end_dt = pred_dt + timedelta(weeks=period_weeks)
        end_date = end_dt.strftime('%Y%m%d')
        
        try:
            # è·å–æœŸé—´æ•°æ®
            data = dm.get_daily_data(
                stock_code=stock_code,
                start_date=pred_date.replace('-', ''),
                end_date=end_date
            )
            
            if data is None or len(data) == 0:
                log.warning(f"  {stock_name} æ— æ•°æ®")
                continue
            
            # è®¡ç®—æ”¶ç›Š
            start_price = data.iloc[0]['close']
            end_price = data.iloc[-1]['close']
            actual_return = (end_price - start_price) / start_price * 100
            
            # è®¡ç®—æœŸé—´æœ€é«˜å’Œæœ€ä½
            max_price = data['high'].max()
            min_price = data['low'].min()
            max_return = (max_price - start_price) / start_price * 100
            max_drawdown = (min_price - start_price) / start_price * 100
            
            results.append({
                'è‚¡ç¥¨ä»£ç ': stock_code,
                'è‚¡ç¥¨åç§°': stock_name,
                'é¢„æµ‹æ¦‚ç‡': probability,
                'é¢„æµ‹ä»·æ ¼': pred_price,
                'æœŸåˆä»·æ ¼': start_price,
                'æœŸæœ«ä»·æ ¼': end_price,
                'å®é™…æ”¶ç›Š%': actual_return,
                'æœŸé—´æœ€é«˜æ”¶ç›Š%': max_return,
                'æœŸé—´æœ€å¤§å›æ’¤%': max_drawdown,
                'æ˜¯å¦ç›ˆåˆ©': actual_return > 0,
                'æ•°æ®æ—¥æœŸ': pred_date,
                'äº¤æ˜“å¤©æ•°': len(data)
            })
            
            if (idx + 1) % 10 == 0:
                log.info(f"  è¿›åº¦: {idx+1}/{len(df_predictions)}")
                
        except Exception as e:
            log.warning(f"  {stock_name} å¤„ç†å¤±è´¥: {e}")
            continue
    
    df_results = pd.DataFrame(results)
    log.success(f"âœ“ æˆåŠŸè®¡ç®— {len(df_results)} åªè‚¡ç¥¨çš„æ”¶ç›Š")
    
    return df_results


def analyze_performance(df_results, period_weeks):
    """åˆ†æé¢„æµ‹è¡¨ç°"""
    log.info("="*80)
    log.info("ğŸ“Š é¢„æµ‹æ•ˆæœåˆ†æ")
    log.info("="*80)
    
    if len(df_results) == 0:
        log.error("æ²¡æœ‰å¯åˆ†æçš„æ•°æ®ï¼")
        return None
    
    analysis = {}
    
    # 1. æ•´ä½“æ”¶ç›Šç»Ÿè®¡
    analysis['æ€»ä½“è¡¨ç°'] = {
        'è¯„ä¼°è‚¡ç¥¨æ•°': len(df_results),
        'å¹³å‡æ”¶ç›Š%': df_results['å®é™…æ”¶ç›Š%'].mean(),
        'ä¸­ä½æ•°æ”¶ç›Š%': df_results['å®é™…æ”¶ç›Š%'].median(),
        'æœ€å¤§æ”¶ç›Š%': df_results['å®é™…æ”¶ç›Š%'].max(),
        'æœ€å¤§äºæŸ%': df_results['å®é™…æ”¶ç›Š%'].min(),
        'æ”¶ç›Šæ ‡å‡†å·®%': df_results['å®é™…æ”¶ç›Š%'].std(),
    }
    
    # 2. èƒœç‡ç»Ÿè®¡
    win_count = (df_results['å®é™…æ”¶ç›Š%'] > 0).sum()
    total_count = len(df_results)
    win_rate = win_count / total_count * 100
    
    analysis['èƒœç‡ç»Ÿè®¡'] = {
        'ç›ˆåˆ©è‚¡ç¥¨æ•°': int(win_count),
        'äºæŸè‚¡ç¥¨æ•°': int(total_count - win_count),
        'æ•´ä½“èƒœç‡%': win_rate,
    }
    
    # 3. åˆ†æ¦‚ç‡åŒºé—´ç»Ÿè®¡
    df_results['æ¦‚ç‡åŒºé—´'] = pd.cut(
        df_results['é¢„æµ‹æ¦‚ç‡'],
        bins=[0, 0.7, 0.8, 0.9, 1.0],
        labels=['<70%', '70-80%', '80-90%', '>90%']
    )
    
    group_stats = []
    for prob_range, group in df_results.groupby('æ¦‚ç‡åŒºé—´'):
        group_stats.append({
            'æ¦‚ç‡åŒºé—´': prob_range,
            'æ•°é‡': len(group),
            'èƒœç‡%': (group['å®é™…æ”¶ç›Š%'] > 0).sum() / len(group) * 100,
            'å¹³å‡æ”¶ç›Š%': group['å®é™…æ”¶ç›Š%'].mean(),
        })
    
    analysis['åˆ†å±‚è¡¨ç°'] = group_stats
    
    # 4. é£é™©æŒ‡æ ‡
    returns = df_results['å®é™…æ”¶ç›Š%'].values / 100
    sharpe_ratio = np.mean(returns) / np.std(returns) * np.sqrt(52/period_weeks) if np.std(returns) > 0 else 0
    
    analysis['é£é™©æŒ‡æ ‡'] = {
        'å¤æ™®æ¯”ç‡': sharpe_ratio,
        'å¹³å‡æœ€å¤§å›æ’¤%': df_results['æœŸé—´æœ€å¤§å›æ’¤%'].mean(),
    }
    
    return analysis


def generate_review_report(prediction_date, period_weeks, df_results, analysis):
    """ç”Ÿæˆå›é¡¾æŠ¥å‘Š"""
    report = []
    report.append("="*80)
    report.append("ğŸ“Š é¢„æµ‹æ•ˆæœå›é¡¾æŠ¥å‘Š")
    report.append("="*80)
    
    # è®¡ç®—å›é¡¾æ—¥æœŸèŒƒå›´
    pred_dt = pd.to_datetime(prediction_date)
    end_dt = pred_dt + timedelta(weeks=period_weeks)
    
    report.append(f"\nğŸ“… é¢„æµ‹æ—¥æœŸ: {pred_dt.strftime('%Yå¹´%mæœˆ%dæ—¥')}")
    report.append(f"â±ï¸  å›é¡¾å‘¨æœŸ: {period_weeks}å‘¨ ({pred_dt.strftime('%Y-%m-%d')} è‡³ {end_dt.strftime('%Y-%m-%d')})")
    report.append(f"ğŸ“ˆ è¯„ä¼°è‚¡ç¥¨: {len(df_results)} åª")
    
    # ä¸€ã€æ•´ä½“è¡¨ç°
    report.append("\n" + "="*80)
    report.append("ä¸€ã€æ•´ä½“è¡¨ç°")
    report.append("="*80)
    
    overall = analysis['æ€»ä½“è¡¨ç°']
    report.append(f"\n1. æ”¶ç›Šç»Ÿè®¡")
    report.append(f"   - å¹³å‡æ”¶ç›Šç‡: {overall['å¹³å‡æ”¶ç›Š%']:+.2f}%")
    report.append(f"   - ä¸­ä½æ•°æ”¶ç›Šç‡: {overall['ä¸­ä½æ•°æ”¶ç›Š%']:+.2f}%")
    report.append(f"   - æœ€å¤§æ”¶ç›Š: {overall['æœ€å¤§æ”¶ç›Š%']:+.2f}%")
    report.append(f"   - æœ€å¤§äºæŸ: {overall['æœ€å¤§äºæŸ%']:+.2f}%")
    report.append(f"   - æ”¶ç›Šæ³¢åŠ¨ç‡: {overall['æ”¶ç›Šæ ‡å‡†å·®%']:.2f}%")
    
    winrate = analysis['èƒœç‡ç»Ÿè®¡']
    report.append(f"\n2. èƒœç‡ç»Ÿè®¡")
    report.append(f"   - æ•´ä½“èƒœç‡: {winrate['æ•´ä½“èƒœç‡%']:.1f}% ({winrate['ç›ˆåˆ©è‚¡ç¥¨æ•°']}/{winrate['ç›ˆåˆ©è‚¡ç¥¨æ•°'] + winrate['äºæŸè‚¡ç¥¨æ•°']})")
    report.append(f"   - ç›ˆåˆ©è‚¡ç¥¨: {winrate['ç›ˆåˆ©è‚¡ç¥¨æ•°']} åª")
    report.append(f"   - äºæŸè‚¡ç¥¨: {winrate['äºæŸè‚¡ç¥¨æ•°']} åª")
    
    risk = analysis['é£é™©æŒ‡æ ‡']
    report.append(f"\n3. é£é™©æŒ‡æ ‡")
    report.append(f"   - å¤æ™®æ¯”ç‡: {risk['å¤æ™®æ¯”ç‡']:.2f}")
    report.append(f"   - å¹³å‡æœ€å¤§å›æ’¤: {risk['å¹³å‡æœ€å¤§å›æ’¤%']:.2f}%")
    
    # äºŒã€åˆ†å±‚è¡¨ç°
    report.append("\n" + "="*80)
    report.append("äºŒã€åˆ†å±‚è¡¨ç°åˆ†æ")
    report.append("="*80)
    
    report.append(f"\n{'æ¦‚ç‡åŒºé—´':<12} {'æ•°é‡':<8} {'èƒœç‡':<12} {'å¹³å‡æ”¶ç›Š':<12}")
    report.append("-"*50)
    
    for stat in analysis['åˆ†å±‚è¡¨ç°']:
        report.append(
            f"{stat['æ¦‚ç‡åŒºé—´']:<12} {stat['æ•°é‡']:<8} "
            f"{stat['èƒœç‡%']:<11.1f}% {stat['å¹³å‡æ”¶ç›Š%']:<11.2f}%"
        )
    
    # ä¸‰ã€Top 10 è¡¨ç°å›é¡¾
    report.append("\n" + "="*80)
    report.append("ä¸‰ã€Top 10 è¡¨ç°å›é¡¾")
    report.append("="*80)
    
    df_top10 = df_results.head(10).copy()
    
    for i, row in df_top10.iterrows():
        status = "âœ…" if row['å®é™…æ”¶ç›Š%'] > 0 else "âŒ"
        report.append(f"\nã€ç¬¬ {i+1} åã€‘{row['è‚¡ç¥¨åç§°']}ï¼ˆ{row['è‚¡ç¥¨ä»£ç ']}ï¼‰")
        report.append(f"  é¢„æµ‹æ¦‚ç‡: {row['é¢„æµ‹æ¦‚ç‡']*100:.2f}%")
        report.append(f"  é¢„æµ‹ä»·æ ¼: {row['é¢„æµ‹ä»·æ ¼']:.2f}")
        report.append(f"  æœŸæœ«ä»·æ ¼: {row['æœŸæœ«ä»·æ ¼']:.2f}")
        report.append(f"  å®é™…æ”¶ç›Š: {row['å®é™…æ”¶ç›Š%']:+.2f}% {status}")
        
        if row['å®é™…æ”¶ç›Š%'] > 10:
            comment = "è¡¨ç°ä¼˜ç§€ï¼Œè¶…é¢„æœŸ"
        elif row['å®é™…æ”¶ç›Š%'] > 5:
            comment = "è¡¨ç°è‰¯å¥½ï¼Œç¬¦åˆé¢„æœŸ"
        elif row['å®é™…æ”¶ç›Š%'] > 0:
            comment = "å°å¹…ç›ˆåˆ©"
        elif row['å®é™…æ”¶ç›Š%'] > -10:
            comment = "å°å¹…äºæŸ"
        else:
            comment = "è¡¨ç°ä¸ä½³"
        
        report.append(f"  è¯„ä»·: {comment}")
    
    # å››ã€æ¨¡å‹è¯„ä¼°
    report.append("\n" + "="*80)
    report.append("å››ã€æ¨¡å‹è¯„ä¼°")
    report.append("="*80)
    
    # æ£€æŸ¥æ¨¡å‹æ ¡å‡†åº¦
    if overall['å¹³å‡æ”¶ç›Š%'] > 5 and winrate['æ•´ä½“èƒœç‡%'] > 60:
        report.append("\nâœ… æ¨¡å‹è¡¨ç°ä¼˜ç§€")
        report.append("   - å¹³å‡æ”¶ç›Šå’Œèƒœç‡éƒ½è¾¾åˆ°é¢„æœŸç›®æ ‡")
        report.append("   - å»ºè®®ç»§ç»­ä½¿ç”¨å½“å‰æ¨¡å‹")
    elif overall['å¹³å‡æ”¶ç›Š%'] > 3 and winrate['æ•´ä½“èƒœç‡%'] > 55:
        report.append("\nâœ… æ¨¡å‹è¡¨ç°è‰¯å¥½")
        report.append("   - è¡¨ç°åŸºæœ¬ç¬¦åˆé¢„æœŸ")
        report.append("   - å¯ç»§ç»­è§‚å¯Ÿåç»­è¡¨ç°")
    else:
        report.append("\nâš ï¸  æ¨¡å‹è¡¨ç°éœ€è¦æ”¹è¿›")
        report.append("   - å¹³å‡æ”¶ç›Šæˆ–èƒœç‡ä½äºé¢„æœŸ")
        report.append("   - å»ºè®®æ£€æŸ¥æ¨¡å‹å¹¶è€ƒè™‘é‡æ–°è®­ç»ƒ")
    
    # æ£€æŸ¥æ¦‚ç‡æ ¡å‡†
    layered = analysis['åˆ†å±‚è¡¨ç°']
    high_prob_group = [g for g in layered if g['æ¦‚ç‡åŒºé—´'] == '>90%']
    if high_prob_group and high_prob_group[0]['èƒœç‡%'] > 70:
        report.append("\nâœ… æ¨¡å‹æ ¡å‡†åº¦è‰¯å¥½")
        report.append("   - é«˜æ¦‚ç‡è‚¡ç¥¨ç¡®å®è¡¨ç°æ›´å¥½")
    else:
        report.append("\nâš ï¸  æ¨¡å‹æ ¡å‡†åº¦æœ‰å¾…æå‡")
        report.append("   - æ¦‚ç‡ä¸å®é™…è¡¨ç°ç›¸å…³æ€§ä¸å¼º")
    
    # äº”ã€æ”¹è¿›å»ºè®®
    report.append("\n" + "="*80)
    report.append("äº”ã€æ”¹è¿›å»ºè®®")
    report.append("="*80)
    
    report.append("\n1. é€‰è‚¡ç­–ç•¥")
    if high_prob_group and high_prob_group[0]['æ•°é‡'] > 5:
        report.append(f"   ğŸ’¡ é‡ç‚¹å…³æ³¨æ¦‚ç‡>{high_prob_group[0]['æ¦‚ç‡åŒºé—´']}çš„è‚¡ç¥¨")
    report.append("   ğŸ’¡ ç»“åˆåŸºæœ¬é¢å’ŒæŠ€æœ¯é¢è¿›è¡ŒäºŒæ¬¡ç­›é€‰")
    
    report.append("\n2. é£æ§å»ºè®®")
    if abs(overall['æœ€å¤§äºæŸ%']) > 15:
        report.append("   âš ï¸  å­˜åœ¨è¾ƒå¤§å•è‚¡äºæŸï¼Œå»ºè®®ä¸¥æ ¼æ‰§è¡Œæ­¢æŸ")
    report.append(f"   ğŸ’¡ å»ºè®®æ­¢æŸç‚¹: -15%")
    report.append(f"   ğŸ’¡ å»ºè®®æ­¢ç›ˆç‚¹: +{max(20, overall['å¹³å‡æ”¶ç›Š%']*2):.0f}%")
    
    report.append("\n3. ä»“ä½ç®¡ç†")
    report.append("   ğŸ’¡ å•è‚¡ä»“ä½ä¸è¶…è¿‡5-10%")
    report.append("   ğŸ’¡ ä¼˜å…ˆé…ç½®é«˜æ¦‚ç‡è‚¡ç¥¨")
    
    # ç»“æŸ
    report.append("\n" + "="*80)
    report.append("æŠ¥å‘Šç»“æŸ")
    report.append("="*80)
    
    return "\n".join(report)


def save_review_results(prediction_date, period_weeks, df_results, report_content):
    """ä¿å­˜å›é¡¾ç»“æœ"""
    # åˆ›å»ºå›é¡¾ç›®å½•
    review_dir = project_root / 'data' / 'reviews'
    review_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜è¯¦ç»†ç»“æœCSV
    csv_file = review_dir / f'review_{prediction_date}_{period_weeks}w_detail.csv'
    df_results.to_csv(csv_file, index=False, encoding='utf-8-sig')
    log.success(f"âœ“ è¯¦ç»†ç»“æœå·²ä¿å­˜: {csv_file}")
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = review_dir / f'review_{prediction_date}_{period_weeks}w.txt'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    log.success(f"âœ“ å›é¡¾æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    # æ‰“å°æŠ¥å‘Š
    log.info("\n" + report_content)
    
    return csv_file, report_file


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    log.info("="*80)
    log.info("ğŸ“Š å¼€å§‹é¢„æµ‹æ•ˆæœå›é¡¾")
    log.info("="*80)
    
    # è§£æå‘¨æœŸ
    period_map = {'1w': 1, '2w': 2, '4w': 4, '6w': 6}
    period_weeks = period_map.get(args.period, 1)
    
    log.info(f"å›é¡¾å‘¨æœŸ: {period_weeks} å‘¨")
    
    # è·å–é¢„æµ‹æ—¥æœŸ
    if args.prediction_date:
        prediction_date = args.prediction_date
    else:
        latest = get_latest_prediction()
        if not latest:
            log.error("æ— æ³•è·å–é¢„æµ‹è®°å½•ï¼")
            return
        prediction_date = latest['date']
    
    log.info(f"é¢„æµ‹æ—¥æœŸ: {prediction_date}")
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»è¿‡å»è¶³å¤Ÿçš„æ—¶é—´
    pred_dt = datetime.strptime(prediction_date, '%Y%m%d')
    days_passed = (datetime.now() - pred_dt).days
    
    if days_passed < period_weeks * 7:
        log.warning(f"âš ï¸  è·ç¦»é¢„æµ‹æ—¥æœŸä»…è¿‡å» {days_passed} å¤©ï¼Œå¯èƒ½æ•°æ®ä¸å®Œæ•´")
        log.warning(f"   å»ºè®®ç­‰å¾… {period_weeks * 7} å¤©åå†è¿›è¡Œå›é¡¾")
        response = input("æ˜¯å¦ç»§ç»­? (y/n): ")
        if response.lower() != 'y':
            log.info("å·²å–æ¶ˆ")
            return
    
    # åŠ è½½é¢„æµ‹æ•°æ®
    df_predictions = load_prediction_data(prediction_date)
    if df_predictions is None:
        return
    
    # é™åˆ¶Top N
    df_predictions = df_predictions.head(args.top_n)
    
    # è®¡ç®—å®é™…æ”¶ç›Š
    df_results = calculate_returns(df_predictions, period_weeks)
    if len(df_results) == 0:
        log.error("æ— æ³•è®¡ç®—æ”¶ç›Šï¼")
        return
    
    # åˆ†æè¡¨ç°
    analysis = analyze_performance(df_results, period_weeks)
    if not analysis:
        return
    
    # ç”ŸæˆæŠ¥å‘Š
    report_content = generate_review_report(
        prediction_date, period_weeks, df_results, analysis
    )
    
    # ä¿å­˜ç»“æœ
    save_review_results(prediction_date, period_weeks, df_results, report_content)
    
    log.success("\nâœ… é¢„æµ‹æ•ˆæœå›é¡¾å®Œæˆï¼")


if __name__ == '__main__':
    main()

