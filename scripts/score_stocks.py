#!/usr/bin/env python3
"""
è‚¡ç¥¨è¯„åˆ†è„šæœ¬ - ä½¿ç”¨æ–°ç‰ˆæ¨¡å‹æ¡†æ¶

åŠŸèƒ½ï¼š
- ä½¿ç”¨æ–°ç‰ˆæ¨¡å‹ç”Ÿå‘½å‘¨æœŸç®¡ç†æ¡†æ¶
- æ”¯æŒæŒ‡å®šæ¨¡å‹ç‰ˆæœ¬æˆ–ä½¿ç”¨å½“å‰ç”Ÿäº§ç‰ˆæœ¬
- æ”¯æŒå†å²å›æµ‹ï¼ˆæŒ‡å®šæ—¥æœŸï¼‰
- ç”Ÿæˆè¯¦ç»†é¢„æµ‹æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
    # ä½¿ç”¨å½“å‰ç”Ÿäº§ç‰ˆæœ¬è¯„åˆ†
    python scripts/score_stocks.py
    
    # ä½¿ç”¨æŒ‡å®šç‰ˆæœ¬è¯„åˆ†
    python scripts/score_stocks.py --version v1.4.0
    
    # å†å²å›æµ‹ï¼ˆæŒ‡å®šæ—¥æœŸï¼‰
    python scripts/score_stocks.py --date 20250919
    
    # é™åˆ¶è¯„åˆ†æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    python scripts/score_stocks.py --max-stocks 100
    
    # æŒ‡å®šæ¨¡å‹
    python scripts/score_stocks.py --model breakout_launch_scorer
"""
import sys
import os
import argparse
import json
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import xgboost as xgb

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.data.data_manager import DataManager
from src.models.lifecycle.iterator import ModelIterator
from src.utils.logger import log


class StockScorer:
    """è‚¡ç¥¨è¯„åˆ†å™¨ï¼ˆä½¿ç”¨æ–°æ¡†æ¶ï¼‰"""
    
    def __init__(self, model_name: str = "breakout_launch_scorer"):
        self.model_name = model_name
        self.iterator = ModelIterator(model_name)
        self.dm = DataManager()
        self.model = None
        self.version = None
        self.feature_names = None
    
    def load_model(self, version: str = None):
        """
        åŠ è½½æ¨¡å‹
        
        Args:
            version: ç‰ˆæœ¬å·ï¼ŒNone è¡¨ç¤ºä½¿ç”¨ç”Ÿäº§ç‰ˆæœ¬æˆ–æœ€æ–°ç‰ˆæœ¬
        """
        # ç¡®å®šç‰ˆæœ¬
        if version is None:
            # ä¼˜å…ˆä½¿ç”¨ç”Ÿäº§ç‰ˆæœ¬
            version = self.iterator.get_current_version('production')
            if version is None:
                version = self.iterator.get_latest_version()
        
        if version is None:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹ç‰ˆæœ¬")
        
        self.version = version
        
        # åŠ è½½æ¨¡å‹
        model_path = self.iterator.get_model_path(version)
        if not model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        
        log.info(f"åŠ è½½æ¨¡å‹: {self.model_name} ç‰ˆæœ¬: {version}")
        
        self.model = xgb.Booster()
        self.model.load_model(str(model_path))
        
        # åŠ è½½ç‰¹å¾åç§°
        feature_names_file = model_path.parent / "feature_names.json"
        if feature_names_file.exists():
            with open(feature_names_file, 'r', encoding='utf-8') as f:
                self.feature_names = json.load(f)
            log.success(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸï¼Œç‰¹å¾æ•°: {len(self.feature_names)}")
        else:
            log.warning("âš ï¸ æœªæ‰¾åˆ°ç‰¹å¾åç§°æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤ç‰¹å¾é¡ºåº")
            self.feature_names = self._get_default_feature_names()
        
        return self
    
    def _get_default_feature_names(self):
        """è·å–é»˜è®¤ç‰¹å¾åç§°"""
        return [
            'close_mean', 'close_std', 'close_max', 'close_min', 'close_trend',
            'pct_chg_mean', 'pct_chg_std', 'pct_chg_sum',
            'positive_days', 'negative_days', 'max_gain', 'max_loss',
            'volume_ratio_mean', 'volume_ratio_max', 'volume_ratio_gt_2', 'volume_ratio_gt_4',
            'macd_mean', 'macd_positive_days', 'macd_max',
            'ma5_mean', 'price_above_ma5', 'ma10_mean', 'price_above_ma10',
            'total_mv_mean', 'circ_mv_mean',
            'return_1w', 'return_2w'
        ]
    
    def get_valid_stocks(self, target_date: datetime = None):
        """è·å–æœ‰æ•ˆè‚¡ç¥¨åˆ—è¡¨"""
        log.info("="*80)
        log.info("è·å–è‚¡ç¥¨åˆ—è¡¨")
        log.info("="*80)
        
        stock_list = self.dm.get_stock_list()
        log.info(f"âœ“ è·å–åˆ° {len(stock_list)} åªè‚¡ç¥¨")
        
        if target_date is None:
            target_date = datetime.now()
        
        excluded = {'st': 0, 'new': 0, 'delisted': 0, 'bj': 0}
        valid_stocks = []
        
        for _, stock in stock_list.iterrows():
            ts_code = stock['ts_code']
            name = stock['name']
            
            # æ’é™¤è§„åˆ™
            if 'ST' in name or 'st' in name.lower() or '*' in name:
                excluded['st'] += 1
                continue
            
            if 'é€€' in name:
                excluded['delisted'] += 1
                continue
            
            if ts_code.endswith('.BJ'):
                excluded['bj'] += 1
                continue
            
            # æ£€æŸ¥ä¸Šå¸‚å¤©æ•°
            list_date = stock.get('list_date', '')
            if list_date:
                try:
                    days = (target_date - pd.to_datetime(list_date)).days
                    if days < 120:
                        excluded['new'] += 1
                        continue
                except:
                    pass
            
            valid_stocks.append(stock)
        
        log.info(f"\nå‰”é™¤ç»Ÿè®¡: ST={excluded['st']}, æ¬¡æ–°={excluded['new']}, "
                f"é€€å¸‚={excluded['delisted']}, åŒ—äº¤æ‰€={excluded['bj']}")
        log.info(f"âœ“ ç¬¦åˆæ¡ä»¶: {len(valid_stocks)} åª")
        
        return pd.DataFrame(valid_stocks)
    
    def extract_features(self, ts_code: str, name: str, 
                        target_date: datetime = None, lookback_days: int = 34):
        """æå–è‚¡ç¥¨ç‰¹å¾"""
        try:
            if target_date is None:
                target_date = datetime.now()
            
            end_date = target_date.strftime('%Y%m%d')
            start_date = (target_date - timedelta(days=lookback_days * 2)).strftime('%Y%m%d')
            
            df = self.dm.get_daily_data(
                stock_code=ts_code,
                start_date=start_date,
                end_date=end_date
            )
            
            if df is None or len(df) < 20:
                return None
            
            df = df.tail(lookback_days).sort_values('trade_date')
            if len(df) < 20:
                return None
            
            # è½¬æ¢æ•°å€¼ç±»å‹
            for col in ['close', 'pct_chg', 'vol']:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            features = {
                'ts_code': ts_code,
                'name': name,
                'latest_date': df['trade_date'].iloc[-1],
                'latest_close': df['close'].iloc[-1],
            }
            
            # ä»·æ ¼ç‰¹å¾
            features['close_mean'] = df['close'].mean()
            features['close_std'] = df['close'].std()
            features['close_max'] = df['close'].max()
            features['close_min'] = df['close'].min()
            features['close_trend'] = (df['close'].iloc[-1] - df['close'].iloc[0]) / df['close'].iloc[0] * 100
            
            # æ¶¨è·Œå¹…ç‰¹å¾
            features['pct_chg_mean'] = df['pct_chg'].mean()
            features['pct_chg_std'] = df['pct_chg'].std()
            features['pct_chg_sum'] = df['pct_chg'].sum()
            features['positive_days'] = (df['pct_chg'] > 0).sum()
            features['negative_days'] = (df['pct_chg'] < 0).sum()
            features['max_gain'] = df['pct_chg'].max()
            features['max_loss'] = df['pct_chg'].min()
            
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            if 'ma5' not in df.columns:
                df['ma5'] = df['close'].rolling(window=5, min_periods=1).mean()
            if 'ma10' not in df.columns:
                df['ma10'] = df['close'].rolling(window=10, min_periods=1).mean()
            
            if 'volume_ratio' not in df.columns:
                df['vol_ma5'] = df['vol'].rolling(window=5, min_periods=1).mean()
                df['volume_ratio'] = df['vol'] / df['vol_ma5']
            
            if 'macd' not in df.columns:
                ema12 = df['close'].ewm(span=12, adjust=False).mean()
                ema26 = df['close'].ewm(span=26, adjust=False).mean()
                df['macd'] = (ema12 - ema26 - (ema12 - ema26).ewm(span=9, adjust=False).mean()) * 2
            
            # é‡æ¯”ç‰¹å¾
            if 'volume_ratio' in df.columns:
                features['volume_ratio_mean'] = df['volume_ratio'].mean()
                features['volume_ratio_max'] = df['volume_ratio'].max()
                features['volume_ratio_gt_2'] = (df['volume_ratio'] > 2).sum()
                features['volume_ratio_gt_4'] = (df['volume_ratio'] > 4).sum()
            
            # MACDç‰¹å¾
            if 'macd' in df.columns:
                macd_data = df['macd'].dropna()
                if len(macd_data) > 0:
                    features['macd_mean'] = macd_data.mean()
                    features['macd_positive_days'] = (macd_data > 0).sum()
                    features['macd_max'] = macd_data.max()
            
            # MAç‰¹å¾
            if 'ma5' in df.columns:
                features['ma5_mean'] = df['ma5'].mean()
                features['price_above_ma5'] = (df['close'] > df['ma5']).sum()
            if 'ma10' in df.columns:
                features['ma10_mean'] = df['ma10'].mean()
                features['price_above_ma10'] = (df['close'] > df['ma10']).sum()
            
            # å¸‚å€¼ç‰¹å¾
            if 'total_mv' in df.columns:
                mv = df['total_mv'].dropna()
                if len(mv) > 0:
                    features['total_mv_mean'] = mv.mean()
            if 'circ_mv' in df.columns:
                circ = df['circ_mv'].dropna()
                if len(circ) > 0:
                    features['circ_mv_mean'] = circ.mean()
            
            # åŠ¨é‡ç‰¹å¾
            days = len(df)
            if days >= 7:
                features['return_1w'] = (df['close'].iloc[-1] - df['close'].iloc[-7]) / df['close'].iloc[-7] * 100
            if days >= 14:
                features['return_2w'] = (df['close'].iloc[-1] - df['close'].iloc[-14]) / df['close'].iloc[-14] * 100
            
            return features
            
        except Exception as e:
            return None
    
    def score_stocks(self, stocks: pd.DataFrame, target_date: datetime = None,
                    max_stocks: int = None):
        """å¯¹è‚¡ç¥¨è¿›è¡Œè¯„åˆ†"""
        log.info("="*80)
        log.info("å¼€å§‹è¯„åˆ†")
        log.info("="*80)
        
        if max_stocks:
            stocks = stocks.head(max_stocks)
            log.info(f"âš ï¸ æµ‹è¯•æ¨¡å¼ï¼šä»…è¯„åˆ†å‰ {max_stocks} åª")
        
        total = len(stocks)
        features_list = []
        stock_info = []
        stats = {'success': 0, 'no_data': 0, 'error': 0}
        
        # æ‰¹é‡æå–ç‰¹å¾
        for i, (_, stock) in enumerate(stocks.iterrows()):
            if (i + 1) % 100 == 0 or i == 0 or (i + 1) == total:
                log.info(f"è¿›åº¦: {i+1}/{total} ({(i+1)/total*100:.1f}%)")
            
            ts_code = stock['ts_code']
            name = stock['name']
            
            features = self.extract_features(ts_code, name, target_date)
            
            if features is None:
                stats['no_data'] += 1
                continue
            
            features_list.append(features)
            stock_info.append({'ts_code': ts_code, 'name': name, 'features': features})
            stats['success'] += 1
        
        log.info(f"\nç‰¹å¾æå–: æˆåŠŸ={stats['success']}, æ— æ•°æ®={stats['no_data']}")
        
        if not features_list:
            log.error("æ²¡æœ‰æˆåŠŸæå–ç‰¹å¾çš„è‚¡ç¥¨")
            return pd.DataFrame()
        
        # æ‰¹é‡é¢„æµ‹
        log.info("æ‰¹é‡é¢„æµ‹...")
        feature_vectors = []
        for features in features_list:
            vector = [features.get(name, 0) for name in self.feature_names]
            vector = [0 if pd.isna(v) else v for v in vector]
            feature_vectors.append(vector)
        
        dmatrix = xgb.DMatrix(feature_vectors, feature_names=self.feature_names)
        probabilities = self.model.predict(dmatrix)
        
        # æ„å»ºç»“æœ
        results = []
        for i, info in enumerate(stock_info):
            features = info['features']
            results.append({
                'è‚¡ç¥¨ä»£ç ': info['ts_code'],
                'è‚¡ç¥¨åç§°': info['name'],
                'ç‰›è‚¡æ¦‚ç‡': float(probabilities[i]),
                'æ•°æ®æ—¥æœŸ': features.get('latest_date', ''),
                'æœ€æ–°ä»·æ ¼': features.get('latest_close', 0),
                '34æ—¥æ¶¨å¹…%': round(features.get('close_trend', 0), 2),
                'ç´¯è®¡æ¶¨è·Œ%': round(features.get('pct_chg_sum', 0), 2),
                '1å‘¨æ¶¨å¹…%': round(features.get('return_1w', 0), 2),
                '2å‘¨æ¶¨å¹…%': round(features.get('return_2w', 0), 2),
            })
        
        df_results = pd.DataFrame(results)
        df_results = df_results.sort_values('ç‰›è‚¡æ¦‚ç‡', ascending=False).reset_index(drop=True)
        
        log.success(f"âœ“ è¯„åˆ†å®Œæˆ: {len(df_results)} åªè‚¡ç¥¨")
        
        return df_results
    
    def generate_report(self, df_scores: pd.DataFrame, top_n: int = 50,
                       target_date: datetime = None):
        """ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š"""
        if target_date is None:
            target_date = datetime.now()
        
        df_top = df_scores.head(top_n)
        
        report = []
        report.append("=" * 80)
        report.append("ğŸ“Š é‡åŒ–é€‰è‚¡é¢„æµ‹æŠ¥å‘Š")
        report.append("=" * 80)
        report.append(f"\nğŸ“… æŠ¥å‘Šæ—¶é—´: {target_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}")
        report.append(f"ğŸ¤– æ¨¡å‹: {self.model_name}")
        report.append(f"ğŸ“¦ ç‰ˆæœ¬: {self.version}")
        report.append(f"ğŸ“ˆ è¯„åˆ†è‚¡ç¥¨: {len(df_scores)} åª")
        report.append(f"ğŸ¯ æ¨èæ•°é‡: {top_n} åª")
        
        # æ¦‚ç‡åˆ†å¸ƒ
        report.append("\n" + "=" * 80)
        report.append("ä¸€ã€æ•´ä½“åˆ†æ")
        report.append("=" * 80)
        
        high = len(df_scores[df_scores['ç‰›è‚¡æ¦‚ç‡'] > 0.8])
        mid = len(df_scores[(df_scores['ç‰›è‚¡æ¦‚ç‡'] >= 0.6) & (df_scores['ç‰›è‚¡æ¦‚ç‡'] <= 0.8)])
        low = len(df_scores[df_scores['ç‰›è‚¡æ¦‚ç‡'] < 0.6])
        
        report.append(f"\næ¦‚ç‡åˆ†å¸ƒ:")
        report.append(f"  é«˜æ½œåŠ›(>80%): {high} åª ({high/len(df_scores)*100:.1f}%)")
        report.append(f"  ä¸­æ½œåŠ›(60-80%): {mid} åª ({mid/len(df_scores)*100:.1f}%)")
        report.append(f"  ä½æ½œåŠ›(<60%): {low} åª ({low/len(df_scores)*100:.1f}%)")
        
        # Top 10
        report.append("\n" + "=" * 80)
        report.append("äºŒã€Top 10 æ¨è")
        report.append("=" * 80)
        
        for i, row in df_top.head(10).iterrows():
            report.append(f"\nã€ç¬¬ {i+1} åã€‘{row['è‚¡ç¥¨åç§°']}ï¼ˆ{row['è‚¡ç¥¨ä»£ç ']}ï¼‰")
            report.append(f"  ğŸ¯ ç‰›è‚¡æ¦‚ç‡: {row['ç‰›è‚¡æ¦‚ç‡']*100:.2f}%")
            report.append(f"  ğŸ’° æœ€æ–°ä»·æ ¼: {row['æœ€æ–°ä»·æ ¼']:.2f} å…ƒ")
            report.append(f"  ğŸ“Š 34æ—¥æ¶¨å¹…: {row['34æ—¥æ¶¨å¹…%']:.2f}%")
        
        # é£é™©æç¤º
        report.append("\n" + "=" * 80)
        report.append("ä¸‰ã€é£é™©æç¤º")
        report.append("=" * 80)
        report.append("\nâš ï¸ æœ¬æŠ¥å‘ŠåŸºäºå†å²æ•°æ®è®­ç»ƒçš„é‡åŒ–æ¨¡å‹ç”Ÿæˆï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®")
        report.append("âš ï¸ è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…")
        
        report.append("\n" + "=" * 80)
        
        return "\n".join(report)
    
    def save_results(self, df_scores: pd.DataFrame, df_top: pd.DataFrame,
                    target_date: datetime = None, top_n: int = 50):
        """ä¿å­˜ç»“æœ"""
        if target_date is None:
            target_date = datetime.now()
        
        date_str = target_date.strftime('%Y%m%d')
        timestamp = target_date.strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜åˆ°ç‰ˆæœ¬ç›®å½•
        version_path = self.iterator.get_version_path(self.version)
        results_dir = version_path / "predictions" / date_str
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # å®Œæ•´è¯„åˆ†
        scores_file = results_dir / f"stock_scores_{timestamp}.csv"
        df_scores.to_csv(scores_file, index=False, encoding='utf-8-sig')
        log.success(f"âœ“ å®Œæ•´è¯„åˆ†: {scores_file}")
        
        # Top N
        top_file = results_dir / f"top_{top_n}_{timestamp}.csv"
        df_top.to_csv(top_file, index=False, encoding='utf-8-sig')
        log.success(f"âœ“ Top {top_n}: {top_file}")
        
        # æŠ¥å‘Š
        report = self.generate_report(df_scores, top_n, target_date)
        report_file = results_dir / f"report_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        log.success(f"âœ“ æŠ¥å‘Š: {report_file}")
        
        # å…ƒæ•°æ®
        metadata = {
            'model_name': self.model_name,
            'version': self.version,
            'prediction_date': date_str,
            'timestamp': datetime.now().isoformat(),
            'total_scored': len(df_scores),
            'top_n': top_n,
            'top_stocks': [
                {'rank': i+1, 'code': row['è‚¡ç¥¨ä»£ç '], 'name': row['è‚¡ç¥¨åç§°'],
                 'probability': float(row['ç‰›è‚¡æ¦‚ç‡'])}
                for i, row in df_top.iterrows()
            ]
        }
        
        metadata_file = results_dir / f"metadata_{timestamp}.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        # åŒæ—¶ä¿å­˜åˆ°ç»Ÿä¸€çš„é¢„æµ‹ç»“æœç›®å½•ï¼ˆä¾¿äºæŸ¥æ‰¾ï¼‰
        unified_dir = 'data/prediction/results'
        os.makedirs(unified_dir, exist_ok=True)
        
        unified_file = f"{unified_dir}/top_{top_n}_stocks_{date_str}_{self.model_name}_{self.version}.csv"
        df_top.to_csv(unified_file, index=False, encoding='utf-8-sig')
        log.success(f"âœ“ ç»Ÿä¸€ç›®å½•: {unified_file}")
        
        # æ‰“å°æŠ¥å‘Š
        print("\n" + report)
        
        return scores_file, top_file, report_file


def main():
    parser = argparse.ArgumentParser(description='è‚¡ç¥¨è¯„åˆ†ï¼ˆæ–°æ¡†æ¶ï¼‰')
    parser.add_argument('--model', '-m', default='breakout_launch_scorer', help='æ¨¡å‹åç§°')
    parser.add_argument('--version', '-v', default=None, help='æ¨¡å‹ç‰ˆæœ¬ï¼ˆé»˜è®¤ä½¿ç”¨ç”Ÿäº§ç‰ˆæœ¬ï¼‰')
    parser.add_argument('--date', '-d', default=None, help='ç›®æ ‡æ—¥æœŸï¼ˆYYYYMMDDæ ¼å¼ï¼‰')
    parser.add_argument('--max-stocks', type=int, default=None, help='æœ€å¤§è¯„åˆ†æ•°é‡ï¼ˆæµ‹è¯•ç”¨ï¼‰')
    parser.add_argument('--top-n', type=int, default=50, help='Top Næ¨èæ•°é‡')
    
    args = parser.parse_args()
    
    # è§£ææ—¥æœŸ
    target_date = None
    if args.date:
        target_date = datetime.strptime(args.date, '%Y%m%d')
        log.info(f"ğŸ“… å†å²å›æµ‹æ¨¡å¼: {target_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}")
    
    log.info("="*80)
    log.info("è‚¡ç¥¨è¯„åˆ†ç³»ç»Ÿï¼ˆæ–°ç‰ˆæ¡†æ¶ï¼‰")
    log.info("="*80)
    
    try:
        # åˆå§‹åŒ–è¯„åˆ†å™¨
        scorer = StockScorer(args.model)
        
        # åŠ è½½æ¨¡å‹
        scorer.load_model(args.version)
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stocks = scorer.get_valid_stocks(target_date)
        
        # è¯„åˆ†
        df_scores = scorer.score_stocks(stocks, target_date, args.max_stocks)
        
        if df_scores.empty:
            log.error("è¯„åˆ†å¤±è´¥ï¼Œæ²¡æœ‰ç»“æœ")
            return
        
        # Top N
        df_top = df_scores.head(args.top_n)
        
        # æ˜¾ç¤ºç»“æœ
        log.info("\n" + "="*80)
        log.info(f"Top {args.top_n} æ¨è")
        log.info("="*80)
        
        print(f"\n{'åºå·':<4} {'ä»£ç ':<12} {'åç§°':<10} {'æ¦‚ç‡':<8} {'æœ€æ–°ä»·':<8} {'34æ—¥%':<8}")
        print("-" * 60)
        for i, row in df_top.iterrows():
            print(f"{i+1:<4} {row['è‚¡ç¥¨ä»£ç ']:<12} {row['è‚¡ç¥¨åç§°']:<10} "
                  f"{row['ç‰›è‚¡æ¦‚ç‡']:.4f} {row['æœ€æ–°ä»·æ ¼']:<8.2f} {row['34æ—¥æ¶¨å¹…%']:<8.2f}")
        
        # ä¿å­˜ç»“æœ
        scorer.save_results(df_scores, df_top, target_date, args.top_n)
        
        log.success("\nâœ… è¯„åˆ†å®Œæˆï¼")
        
    except Exception as e:
        log.error(f"è¯„åˆ†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

