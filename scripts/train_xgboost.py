"""
XGBoostæ¨¡å‹è®­ç»ƒè„šæœ¬

æ¨èä½œä¸ºç¬¬ä¸€ä¸ªbaselineæ¨¡å‹ï¼
"""
import sys
import os
import warnings
import pandas as pd
import numpy as np
from datetime import datetime
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    classification_report, confusion_matrix, 
    roc_auc_score, roc_curve, precision_recall_curve
)
import xgboost as xgb
from src.utils.logger import log


def load_and_prepare_data(neg_version='v2'):
    """
    åŠ è½½å¹¶å‡†å¤‡è®­ç»ƒæ•°æ®
    
    Args:
        neg_version: è´Ÿæ ·æœ¬ç‰ˆæœ¬ ('v1' æˆ– 'v2')
        
    Returns:
        df_features: ç‰¹å¾DataFrame
    """
    log.info("="*80)
    log.info("ç¬¬ä¸€æ­¥ï¼šåŠ è½½æ•°æ®")
    log.info("="*80)
    
    # åŠ è½½æ­£æ ·æœ¬
    df_pos = pd.read_csv('data/processed/feature_data_34d.csv')
    df_pos['label'] = 1
    log.success(f"âœ“ æ­£æ ·æœ¬åŠ è½½å®Œæˆ: {len(df_pos)} æ¡")
    
    # åŠ è½½è´Ÿæ ·æœ¬
    if neg_version == 'v2':
        neg_file = 'data/processed/negative_feature_data_v2_34d.csv'
    else:
        neg_file = 'data/processed/negative_feature_data_34d.csv'
    
    df_neg = pd.read_csv(neg_file)
    log.success(f"âœ“ è´Ÿæ ·æœ¬åŠ è½½å®Œæˆ: {len(df_neg)} æ¡ (ç‰ˆæœ¬: {neg_version})")
    
    # åˆå¹¶
    df = pd.concat([df_pos, df_neg])
    log.info(f"âœ“ æ•°æ®åˆå¹¶å®Œæˆ: {len(df)} æ¡")
    log.info(f"  - æ­£æ ·æœ¬: {len(df_pos)} æ¡")
    log.info(f"  - è´Ÿæ ·æœ¬: {len(df_neg)} æ¡")
    log.info("")
    
    return df


def extract_features(df):
    """
    ä»34å¤©çš„æ—¶åºæ•°æ®ä¸­æå–ç»Ÿè®¡ç‰¹å¾
    
    Args:
        df: åŸå§‹DataFrameï¼ˆæ¯è¡Œæ˜¯ä¸€å¤©çš„æ•°æ®ï¼‰
        
    Returns:
        df_features: ç‰¹å¾DataFrameï¼ˆæ¯è¡Œæ˜¯ä¸€ä¸ªæ ·æœ¬ï¼‰
    """
    log.info("="*80)
    log.info("ç¬¬äºŒæ­¥ï¼šç‰¹å¾å·¥ç¨‹")
    log.info("="*80)
    log.info("å°†34å¤©æ—¶åºæ•°æ®è½¬æ¢ä¸ºç»Ÿè®¡ç‰¹å¾...")
    
    features = []
    sample_ids = df['sample_id'].unique()
    
    for i, sample_id in enumerate(sample_ids):
        if (i + 1) % 500 == 0:
            log.info(f"è¿›åº¦: {i+1}/{len(sample_ids)}")
        
        sample_data = df[df['sample_id'] == sample_id].sort_values('days_to_t1')
        
        if len(sample_data) < 20:  # è‡³å°‘20å¤©æ•°æ®
            continue
        
        feature_dict = {
            'sample_id': sample_id,
            'label': int(sample_data['label'].iloc[0]),
        }
        
        # ä»·æ ¼ç‰¹å¾
        feature_dict['close_mean'] = sample_data['close'].mean()
        feature_dict['close_std'] = sample_data['close'].std()
        feature_dict['close_max'] = sample_data['close'].max()
        feature_dict['close_min'] = sample_data['close'].min()
        feature_dict['close_trend'] = (
            (sample_data['close'].iloc[-1] - sample_data['close'].iloc[0]) / 
            sample_data['close'].iloc[0] * 100
        )
        
        # æ¶¨è·Œå¹…ç‰¹å¾
        feature_dict['pct_chg_mean'] = sample_data['pct_chg'].mean()
        feature_dict['pct_chg_std'] = sample_data['pct_chg'].std()
        feature_dict['pct_chg_sum'] = sample_data['pct_chg'].sum()
        feature_dict['positive_days'] = (sample_data['pct_chg'] > 0).sum()
        feature_dict['negative_days'] = (sample_data['pct_chg'] < 0).sum()
        feature_dict['max_gain'] = sample_data['pct_chg'].max()
        feature_dict['max_loss'] = sample_data['pct_chg'].min()
        
        # é‡æ¯”ç‰¹å¾
        if 'volume_ratio' in sample_data.columns:
            feature_dict['volume_ratio_mean'] = sample_data['volume_ratio'].mean()
            feature_dict['volume_ratio_max'] = sample_data['volume_ratio'].max()
            feature_dict['volume_ratio_gt_2'] = (sample_data['volume_ratio'] > 2).sum()
            feature_dict['volume_ratio_gt_4'] = (sample_data['volume_ratio'] > 4).sum()
        
        # MACDç‰¹å¾
        if 'macd' in sample_data.columns:
            macd_data = sample_data['macd'].dropna()
            if len(macd_data) > 0:
                feature_dict['macd_mean'] = macd_data.mean()
                feature_dict['macd_positive_days'] = (macd_data > 0).sum()
                feature_dict['macd_max'] = macd_data.max()
        
        # MAç‰¹å¾
        if 'ma5' in sample_data.columns:
            feature_dict['ma5_mean'] = sample_data['ma5'].mean()
            feature_dict['price_above_ma5'] = (
                sample_data['close'] > sample_data['ma5']
            ).sum()
        
        if 'ma10' in sample_data.columns:
            feature_dict['ma10_mean'] = sample_data['ma10'].mean()
            feature_dict['price_above_ma10'] = (
                sample_data['close'] > sample_data['ma10']
            ).sum()
        
        # å¸‚å€¼ç‰¹å¾
        if 'total_mv' in sample_data.columns:
            mv_data = sample_data['total_mv'].dropna()
            if len(mv_data) > 0:
                feature_dict['total_mv_mean'] = mv_data.mean()
        
        if 'circ_mv' in sample_data.columns:
            circ_mv_data = sample_data['circ_mv'].dropna()
            if len(circ_mv_data) > 0:
                feature_dict['circ_mv_mean'] = circ_mv_data.mean()
        
        # åŠ¨é‡ç‰¹å¾ï¼ˆåˆ†æ®µæ”¶ç›Šç‡ï¼‰
        days = len(sample_data)
        if days >= 7:
            feature_dict['return_1w'] = (
                (sample_data['close'].iloc[-1] - sample_data['close'].iloc[-7]) /
                sample_data['close'].iloc[-7] * 100
            )
        if days >= 14:
            feature_dict['return_2w'] = (
                (sample_data['close'].iloc[-1] - sample_data['close'].iloc[-14]) /
                sample_data['close'].iloc[-14] * 100
            )
        
        features.append(feature_dict)
    
    df_features = pd.DataFrame(features)
    
    log.success(f"âœ“ ç‰¹å¾æå–å®Œæˆ: {len(df_features)} ä¸ªæ ·æœ¬")
    log.info(f"âœ“ ç‰¹å¾ç»´åº¦: {len(df_features.columns) - 2} ä¸ªç‰¹å¾")
    log.info(f"âœ“ ç‰¹å¾åˆ—è¡¨: {list(df_features.columns[2:])}")
    log.info("")
    
    return df_features


def train_model(df_features, test_size=0.2):
    """
    è®­ç»ƒXGBoostæ¨¡å‹
    
    Args:
        df_features: ç‰¹å¾DataFrame
        test_size: æµ‹è¯•é›†æ¯”ä¾‹
        
    Returns:
        model, metrics
    """
    log.info("="*80)
    log.info("ç¬¬ä¸‰æ­¥ï¼šè®­ç»ƒXGBoostæ¨¡å‹")
    log.info("="*80)
    
    # å‡†å¤‡æ•°æ®
    X = df_features.drop(['sample_id', 'label'], axis=1)
    y = df_features['label']
    
    # å¤„ç†ç¼ºå¤±å€¼
    X = X.fillna(0)
    
    log.info(f"ç‰¹å¾çŸ©é˜µ: {X.shape}")
    log.info(f"æ ‡ç­¾åˆ†å¸ƒ: {y.value_counts().to_dict()}")
    log.info("")
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42, stratify=y
    )
    
    log.info(f"è®­ç»ƒé›†: {len(X_train)} ä¸ªæ ·æœ¬")
    log.info(f"æµ‹è¯•é›†: {len(X_test)} ä¸ªæ ·æœ¬")
    log.info("")
    
    # è®­ç»ƒæ¨¡å‹
    log.info("å¼€å§‹è®­ç»ƒ...")
    model = xgb.XGBClassifier(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        min_child_weight=3,
        gamma=0.1,
        reg_alpha=0.1,
        reg_lambda=1.0,
        random_state=42,
        eval_metric='logloss'
    )
    
    model.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        verbose=False
    )
    
    log.success("âœ“ æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    log.info("")
    
    # é¢„æµ‹
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1]
    
    # è¯„ä¼°
    log.info("="*80)
    log.info("ç¬¬å››æ­¥ï¼šæ¨¡å‹è¯„ä¼°")
    log.info("="*80)
    
    # åˆ†ç±»æŠ¥å‘Š
    log.info("\nåˆ†ç±»æŠ¥å‘Š:")
    report = classification_report(
        y_test, y_pred, 
        target_names=['è´Ÿæ ·æœ¬', 'æ­£æ ·æœ¬'],
        output_dict=True
    )
    print(classification_report(
        y_test, y_pred, 
        target_names=['è´Ÿæ ·æœ¬', 'æ­£æ ·æœ¬']
    ))
    
    # AUC
    auc = roc_auc_score(y_test, y_prob)
    log.info(f"\nAUC-ROC: {auc:.4f}")
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_test, y_pred)
    log.info("\næ··æ·†çŸ©é˜µ:")
    log.info(f"  çœŸè´Ÿä¾‹(TN): {cm[0,0]:4d}  |  å‡æ­£ä¾‹(FP): {cm[0,1]:4d}")
    log.info(f"  å‡è´Ÿä¾‹(FN): {cm[1,0]:4d}  |  çœŸæ­£ä¾‹(TP): {cm[1,1]:4d}")
    
    # ç‰¹å¾é‡è¦æ€§
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    log.info("\n" + "="*80)
    log.info("ç‰¹å¾é‡è¦æ€§ Top 10:")
    log.info("="*80)
    for idx, row in feature_importance.head(10).iterrows():
        log.info(f"  {row['feature']:25s}: {row['importance']:.4f}")
    
    # æ±‡æ€»æŒ‡æ ‡
    metrics = {
        'accuracy': report['accuracy'],
        'precision': report['æ­£æ ·æœ¬']['precision'],
        'recall': report['æ­£æ ·æœ¬']['recall'],
        'f1_score': report['æ­£æ ·æœ¬']['f1-score'],
        'auc': auc,
        'confusion_matrix': cm.tolist(),
        'feature_importance': feature_importance.to_dict('records')
    }
    
    return model, metrics, X_test, y_test, y_prob


def save_model(model, metrics, neg_version):
    """ä¿å­˜æ¨¡å‹å’Œç»“æœ"""
    log.info("\n" + "="*80)
    log.info("ç¬¬äº”æ­¥ï¼šä¿å­˜æ¨¡å‹")
    log.info("="*80)
    
    # åˆ›å»ºç›®å½•
    os.makedirs('models', exist_ok=True)
    os.makedirs('data/results', exist_ok=True)
    
    # ä¿å­˜æ¨¡å‹
    model_file = f'models/xgboost_{neg_version}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    model.save_model(model_file)
    log.success(f"âœ“ æ¨¡å‹å·²ä¿å­˜: {model_file}")
    
    # ä¿å­˜æŒ‡æ ‡
    metrics_file = f'data/results/xgboost_{neg_version}_metrics.json'
    metrics['model_file'] = model_file
    metrics['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    metrics['neg_version'] = neg_version
    
    with open(metrics_file, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)
    
    log.success(f"âœ“ è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {metrics_file}")
    log.info("")


def main():
    """ä¸»å‡½æ•°"""
    log.info("="*80)
    log.info("XGBoost è‚¡ç¥¨é€‰è‚¡æ¨¡å‹è®­ç»ƒ")
    log.info("="*80)
    log.info("")
    
    # é€‰æ‹©è´Ÿæ ·æœ¬ç‰ˆæœ¬
    NEG_VERSION = 'v2'  # 'v1' æˆ– 'v2'
    
    log.info(f"é…ç½®:")
    log.info(f"  è´Ÿæ ·æœ¬ç‰ˆæœ¬: {NEG_VERSION}")
    log.info(f"  æµ‹è¯•é›†æ¯”ä¾‹: 0.2")
    log.info(f"  æ¨¡å‹: XGBoost")
    log.info("")
    
    try:
        # 1. åŠ è½½æ•°æ®
        df = load_and_prepare_data(neg_version=NEG_VERSION)
        
        # 2. ç‰¹å¾å·¥ç¨‹
        df_features = extract_features(df)
        
        # 3. è®­ç»ƒæ¨¡å‹
        model, metrics, X_test, y_test, y_prob = train_model(df_features)
        
        # 4. ä¿å­˜æ¨¡å‹
        save_model(model, metrics, NEG_VERSION)
        
        # 5. æœ€ç»ˆæ€»ç»“
        log.info("="*80)
        log.success("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        log.info("="*80)
        log.info("")
        log.info("ğŸ“Š æ¨¡å‹æ€§èƒ½æ€»ç»“:")
        log.info(f"  å‡†ç¡®ç‡ (Accuracy):  {metrics['accuracy']:.2%}")
        log.info(f"  ç²¾ç¡®ç‡ (Precision): {metrics['precision']:.2%}")
        log.info(f"  å¬å›ç‡ (Recall):    {metrics['recall']:.2%}")
        log.info(f"  F1åˆ†æ•° (F1-Score):  {metrics['f1_score']:.2%}")
        log.info(f"  AUC-ROC:            {metrics['auc']:.4f}")
        log.info("")
        log.info("ğŸ¯ ä¸‹ä¸€æ­¥:")
        log.info("  1. æŸ¥çœ‹ç‰¹å¾é‡è¦æ€§ï¼Œä¼˜åŒ–ç‰¹å¾å·¥ç¨‹")
        log.info("  2. å°è¯•ä¸åŒçš„è´Ÿæ ·æœ¬ç‰ˆæœ¬ï¼ˆv1 vs v2ï¼‰")
        log.info("  3. è°ƒæ•´è¶…å‚æ•°æå‡æ€§èƒ½")
        log.info("  4. ä½¿ç”¨æ¨¡å‹è¿›è¡Œå›æµ‹éªŒè¯")
        log.info("")
        
    except FileNotFoundError as e:
        log.error(f"âœ— æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        log.error("è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤å‡†å¤‡æ•°æ®:")
        log.error("  1. python scripts/prepare_positive_samples.py")
        log.error("  2. python scripts/prepare_negative_samples_v2.py")
    except Exception as e:
        log.error(f"âœ— è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()

