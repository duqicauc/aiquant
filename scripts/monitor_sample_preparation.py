#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ ·æœ¬å‡†å¤‡ç›‘æ§è„šæœ¬

åŠŸèƒ½ï¼š
1. ç›‘æ§æ­£æ ·æœ¬å‡†å¤‡çŠ¶æ€
2. ç›‘æ§è´Ÿæ ·æœ¬å‡†å¤‡çŠ¶æ€
3. å½“æ­£è´Ÿæ ·æœ¬éƒ½å‡†å¤‡å¥½åï¼Œè‡ªåŠ¨è§¦å‘æ¨¡å‹è®­ç»ƒæµç¨‹
"""
import sys
import os
import time
import subprocess
from pathlib import Path
from datetime import datetime
import pandas as pd
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.utils.logger import log


class SamplePreparationMonitor:
    """æ ·æœ¬å‡†å¤‡ç›‘æ§å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç›‘æ§å™¨"""
        self.project_root = PROJECT_ROOT
        self.data_dir = self.project_root / 'data' / 'processed'
        
        # æ­£æ ·æœ¬æ–‡ä»¶
        self.positive_samples_file = self.data_dir / 'positive_samples.csv'
        self.positive_features_file = self.data_dir / 'feature_data_34d.csv'
        self.positive_stats_file = self.data_dir / 'sample_statistics.json'
        
        # è´Ÿæ ·æœ¬æ–‡ä»¶ï¼ˆV2ç‰ˆæœ¬ï¼‰
        self.negative_samples_file = self.data_dir / 'negative_samples_v2.csv'
        self.negative_features_file = self.data_dir / 'negative_feature_data_v2_34d.csv'
        self.negative_stats_file = self.data_dir / 'negative_sample_statistics_v2.json'
        
        # è®­ç»ƒæµç¨‹è„šæœ¬
        self.quality_check_script = self.project_root / 'scripts' / 'check_sample_quality.py'
        self.train_script = self.project_root / 'scripts' / 'train_xgboost_timeseries.py'
        self.walk_forward_script = self.project_root / 'scripts' / 'walk_forward_validation.py'
        
    def check_positive_samples(self):
        """
        æ£€æŸ¥æ­£æ ·æœ¬æ˜¯å¦å‡†å¤‡å¥½
        
        Returns:
            tuple: (æ˜¯å¦å‡†å¤‡å¥½, è¯¦ç»†ä¿¡æ¯)
        """
        log.info("="*80)
        log.info("æ£€æŸ¥æ­£æ ·æœ¬å‡†å¤‡çŠ¶æ€")
        log.info("="*80)
        
        # æ£€æŸ¥å¿…éœ€æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = [
            self.positive_samples_file,
            self.positive_features_file
        ]
        
        missing_files = []
        for file in required_files:
            if not file.exists():
                missing_files.append(str(file))
        
        if missing_files:
            log.warning(f"âœ— æ­£æ ·æœ¬æ–‡ä»¶ç¼ºå¤±:")
            for f in missing_files:
                log.warning(f"  - {f}")
            return False, {"status": "missing_files", "files": missing_files}
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆï¼ˆéç©ºï¼‰
        try:
            df_samples = pd.read_csv(self.positive_samples_file)
            df_features = pd.read_csv(self.positive_features_file)
            
            if df_samples.empty:
                log.warning("âœ— æ­£æ ·æœ¬åˆ—è¡¨ä¸ºç©º")
                return False, {"status": "empty_samples"}
            
            if df_features.empty:
                log.warning("âœ— æ­£æ ·æœ¬ç‰¹å¾æ•°æ®ä¸ºç©º")
                return False, {"status": "empty_features"}
            
            # æ£€æŸ¥åŸºæœ¬å­—æ®µ
            required_cols = ['ts_code', 't1_date', 'total_return', 'max_return']
            missing_cols = [col for col in required_cols if col not in df_samples.columns]
            
            if missing_cols:
                log.warning(f"âœ— æ­£æ ·æœ¬ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_cols}")
                return False, {"status": "missing_columns", "columns": missing_cols}
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = {
                "status": "ready",
                "sample_count": len(df_samples),
                "feature_count": len(df_features),
                "unique_stocks": df_samples['ts_code'].nunique(),
                "avg_total_return": float(df_samples['total_return'].mean()),
                "avg_max_return": float(df_samples['max_return'].mean())
            }
            
            log.success("âœ“ æ­£æ ·æœ¬å·²å‡†å¤‡å¥½")
            log.info(f"  æ ·æœ¬æ•°é‡: {stats['sample_count']}")
            log.info(f"  ç‰¹å¾è®°å½•: {stats['feature_count']}")
            log.info(f"  è‚¡ç¥¨æ•°é‡: {stats['unique_stocks']}")
            log.info(f"  å¹³å‡æ€»æ¶¨å¹…: {stats['avg_total_return']:.2f}%")
            log.info(f"  å¹³å‡æœ€é«˜æ¶¨å¹…: {stats['avg_max_return']:.2f}%")
            
            return True, stats
            
        except Exception as e:
            log.error(f"âœ— æ£€æŸ¥æ­£æ ·æœ¬æ—¶å‡ºé”™: {e}")
            return False, {"status": "error", "error": str(e)}
    
    def check_negative_samples(self):
        """
        æ£€æŸ¥è´Ÿæ ·æœ¬æ˜¯å¦å‡†å¤‡å¥½
        
        Returns:
            tuple: (æ˜¯å¦å‡†å¤‡å¥½, è¯¦ç»†ä¿¡æ¯)
        """
        log.info("\n" + "="*80)
        log.info("æ£€æŸ¥è´Ÿæ ·æœ¬å‡†å¤‡çŠ¶æ€")
        log.info("="*80)
        
        # æ£€æŸ¥å¿…éœ€æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = [
            self.negative_samples_file,
            self.negative_features_file
        ]
        
        missing_files = []
        for file in required_files:
            if not file.exists():
                missing_files.append(str(file))
        
        if missing_files:
            log.warning(f"âœ— è´Ÿæ ·æœ¬æ–‡ä»¶ç¼ºå¤±:")
            for f in missing_files:
                log.warning(f"  - {f}")
            return False, {"status": "missing_files", "files": missing_files}
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆï¼ˆéç©ºï¼‰
        try:
            df_samples = pd.read_csv(self.negative_samples_file)
            df_features = pd.read_csv(self.negative_features_file)
            
            if df_samples.empty:
                log.warning("âœ— è´Ÿæ ·æœ¬åˆ—è¡¨ä¸ºç©º")
                return False, {"status": "empty_samples"}
            
            if df_features.empty:
                log.warning("âœ— è´Ÿæ ·æœ¬ç‰¹å¾æ•°æ®ä¸ºç©º")
                return False, {"status": "empty_features"}
            
            # æ£€æŸ¥åŸºæœ¬å­—æ®µ
            required_cols = ['ts_code', 't1_date']
            missing_cols = [col for col in required_cols if col not in df_samples.columns]
            
            if missing_cols:
                log.warning(f"âœ— è´Ÿæ ·æœ¬ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_cols}")
                return False, {"status": "missing_columns", "columns": missing_cols}
            
            # æ£€æŸ¥labelå­—æ®µï¼ˆåº”è¯¥éƒ½æ˜¯0ï¼‰
            if 'label' in df_features.columns:
                label_counts = df_features['label'].value_counts()
                if 0 not in label_counts.index or label_counts[0] < len(df_features) * 0.9:
                    log.warning("âš ï¸  è´Ÿæ ·æœ¬ç‰¹å¾æ•°æ®ä¸­label=0çš„æ¯”ä¾‹å¼‚å¸¸")
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = {
                "status": "ready",
                "sample_count": len(df_samples),
                "feature_count": len(df_features),
                "unique_stocks": df_samples['ts_code'].nunique()
            }
            
            log.success("âœ“ è´Ÿæ ·æœ¬å·²å‡†å¤‡å¥½")
            log.info(f"  æ ·æœ¬æ•°é‡: {stats['sample_count']}")
            log.info(f"  ç‰¹å¾è®°å½•: {stats['feature_count']}")
            log.info(f"  è‚¡ç¥¨æ•°é‡: {stats['unique_stocks']}")
            
            return True, stats
            
        except Exception as e:
            log.error(f"âœ— æ£€æŸ¥è´Ÿæ ·æœ¬æ—¶å‡ºé”™: {e}")
            return False, {"status": "error", "error": str(e)}
    
    def check_all_samples(self):
        """
        æ£€æŸ¥æ‰€æœ‰æ ·æœ¬æ˜¯å¦å‡†å¤‡å¥½
        
        Returns:
            dict: æ£€æŸ¥ç»“æœ
        """
        log.info("\n" + "="*80)
        log.info("æ ·æœ¬å‡†å¤‡çŠ¶æ€æ£€æŸ¥")
        log.info("="*80)
        log.info(f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        log.info("")
        
        positive_ready, positive_info = self.check_positive_samples()
        negative_ready, negative_info = self.check_negative_samples()
        
        result = {
            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "positive_samples": {
                "ready": positive_ready,
                "info": positive_info
            },
            "negative_samples": {
                "ready": negative_ready,
                "info": negative_info
            },
            "all_ready": positive_ready and negative_ready
        }
        
        log.info("\n" + "="*80)
        log.info("æ£€æŸ¥ç»“æœæ€»ç»“")
        log.info("="*80)
        log.info(f"æ­£æ ·æœ¬: {'âœ“ å·²å‡†å¤‡å¥½' if positive_ready else 'âœ— æœªå‡†å¤‡å¥½'}")
        log.info(f"è´Ÿæ ·æœ¬: {'âœ“ å·²å‡†å¤‡å¥½' if negative_ready else 'âœ— æœªå‡†å¤‡å¥½'}")
        log.info(f"æ€»ä½“çŠ¶æ€: {'âœ… æ‰€æœ‰æ ·æœ¬å·²å‡†å¤‡å¥½ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ' if result['all_ready'] else 'â³ ç­‰å¾…æ ·æœ¬å‡†å¤‡å®Œæˆ'}")
        log.info("")
        
        return result
    
    def run_training_pipeline(self):
        """
        è¿è¡Œæ¨¡å‹è®­ç»ƒæµç¨‹
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        log.info("="*80)
        log.info("ğŸš€ å¼€å§‹è‡ªåŠ¨æ‰§è¡Œæ¨¡å‹è®­ç»ƒæµç¨‹")
        log.info("="*80)
        log.info("")
        
        steps = [
            ("æ•°æ®è´¨é‡æ£€æŸ¥", self.quality_check_script),
            ("æ¨¡å‹è®­ç»ƒ", self.train_script),
            ("Walk-forwardéªŒè¯", self.walk_forward_script)
        ]
        
        for step_name, script in steps:
            if not script.exists():
                log.warning(f"âš ï¸  è„šæœ¬ä¸å­˜åœ¨ï¼Œè·³è¿‡: {script}")
                continue
            
            log.info("="*80)
            log.info(f"æ‰§è¡Œæ­¥éª¤: {step_name}")
            log.info(f"è„šæœ¬: {script}")
            log.info("")
            
            try:
                # æ‰§è¡Œè„šæœ¬
                result = subprocess.run(
                    [sys.executable, str(script)],
                    cwd=str(self.project_root),
                    capture_output=False,
                    text=True
                )
                
                if result.returncode != 0:
                    log.error(f"âŒ {step_name} æ‰§è¡Œå¤±è´¥ (é€€å‡ºç : {result.returncode})")
                    return False
                else:
                    log.success(f"âœ… {step_name} æ‰§è¡ŒæˆåŠŸ")
                    log.info("")
                    
            except Exception as e:
                log.error(f"âŒ {step_name} æ‰§è¡Œå¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
                return False
        
        log.info("="*80)
        log.success("âœ… æ¨¡å‹è®­ç»ƒæµç¨‹å…¨éƒ¨å®Œæˆï¼")
        log.info("="*80)
        return True
    
    def monitor_once(self, auto_run=False):
        """
        æ‰§è¡Œä¸€æ¬¡æ£€æŸ¥ï¼ˆä¸å¾ªç¯ï¼‰
        
        Args:
            auto_run: å¦‚æœæ ·æœ¬éƒ½å‡†å¤‡å¥½ï¼Œæ˜¯å¦è‡ªåŠ¨è¿è¡Œè®­ç»ƒæµç¨‹
            
        Returns:
            dict: æ£€æŸ¥ç»“æœ
        """
        result = self.check_all_samples()
        
        if result['all_ready'] and auto_run:
            log.info("\n" + "="*80)
            log.info("æ£€æµ‹åˆ°æ‰€æœ‰æ ·æœ¬å·²å‡†å¤‡å¥½ï¼Œè‡ªåŠ¨å¯åŠ¨è®­ç»ƒæµç¨‹...")
            log.info("="*80)
            log.info("")
            
            success = self.run_training_pipeline()
            result['training_pipeline'] = {
                "executed": True,
                "success": success
            }
        else:
            result['training_pipeline'] = {
                "executed": False,
                "reason": "samples_not_ready" if not result['all_ready'] else "auto_run_disabled"
            }
        
        return result
    
    def monitor_loop(self, interval=300, auto_run=True):
        """
        å¾ªç¯ç›‘æ§ï¼ˆæ¯intervalç§’æ£€æŸ¥ä¸€æ¬¡ï¼‰
        
        Args:
            interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤5åˆ†é’Ÿ
            auto_run: å¦‚æœæ ·æœ¬éƒ½å‡†å¤‡å¥½ï¼Œæ˜¯å¦è‡ªåŠ¨è¿è¡Œè®­ç»ƒæµç¨‹
        """
        log.info("="*80)
        log.info("ğŸ”„ æ ·æœ¬å‡†å¤‡ç›‘æ§å™¨å·²å¯åŠ¨ï¼ˆå¾ªç¯æ¨¡å¼ï¼‰")
        log.info("="*80)
        log.info(f"æ£€æŸ¥é—´éš”: {interval} ç§’ ({interval/60:.1f} åˆ†é’Ÿ)")
        log.info(f"è‡ªåŠ¨è¿è¡Œ: {'æ˜¯' if auto_run else 'å¦'}")
        log.info("")
        log.info("ğŸ’¡ æç¤º: æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        log.info("")
        
        try:
            while True:
                result = self.monitor_once(auto_run=auto_run)
                
                # å¦‚æœå·²ç»æ‰§è¡Œäº†è®­ç»ƒæµç¨‹ï¼Œåœæ­¢ç›‘æ§
                if result.get('training_pipeline', {}).get('executed'):
                    if result['training_pipeline'].get('success'):
                        log.info("\n" + "="*80)
                        log.success("âœ… è®­ç»ƒæµç¨‹å·²å®Œæˆï¼Œç›‘æ§å™¨å°†é€€å‡º")
                        log.info("="*80)
                        break
                    else:
                        log.warning("\nâš ï¸  è®­ç»ƒæµç¨‹æ‰§è¡Œå¤±è´¥ï¼Œç»§ç»­ç›‘æ§...")
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                log.info(f"\nâ³ ç­‰å¾… {interval} ç§’åè¿›è¡Œä¸‹æ¬¡æ£€æŸ¥...")
                log.info(f"ä¸‹æ¬¡æ£€æŸ¥æ—¶é—´: {(datetime.now().timestamp() + interval):.0f}")
                log.info("")
                time.sleep(interval)
                
        except KeyboardInterrupt:
            log.info("\n" + "="*80)
            log.info("â¹ï¸  ç›‘æ§å™¨å·²åœæ­¢ï¼ˆç”¨æˆ·ä¸­æ–­ï¼‰")
            log.info("="*80)
        except Exception as e:
            log.error(f"\nâŒ ç›‘æ§å™¨å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ ·æœ¬å‡†å¤‡ç›‘æ§è„šæœ¬')
    parser.add_argument(
        '--mode',
        choices=['once', 'loop'],
        default='once',
        help='è¿è¡Œæ¨¡å¼: once=æ£€æŸ¥ä¸€æ¬¡, loop=å¾ªç¯ç›‘æ§'
    )
    parser.add_argument(
        '--interval',
        type=int,
        default=300,
        help='å¾ªç¯æ¨¡å¼ä¸‹çš„æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤300ç§’ï¼ˆ5åˆ†é’Ÿï¼‰'
    )
    parser.add_argument(
        '--auto-run',
        action='store_true',
        default=False,
        help='å¦‚æœæ ·æœ¬éƒ½å‡†å¤‡å¥½ï¼Œè‡ªåŠ¨è¿è¡Œè®­ç»ƒæµç¨‹'
    )
    parser.add_argument(
        '--no-auto-run',
        dest='auto_run',
        action='store_false',
        help='ä¸è‡ªåŠ¨è¿è¡Œè®­ç»ƒæµç¨‹ï¼ˆä»…æ£€æŸ¥ï¼‰'
    )
    
    args = parser.parse_args()
    
    monitor = SamplePreparationMonitor()
    
    if args.mode == 'once':
        # å•æ¬¡æ£€æŸ¥æ¨¡å¼
        result = monitor.monitor_once(auto_run=args.auto_run)
        
        # ä¿å­˜æ£€æŸ¥ç»“æœ
        result_file = PROJECT_ROOT / 'data' / 'processed' / 'sample_preparation_status.json'
        result_file.parent.mkdir(parents=True, exist_ok=True)
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        log.info(f"\næ£€æŸ¥ç»“æœå·²ä¿å­˜: {result_file}")
        
        # è¿”å›é€‚å½“çš„é€€å‡ºç 
        if result['all_ready']:
            sys.exit(0)
        else:
            sys.exit(1)
    else:
        # å¾ªç¯ç›‘æ§æ¨¡å¼
        monitor.monitor_loop(interval=args.interval, auto_run=args.auto_run)


if __name__ == '__main__':
    main()

