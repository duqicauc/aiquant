"""
é¢„æµ‹å‡†ç¡®ç‡åˆ†æè„šæœ¬

åŠŸèƒ½ï¼š
1. è¯»å–å†å²é¢„æµ‹ç»“æœ
2. è·å–å®é™…è‚¡ä»·è¡¨ç°
3. è®¡ç®—å‡†ç¡®ç‡ã€æ”¶ç›Šç‡ç­‰æŒ‡æ ‡
4. ç”Ÿæˆåˆ†ææŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
  python scripts/analyze_prediction_accuracy.py --date 20250919 --weeks 4
  python scripts/analyze_prediction_accuracy.py --all  # åˆ†ææ‰€æœ‰å†å²é¢„æµ‹
"""
import sys
import os
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.data.data_manager import DataManager
from src.utils.logger import log


def load_prediction_metadata(prediction_date):
    """åŠ è½½æŒ‡å®šæ—¥æœŸçš„é¢„æµ‹å…ƒæ•°æ®"""
    metadata_dir = Path('data/prediction/metadata')
    
    # æŸ¥æ‰¾è¯¥æ—¥æœŸçš„å…ƒæ•°æ®æ–‡ä»¶
    pattern = f'prediction_metadata_{prediction_date}*.json'
    metadata_files = list(metadata_dir.glob(pattern))
    
    if not metadata_files:
        log.warning(f"æœªæ‰¾åˆ° {prediction_date} çš„é¢„æµ‹å…ƒæ•°æ®")
        return None
    
    # å–æœ€æ–°çš„
    metadata_file = max(metadata_files, key=lambda x: x.stat().st_mtime)
    
    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)
    
    log.info(f"âœ“ åŠ è½½é¢„æµ‹å…ƒæ•°æ®: {metadata_file}")
    return metadata


def get_actual_performance(dm, stock_code, prediction_date, weeks=4):
    """
    è·å–è‚¡ç¥¨å®é™…è¡¨ç°
    
    Args:
        dm: DataManagerå®ä¾‹
        stock_code: è‚¡ç¥¨ä»£ç 
        prediction_date: é¢„æµ‹æ—¥æœŸï¼ˆYYYYMMDDï¼‰
        weeks: è§‚å¯Ÿå‘¨æœŸï¼ˆå‘¨æ•°ï¼‰
    
    Returns:
        dict: åŒ…å«æ”¶ç›Šç‡ã€æ˜¯å¦è¾¾åˆ°50%æ¶¨å¹…ç­‰ä¿¡æ¯
    """
    try:
        # è®¡ç®—ç»“æŸæ—¥æœŸï¼ˆé¢„æµ‹æ—¥æœŸ + weekså‘¨ï¼‰
        pred_date = datetime.strptime(prediction_date, '%Y%m%d')
        end_date = pred_date + timedelta(weeks=weeks)
        end_date_str = end_date.strftime('%Y%m%d')
        
        # è·å–é¢„æµ‹æ—¥æœŸå½“å¤©çš„ä»·æ ¼
        df_pred = dm.get_daily_data(stock_code, prediction_date, prediction_date)
        if df_pred.empty:
            return None
        
        pred_price = df_pred['close'].iloc[0]
        
        # è·å–è§‚å¯ŸæœŸå†…çš„æ•°æ®
        df_period = dm.get_daily_data(stock_code, prediction_date, end_date_str)
        if df_period.empty:
            return None
        
        # è®¡ç®—æœ€å¤§æ¶¨å¹…ã€æœ€å¤§è·Œå¹…ã€æœ€ç»ˆæ¶¨å¹…
        max_price = df_period['close'].max()
        min_price = df_period['close'].min()
        final_price = df_period['close'].iloc[-1]
        
        max_return = (max_price / pred_price - 1) * 100
        min_return = (min_price / pred_price - 1) * 100
        final_return = (final_price / pred_price - 1) * 100
        
        # åˆ¤æ–­æ˜¯å¦è¾¾åˆ°50%æ¶¨å¹…ï¼ˆç‰›è‚¡æ ‡å‡†ï¼‰
        is_bull_stock = max_return >= 50
        
        return {
            'pred_price': float(pred_price),
            'max_price': float(max_price),
            'min_price': float(min_price),
            'final_price': float(final_price),
            'max_return': float(max_return),
            'min_return': float(min_return),
            'final_return': float(final_return),
            'is_bull_stock': is_bull_stock,
            'observation_days': len(df_period)
        }
    except Exception as e:
        log.warning(f"è·å– {stock_code} å®é™…è¡¨ç°å¤±è´¥: {e}")
        return None


def analyze_prediction(prediction_date, weeks=4):
    """åˆ†æå•æ¬¡é¢„æµ‹çš„å‡†ç¡®ç‡"""
    log.info("="*80)
    log.info(f"åˆ†æé¢„æµ‹å‡†ç¡®ç‡: {prediction_date} ({weeks}å‘¨)")
    log.info("="*80)
    
    # åŠ è½½é¢„æµ‹å…ƒæ•°æ®
    metadata = load_prediction_metadata(prediction_date)
    if not metadata:
        return None
    
    # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    dm = DataManager()
    
    # åˆ†ææ¯åªæ¨èè‚¡ç¥¨çš„å®é™…è¡¨ç°
    results = []
    top_stocks = metadata.get('top_stocks', [])
    
    log.info(f"\nåˆ†æ {len(top_stocks)} åªæ¨èè‚¡ç¥¨çš„å®é™…è¡¨ç°...")
    
    for i, stock in enumerate(top_stocks):
        if (i + 1) % 10 == 0:
            log.info(f"è¿›åº¦: {i+1}/{len(top_stocks)}")
        
        stock_code = stock['code']
        performance = get_actual_performance(dm, stock_code, prediction_date, weeks)
        
        if performance:
            result = {
                'rank': stock['rank'],
                'code': stock_code,
                'name': stock['name'],
                'predicted_prob': stock['probability'],
                'predicted_price': stock['price'],
                'actual_max_return': performance['max_return'],
                'actual_final_return': performance['final_return'],
                'actual_min_return': performance['min_return'],
                'is_bull_stock': performance['is_bull_stock'],
                'max_price': performance['max_price'],
                'final_price': performance['final_price']
            }
            results.append(result)
    
    if not results:
        log.warning("æ²¡æœ‰è·å–åˆ°ä»»ä½•è‚¡ç¥¨çš„å®é™…è¡¨ç°æ•°æ®")
        return None
    
    df_results = pd.DataFrame(results)
    
    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    total = len(df_results)
    bull_stocks = df_results['is_bull_stock'].sum()
    accuracy = bull_stocks / total * 100 if total > 0 else 0
    
    avg_max_return = df_results['actual_max_return'].mean()
    avg_final_return = df_results['actual_final_return'].mean()
    
    positive_count = (df_results['actual_final_return'] > 0).sum()
    positive_rate = positive_count / total * 100 if total > 0 else 0
    
    analysis = {
        'prediction_date': prediction_date,
        'weeks': weeks,
        'total_stocks': total,
        'bull_stocks': int(bull_stocks),
        'accuracy': float(accuracy),
        'avg_max_return': float(avg_max_return),
        'avg_final_return': float(avg_final_return),
        'positive_count': int(positive_count),
        'positive_rate': float(positive_rate),
        'results': df_results.to_dict('records')
    }
    
    return analysis


def generate_accuracy_report(analysis):
    """ç”Ÿæˆå‡†ç¡®ç‡åˆ†ææŠ¥å‘Š"""
    report = []
    report.append("=" * 80)
    report.append("ğŸ“Š é¢„æµ‹å‡†ç¡®ç‡åˆ†ææŠ¥å‘Š")
    report.append("=" * 80)
    
    report.append(f"\nğŸ“… é¢„æµ‹æ—¥æœŸ: {analysis['prediction_date']}")
    report.append(f"â±ï¸  è§‚å¯Ÿå‘¨æœŸ: {analysis['weeks']} å‘¨")
    report.append(f"ğŸ“ˆ åˆ†æè‚¡ç¥¨æ•°: {analysis['total_stocks']} åª")
    
    report.append("\n" + "=" * 80)
    report.append("ä¸€ã€æ•´ä½“è¡¨ç°")
    report.append("=" * 80)
    
    report.append(f"\n1. å‡†ç¡®ç‡ï¼ˆè¾¾åˆ°50%æ¶¨å¹…ï¼‰")
    report.append(f"   - ç‰›è‚¡æ•°é‡: {analysis['bull_stocks']} åª")
    report.append(f"   - å‡†ç¡®ç‡: {analysis['accuracy']:.2f}%")
    
    report.append(f"\n2. æ”¶ç›Šç‡ç»Ÿè®¡")
    report.append(f"   - å¹³å‡æœ€å¤§æ¶¨å¹…: {analysis['avg_max_return']:.2f}%")
    report.append(f"   - å¹³å‡æœ€ç»ˆæ¶¨å¹…: {analysis['avg_final_return']:.2f}%")
    
    report.append(f"\n3. ç›ˆåˆ©æƒ…å†µ")
    report.append(f"   - ç›ˆåˆ©è‚¡ç¥¨æ•°: {analysis['positive_count']} åª")
    report.append(f"   - ç›ˆåˆ©æ¯”ä¾‹: {analysis['positive_rate']:.2f}%")
    
    # Top 10 è¡¨ç°
    report.append("\n" + "=" * 80)
    report.append("äºŒã€Top 10 è¡¨ç°è¯¦æƒ…")
    report.append("=" * 80)
    
    df_results = pd.DataFrame(analysis['results'])
    df_sorted = df_results.sort_values('actual_max_return', ascending=False).head(10)
    
    for i, row in df_sorted.iterrows():
        report.append(f"\nã€ç¬¬ {row['rank']} åã€‘{row['name']}ï¼ˆ{row['code']}ï¼‰")
        report.append(f"  é¢„æµ‹æ¦‚ç‡: {row['predicted_prob']*100:.2f}%")
        report.append(f"  æœ€å¤§æ¶¨å¹…: {row['actual_max_return']:.2f}%")
        report.append(f"  æœ€ç»ˆæ¶¨å¹…: {row['actual_final_return']:.2f}%")
        report.append(f"  æ˜¯å¦ç‰›è‚¡: {'âœ… æ˜¯' if row['is_bull_stock'] else 'âŒ å¦'}")
    
    report.append("\n" + "=" * 80)
    report.append("æŠ¥å‘Šç»“æŸ")
    report.append("=" * 80)
    
    return "\n".join(report)


def save_analysis_results(analysis, report_content):
    """ä¿å­˜åˆ†æç»“æœ"""
    output_dir = Path('data/prediction/analysis')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    prediction_date = analysis['prediction_date']
    weeks = analysis['weeks']
    
    # ä¿å­˜è¯¦ç»†ç»“æœCSV
    df_results = pd.DataFrame(analysis['results'])
    csv_file = output_dir / f'accuracy_{prediction_date}_{weeks}w.csv'
    df_results.to_csv(csv_file, index=False, encoding='utf-8-sig')
    log.success(f"âœ“ è¯¦ç»†ç»“æœå·²ä¿å­˜: {csv_file}")
    
    # ä¿å­˜åˆ†ææŠ¥å‘Š
    report_file = output_dir / f'accuracy_report_{prediction_date}_{weeks}w.txt'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    log.success(f"âœ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    # ä¿å­˜JSONå…ƒæ•°æ®
    json_file = output_dir / f'accuracy_{prediction_date}_{weeks}w.json'
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(analysis, f, indent=2, ensure_ascii=False)
    log.success(f"âœ“ åˆ†æå…ƒæ•°æ®å·²ä¿å­˜: {json_file}")
    
    return csv_file, report_file, json_file


def analyze_all_predictions(weeks=4):
    """åˆ†ææ‰€æœ‰å†å²é¢„æµ‹"""
    metadata_dir = Path('data/prediction/metadata')
    
    # æŸ¥æ‰¾æ‰€æœ‰å…ƒæ•°æ®æ–‡ä»¶
    metadata_files = list(metadata_dir.glob('prediction_metadata_*.json'))
    
    if not metadata_files:
        log.warning("æœªæ‰¾åˆ°ä»»ä½•é¢„æµ‹å…ƒæ•°æ®")
        return
    
    log.info(f"æ‰¾åˆ° {len(metadata_files)} ä¸ªå†å²é¢„æµ‹")
    
    all_analyses = []
    
    for metadata_file in metadata_files:
        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        prediction_date = metadata['prediction_date']
        
        # åªåˆ†æéå›æµ‹çš„é¢„æµ‹ï¼ˆå®é™…é¢„æµ‹ï¼‰
        if metadata.get('is_backtest', False):
            continue
        
        log.info(f"\nåˆ†æé¢„æµ‹: {prediction_date}")
        analysis = analyze_prediction(prediction_date, weeks)
        
        if analysis:
            all_analyses.append(analysis)
    
    if not all_analyses:
        log.warning("æ²¡æœ‰å¯åˆ†æçš„é¢„æµ‹ç»“æœ")
        return
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    log.info("\n" + "="*80)
    log.info("æ±‡æ€»åˆ†æç»“æœ")
    log.info("="*80)
    
    total_predictions = len(all_analyses)
    avg_accuracy = np.mean([a['accuracy'] for a in all_analyses])
    avg_max_return = np.mean([a['avg_max_return'] for a in all_analyses])
    avg_final_return = np.mean([a['avg_final_return'] for a in all_analyses])
    
    log.info(f"\næ€»é¢„æµ‹æ¬¡æ•°: {total_predictions}")
    log.info(f"å¹³å‡å‡†ç¡®ç‡: {avg_accuracy:.2f}%")
    log.info(f"å¹³å‡æœ€å¤§æ¶¨å¹…: {avg_max_return:.2f}%")
    log.info(f"å¹³å‡æœ€ç»ˆæ¶¨å¹…: {avg_final_return:.2f}%")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='é¢„æµ‹å‡†ç¡®ç‡åˆ†æ')
    parser.add_argument('--date', type=str, default=None,
                        help='é¢„æµ‹æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYYMMDDï¼‰ï¼Œä¾‹å¦‚ï¼š--date 20250919')
    parser.add_argument('--weeks', type=int, default=4,
                        help='è§‚å¯Ÿå‘¨æœŸï¼ˆå‘¨æ•°ï¼‰ï¼Œé»˜è®¤4å‘¨')
    parser.add_argument('--all', action='store_true',
                        help='åˆ†ææ‰€æœ‰å†å²é¢„æµ‹')
    
    args = parser.parse_args()
    
    if args.all:
        analyze_all_predictions(weeks=args.weeks)
    elif args.date:
        analysis = analyze_prediction(args.date, weeks=args.weeks)
        
        if analysis:
            report_content = generate_accuracy_report(analysis)
            save_analysis_results(analysis, report_content)
            log.info("\n" + report_content)
        else:
            log.error("åˆ†æå¤±è´¥")
    else:
        parser.print_help()
        log.error("è¯·æŒ‡å®š --date æˆ– --all å‚æ•°")


if __name__ == '__main__':
    main()

