# æ­£æ ·æœ¬æ•°æ®å‡†å¤‡ - ä½¿ç”¨æŒ‡å— ğŸš€

## å¿«é€Ÿå¼€å§‹

### æ­¥éª¤1: ç¯å¢ƒå‡†å¤‡

ç¡®ä¿å·²å®‰è£…ä¾èµ–å¹¶é…ç½®å¥½Tushare Tokenï¼š

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# é…ç½®Tokenï¼ˆåœ¨.envæ–‡ä»¶ä¸­ï¼‰
TUSHARE_TOKEN=ä½ çš„token
```

**âš ï¸ Tushareç§¯åˆ†è¦æ±‚**ï¼š
- **åŸºç¡€åŠŸèƒ½**ï¼š0ç§¯åˆ†ï¼ˆå…è´¹ï¼‰
- **å®Œæ•´åŠŸèƒ½**ï¼š2000ç§¯åˆ†ï¼ˆæ¨èï¼‰
- **é«˜çº§åŠŸèƒ½**ï¼š5000ç§¯åˆ†ï¼ˆæŠ€æœ¯å› å­APIï¼Œå¼ºçƒˆæ¨èï¼ï¼‰

ğŸ’¡ æŸ¥çœ‹è¯¦æƒ…ï¼š[Tushare ProåŠŸèƒ½è¯´æ˜](TUSHARE_PRO_FEATURES.md)

### æ­¥éª¤2: å¿«é€Ÿæµ‹è¯•ï¼ˆæ¨èï¼‰

å…ˆè¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯é€»è¾‘ï¼š

```bash
cd /Users/javaadu/Documents/GitHub/aiquant
python scripts/test_positive_samples.py
```

é€‰æ‹©æµ‹è¯•æ¨¡å¼ï¼š
- `1`: æµ‹è¯•å•åªè‚¡ç¥¨ï¼ˆè´µå·èŒ…å°ï¼‰- çº¦1åˆ†é’Ÿ
- `2`: æµ‹è¯•5åªè‚¡ç¥¨ - çº¦3-5åˆ†é’Ÿ

### æ­¥éª¤3: è¿è¡Œå®Œæ•´æµç¨‹

ç¡®è®¤æµ‹è¯•é€šè¿‡åï¼Œè¿è¡Œå®Œæ•´è„šæœ¬ï¼š

```bash
python scripts/prepare_positive_samples.py
```

**âš ï¸ æ³¨æ„**ï¼š
- é¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦**å‡ å°æ—¶**ï¼ˆå–å†³äºæ—¥æœŸèŒƒå›´å’Œè‚¡ç¥¨æ•°é‡ï¼‰
- å»ºè®®å…ˆä¿®æ”¹è„šæœ¬ä¸­çš„æ—¥æœŸèŒƒå›´è¿›è¡Œå°è§„æ¨¡æµ‹è¯•
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„Tushareç§¯åˆ†å’ŒAPIè°ƒç”¨é¢åº¦

---

## é…ç½®è¯´æ˜

### ä¿®æ”¹æ—¥æœŸèŒƒå›´

ç¼–è¾‘ `scripts/prepare_positive_samples.py`ï¼š

```python
# æµ‹è¯•æ¨¡å¼ï¼ˆå¿«é€Ÿï¼‰
START_DATE = '20220101'  # æœ€è¿‘2å¹´
END_DATE = None          # åˆ°ä»Šå¤©

# å®Œæ•´æ¨¡å¼ï¼ˆæ…¢ï¼‰
START_DATE = '20000101'  # ä»2000å¹´å¼€å§‹
END_DATE = None
```

### ä¿®æ”¹å›çœ‹å¤©æ•°

é»˜è®¤æå–T1å‰34å¤©æ•°æ®ï¼Œå¯ä¿®æ”¹ï¼š

```python
df_features = screener.extract_features(
    df_samples,
    lookback_days=34  # æ”¹ä¸ºå…¶ä»–å€¼ï¼Œå¦‚50ã€60ç­‰
)
```

---

## è¾“å‡ºæ–‡ä»¶

è¿è¡Œå®Œæˆåï¼Œä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

### 1. æ­£æ ·æœ¬åˆ—è¡¨
**æ–‡ä»¶**: `data/processed/positive_samples.csv`

| å­—æ®µ | è¯´æ˜ | ç¤ºä¾‹ |
|-----|------|------|
| ts_code | è‚¡ç¥¨ä»£ç  | 600519.SH |
| name | è‚¡ç¥¨åç§° | è´µå·èŒ…å° |
| t1_date | T1æ—¥æœŸ | 20150601 |
| week1_open | ç¬¬1å‘¨å¼€ç›˜ä»· | 180.50 |
| week3_close | ç¬¬3å‘¨æ”¶ç›˜ä»· | 285.60 |
| total_return | æ€»æ¶¨å¹…(%) | 58.23 |
| max_return | æœ€é«˜æ¶¨å¹…(%) | 73.45 |

### 2. ç‰¹å¾æ•°æ®é›†
**æ–‡ä»¶**: `data/processed/feature_data_34d.csv`

| å­—æ®µ | è¯´æ˜ | ç¤ºä¾‹ |
|-----|------|------|
| sample_id | æ ·æœ¬ID | 0 |
| ts_code | è‚¡ç¥¨ä»£ç  | 600519.SH |
| name | è‚¡ç¥¨åç§° | è´µå·èŒ…å° |
| trade_date | äº¤æ˜“æ—¥æœŸ | 2015-05-01 |
| close | æ”¶ç›˜ä»· | 175.20 |
| pct_chg | æ¶¨è·Œå¹…(%) | 2.35 |
| total_mv | æ€»å¸‚å€¼(ä¸‡å…ƒ) | 3500000 |
| circ_mv | æµé€šå¸‚å€¼(ä¸‡å…ƒ) | 2800000 |
| ma5 | 5æ—¥å‡çº¿ | 172.5 |
| ma10 | 10æ—¥å‡çº¿ | 168.3 |
| volume_ratio | é‡æ¯” | 1.25 |
| days_to_t1 | è·T1å¤©æ•° | -34 |

### 3. ç»Ÿè®¡æŠ¥å‘Š
**æ–‡ä»¶**: `data/processed/sample_statistics.json`

```json
{
  "generation_time": "2024-12-22 18:30:00",
  "date_range": "20220101 - today",
  "total_samples": 156,
  "unique_stocks": 148,
  "avg_total_return": 67.8,
  "avg_max_return": 89.3,
  "feature_records": 5304,
  "lookback_days": 34
}
```

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. åˆ†æ‰¹å¤„ç†

ä¿®æ”¹è„šæœ¬ï¼Œæ¯æ¬¡å¤„ç†éƒ¨åˆ†è‚¡ç¥¨ï¼š

```python
# è·å–è‚¡ç¥¨åˆ—è¡¨
stock_list = self._get_valid_stock_list()

# åªå¤„ç†å‰100åª
stock_list = stock_list.head(100)
```

### 2. ä½¿ç”¨ç¼“å­˜

å°†ä¸‹è½½çš„æ•°æ®ä¿å­˜åˆ°æœ¬åœ°æ•°æ®åº“ï¼Œé¿å…é‡å¤ä¸‹è½½ã€‚

### 3. å¹¶è¡Œå¤„ç†

ä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼‰ã€‚

---

## å¸¸è§é—®é¢˜

### Q1: æŠ¥é”™"è¯·è®¾ç½®TUSHARE_TOKEN"
**A**: åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º`.env`æ–‡ä»¶ï¼Œæ·»åŠ ä½ çš„Tokenã€‚

### Q2: è¿è¡Œå¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ
**A**: 
1. å…ˆæ”¹ä¸ºå°æ—¥æœŸèŒƒå›´æµ‹è¯•ï¼ˆå¦‚æœ€è¿‘1å¹´ï¼‰
2. å‡å°‘è‚¡ç¥¨æ•°é‡
3. æ£€æŸ¥ç½‘ç»œè¿æ¥

### Q3: æœªæ‰¾åˆ°ä»»ä½•æ ·æœ¬ï¼Ÿ
**A**: å¯èƒ½åŸå› ï¼š
1. æ—¥æœŸèŒƒå›´å¤ªå°
2. ç­›é€‰æ¡ä»¶å¤ªä¸¥æ ¼
3. æ•°æ®è´¨é‡é—®é¢˜

å¯ä»¥é€‚å½“æ”¾å®½æ¡ä»¶è¿›è¡Œæµ‹è¯•ã€‚

### Q4: ç§¯åˆ†ä¸è¶³ï¼Ÿ
**A**: 
1. Tushareéœ€è¦è‡³å°‘2000ç§¯åˆ†æ‰èƒ½è·å–å¸‚å€¼æ•°æ®
2. å®Œå–„ä¸ªäººèµ„æ–™ã€æ¯æ—¥ç­¾åˆ°è·å–ç§¯åˆ†
3. æˆ–ä½¿ç”¨æèµ æ–¹å¼å¿«é€Ÿè·å¾—ç§¯åˆ†

### Q5: æ•°æ®ç¼ºå¤±æ€ä¹ˆåŠï¼Ÿ
**A**: 
- T1å‰34å¤©æ•°æ®ä¸è¶³çš„æ ·æœ¬ä¼šæœ‰è­¦å‘Š
- å¯ä»¥å¿½ç•¥è¿™äº›æ ·æœ¬æˆ–å‡å°‘lookback_days

---

## æ•°æ®éªŒè¯

è¿è¡Œå®Œæˆåï¼Œå»ºè®®è¿›è¡Œæ•°æ®éªŒè¯ï¼š

```python
import pandas as pd

# 1. æ£€æŸ¥æ ·æœ¬è´¨é‡
df_samples = pd.read_csv('data/processed/positive_samples.csv')
print(df_samples.describe())

# 2. æ£€æŸ¥ç‰¹å¾å®Œæ•´æ€§
df_features = pd.read_csv('data/processed/feature_data_34d.csv')
print(df_features.isnull().sum())

# 3. å¯è§†åŒ–åˆ†æ
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))

plt.subplot(131)
plt.hist(df_samples['total_return'], bins=30)
plt.title('æ€»æ¶¨å¹…åˆ†å¸ƒ')

plt.subplot(132)
plt.hist(df_samples['max_return'], bins=30)
plt.title('æœ€é«˜æ¶¨å¹…åˆ†å¸ƒ')

plt.subplot(133)
df_samples['ts_code'].value_counts().head(20).plot(kind='bar')
plt.title('Top20é«˜é¢‘è‚¡ç¥¨')

plt.tight_layout()
plt.savefig('data/processed/sample_analysis.png')
print("åˆ†æå›¾è¡¨å·²ä¿å­˜")
```

---

## ä¸‹ä¸€æ­¥

å®Œæˆæ­£æ ·æœ¬å‡†å¤‡åï¼š

1. **æ•°æ®åˆ†æ**
   - æŸ¥çœ‹æ ·æœ¬åˆ†å¸ƒ
   - æ£€æŸ¥æ•°æ®è´¨é‡
   - å¯è§†åŒ–åˆ†æ

2. **å‡†å¤‡è´Ÿæ ·æœ¬**
   - æœªæ¥ä¸‹è·Œæˆ–æ¨ªç›˜çš„è‚¡ç¥¨
   - éšæœºé‡‡æ ·æ­£å¸¸è‚¡ç¥¨

3. **ç‰¹å¾å·¥ç¨‹**
   - æ·»åŠ æ›´å¤šæŠ€æœ¯æŒ‡æ ‡
   - ç‰¹å¾æ ‡å‡†åŒ–
   - ç‰¹å¾é€‰æ‹©

4. **æ¨¡å‹è®­ç»ƒ**
   - ä½¿ç”¨XGBoost/LightGBM
   - äº¤å‰éªŒè¯
   - è¶…å‚æ•°è°ƒä¼˜

5. **å›æµ‹éªŒè¯**
   - å†å²å›æµ‹
   - ç»©æ•ˆè¯„ä¼°
   - ç­–ç•¥ä¼˜åŒ–

---

**ç¥æ•°æ®å‡†å¤‡é¡ºåˆ©ï¼** ğŸ“ŠğŸš€

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
- [é¡¹ç›®è®¾è®¡æ–‡æ¡£](PROJECT_DESIGN.md)
- [APIå‚è€ƒ](API_REFERENCE.md)
- [å¿«é€Ÿå¼€å§‹](QUICKSTART.md)

