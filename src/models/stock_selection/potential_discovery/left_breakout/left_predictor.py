"""
å·¦ä¾§æ½œåŠ›ç‰›è‚¡æ¨¡å‹ - è‚¡ç¥¨é¢„æµ‹è¯„åˆ†å™¨

å¯¹å½“å‰å¸‚åœºè‚¡ç¥¨è¿›è¡Œå®æ—¶è¯„åˆ†å’Œé¢„æµ‹ï¼Œè¯†åˆ«å·¦ä¾§äº¤æ˜“æœºä¼š
"""
import pandas as pd
import numpy as np
import os
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from src.utils.logger import log


class LeftBreakoutPredictor:
    """å·¦ä¾§æ½œåŠ›ç‰›è‚¡é¢„æµ‹å™¨"""

    def __init__(self, left_model):
        """
        åˆå§‹åŒ–é¢„æµ‹å™¨

        Args:
            left_model: å·¦ä¾§æ¨¡å‹å®ä¾‹
        """
        self.model = left_model
        self.feature_engineer = left_model.feature_engineer
        # ç¼“å­˜äº¤æ˜“æ—¥å†ï¼ˆæŒ‰æ—¥æœŸç¼“å­˜ï¼‰
        self._calendar_cache = {}

    def predict_current_market(
        self,
        prediction_date: str = None,
        top_n: int = 50,
        min_probability: float = 0.1,
        max_stocks: int = None
    ) -> pd.DataFrame:
        """
        å¯¹å½“å‰å¸‚åœºè¿›è¡Œé¢„æµ‹

        Args:
            prediction_date: é¢„æµ‹æ—¥æœŸï¼Œé»˜è®¤ä»Šå¤©
            top_n: è¿”å›å‰Nä¸ªç»“æœ
            min_probability: æœ€å°æ¦‚ç‡é˜ˆå€¼
            max_stocks: æœ€å¤§å¤„ç†è‚¡ç¥¨æ•°

        Returns:
            é¢„æµ‹ç»“æœDataFrame
        """
        if prediction_date is None:
            prediction_date = datetime.now().strftime('%Y%m%d')

        # 1. è·å–å¸‚åœºè‚¡ç¥¨åˆ—è¡¨
        market_stocks = self._get_market_stocks()
        if market_stocks.empty:
            log.error("æ— æ³•è·å–å¸‚åœºè‚¡ç¥¨åˆ—è¡¨")
            return pd.DataFrame()

        if max_stocks:
            market_stocks = market_stocks.head(max_stocks)

        log.info(f"ğŸ“Š å¤„ç†è‚¡ç¥¨: {len(market_stocks)} åª")

        # 2. é¢„åŠ è½½äº¤æ˜“æ—¥å†
        trading_days = self._get_trading_days_cached(prediction_date)
        if not trading_days or len(trading_days) < 20:
            log.error(f"äº¤æ˜“æ—¥å†ä¸è¶³: {len(trading_days) if trading_days else 0} å¤©")
            return pd.DataFrame()


        # 3. ä¸ºæ¯åªè‚¡ç¥¨æå–ç‰¹å¾
        all_features = []
        success_count = 0
        total = len(market_stocks)
        start_time = datetime.now()
        last_check_time = start_time
        last_check_count = 0

        for idx, row in market_stocks.iterrows():
            ts_code = row['ts_code']
            name = row['name']

            # æ˜¾ç¤ºè¿›åº¦
            current = idx + 1
            if current % 100 == 0 or current == total or (total > 1000 and current % (total // 10) == 0):
                progress_pct = current / total * 100
                now = datetime.now()
                elapsed = (now - start_time).total_seconds()
                
                # ä½¿ç”¨æœ€è¿‘100åªçš„é€Ÿåº¦æ¥ä¼°ç®—ï¼ˆæ›´å‡†ç¡®ï¼‰
                recent_elapsed = (now - last_check_time).total_seconds()
                recent_count = current - last_check_count
                recent_speed = recent_count / recent_elapsed if recent_elapsed > 0 else 0
                
                # å¦‚æœæœ€è¿‘é€Ÿåº¦å¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨ï¼›å¦åˆ™ä½¿ç”¨å¹³å‡é€Ÿåº¦
                if recent_speed > 0 and recent_count >= 50:
                    speed = recent_speed
                else:
                    speed = current / elapsed if elapsed > 0 else 0
                
                remaining = (total - current) / speed if speed > 0 else 0
                log.info(f"è¿›åº¦: {current}/{total} ({progress_pct:.1f}%) | æˆåŠŸ: {success_count} | é€Ÿåº¦: {speed:.1f}åª/ç§’ | å‰©ä½™: {remaining/60:.1f}åˆ†é’Ÿ")
                
                # æ›´æ–°æ£€æŸ¥ç‚¹
                last_check_time = now
                last_check_count = current

            try:
                stock_features = self._extract_stock_features(
                    ts_code, name, prediction_date, trading_days=trading_days
                )
                if not stock_features.empty:
                    all_features.append(stock_features)
                    success_count += 1
            except Exception as e:
                # åªåœ¨debugæ¨¡å¼ä¸‹è®°å½•è¯¦ç»†é”™è¯¯
                log.debug(f"æå– {ts_code} ç‰¹å¾å¤±è´¥: {e}")
                continue

        log.info(f"âœ… ç‰¹å¾æå–å®Œæˆ: {success_count}/{total} æˆåŠŸ ({success_count/total*100:.1f}%)")

        if not all_features:
            log.error("æ²¡æœ‰æˆåŠŸæå–åˆ°ä»»ä½•è‚¡ç¥¨ç‰¹å¾")
            return pd.DataFrame()

        # 4. åˆå¹¶ç‰¹å¾å¹¶é¢„æµ‹
        features_df = pd.concat(all_features, ignore_index=True)
        predictions = self.model.predict_stocks(features_df)

        if predictions.empty:
            log.error("æ¨¡å‹é¢„æµ‹å¤±è´¥")
            return pd.DataFrame()

        predictions['prediction_date'] = prediction_date
        predictions['rank'] = range(1, len(predictions) + 1)
        filtered_predictions = self._apply_filters(predictions, min_probability, top_n)

        log.info(f"ğŸ¯ æ¨¡å‹é¢„æµ‹å®Œæˆ: {len(filtered_predictions)} åªè‚¡ç¥¨")

        return filtered_predictions

    def _get_trading_days_cached(self, prediction_date: str) -> List[str]:
        """
        è·å–äº¤æ˜“æ—¥å†ï¼ˆå¸¦ç¼“å­˜ï¼‰

        Args:
            prediction_date: é¢„æµ‹æ—¥æœŸ

        Returns:
            äº¤æ˜“æ—¥åˆ—è¡¨
        """
        # æ£€æŸ¥ç¼“å­˜
        if prediction_date in self._calendar_cache:
            return self._calendar_cache[prediction_date]

        try:
            end_date = str(prediction_date)
            import datetime as dt
            end_dt = dt.datetime.strptime(end_date, '%Y%m%d')
            start_dt = end_dt - dt.timedelta(days=60)
            start_date = start_dt.strftime('%Y%m%d')

            # è·å–äº¤æ˜“æ—¥å†
            calendar_df = self.model.dm.get_trade_calendar(start_date, end_date)
            if calendar_df.empty:
                return []

            # ç­›é€‰äº¤æ˜“æ—¥
            trading_days = calendar_df[calendar_df['is_open'] == 1]['cal_date'].sort_values().tolist()
            
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼ˆç¡®ä¿æ ¼å¼ä¸€è‡´ï¼‰
            trading_days_str = []
            for td in trading_days:
                if isinstance(td, pd.Timestamp):
                    trading_days_str.append(td.strftime('%Y%m%d'))
                elif isinstance(td, str):
                    # å¦‚æœå·²ç»æ˜¯å­—ç¬¦ä¸²ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
                    if len(td) == 8:
                        trading_days_str.append(td)
                    else:
                        # å°è¯•è½¬æ¢
                        try:
                            dt_obj = pd.to_datetime(td)
                            trading_days_str.append(dt_obj.strftime('%Y%m%d'))
                        except:
                            trading_days_str.append(str(td))
                else:
                    trading_days_str.append(str(td))
            
            # ç¼“å­˜ç»“æœ
            self._calendar_cache[prediction_date] = trading_days_str
            log.info(f"äº¤æ˜“æ—¥å†è½¬æ¢å®Œæˆ: {len(trading_days_str)} ä¸ªäº¤æ˜“æ—¥ï¼Œç¤ºä¾‹: {trading_days_str[:3] if trading_days_str else 'æ— '}")
            return trading_days_str

        except Exception as e:
            log.warning(f"è·å–äº¤æ˜“æ—¥å†å¤±è´¥ {prediction_date}: {e}")
            return []

    def _extract_stock_features(
        self, 
        ts_code: str, 
        name: str, 
        prediction_date: str,
        trading_days: List[str] = None
    ) -> pd.DataFrame:
        """
        æå–å•åªè‚¡ç¥¨çš„ç‰¹å¾

        Args:
            ts_code: è‚¡ç¥¨ä»£ç 
            name: è‚¡ç¥¨åç§°
            prediction_date: é¢„æµ‹æ—¥æœŸ
            trading_days: äº¤æ˜“æ—¥åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™è·³è¿‡è·å–äº¤æ˜“æ—¥å†ï¼‰

        Returns:
            è‚¡ç¥¨ç‰¹å¾DataFrame
        """
        try:
            end_date = str(prediction_date)

            # å¦‚æœæ²¡æœ‰æä¾›äº¤æ˜“æ—¥å†ï¼Œåˆ™è·å–
            if trading_days is None:
                trading_days = self._get_trading_days_cached(prediction_date)

            if not trading_days or len(trading_days) < 20:  # æœ€å°‘éœ€è¦20å¤©æ•°æ®
                log.debug(f"äº¤æ˜“æ—¥å†ä¸è¶³ {ts_code}: {len(trading_days) if trading_days else 0} å¤©")
                return pd.DataFrame()

            # å–æœ€è¿‘çš„34ä¸ªäº¤æ˜“æ—¥
            recent_trading_days = trading_days[-34:] if len(trading_days) >= 34 else trading_days
            if not recent_trading_days:
                log.debug(f"æ²¡æœ‰å¯ç”¨çš„äº¤æ˜“æ—¥ {ts_code}")
                return pd.DataFrame()
            
            start_date = recent_trading_days[0]
            
            # ç¡®ä¿start_dateæ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼ˆYYYYMMDDï¼‰
            if isinstance(start_date, pd.Timestamp):
                start_date = start_date.strftime('%Y%m%d')
            elif not isinstance(start_date, str) or len(start_date) != 8:
                # å°è¯•è½¬æ¢
                try:
                    if isinstance(start_date, (int, float)):
                        start_date = str(int(start_date))
                    else:
                        dt_obj = pd.to_datetime(str(start_date))
                        start_date = dt_obj.strftime('%Y%m%d')
                except:
                    log.debug(f"æ— æ³•è½¬æ¢start_dateæ ¼å¼ {ts_code}: {start_date}")
                    return pd.DataFrame()

            # è·å–æ—¥çº¿æ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡
            try:
                df = self.model.dm.get_complete_data(ts_code, start_date, end_date)
            except Exception as e:
                log.debug(f"è·å–æ—¥çº¿æ•°æ®å¤±è´¥ {ts_code} [{start_date} - {end_date}]: {e}")
                return pd.DataFrame()
                
            if df.empty:
                log.debug(f"æ—¥çº¿æ•°æ®ä¸ºç©º {ts_code} [{start_date} - {end_date}]")
                return pd.DataFrame()
                
            if len(df) < 20:
                log.debug(f"æ—¥çº¿æ•°æ®ä¸è¶³ {ts_code}: åªæœ‰ {len(df)} å¤©ï¼Œéœ€è¦è‡³å°‘20å¤©")
                return pd.DataFrame()

            # è·å–æŠ€æœ¯å› å­æ•°æ®ï¼ˆå¯é€‰ï¼Œå¤±è´¥ä¸å½±å“ï¼‰
            try:
                df_factor = self.model.dm.get_stk_factor(ts_code, start_date, end_date)
                if not df_factor.empty:
                    df = pd.merge(df, df_factor, on='trade_date', how='left')
            except Exception as e:
                log.debug(f"è·å–æŠ€æœ¯å› å­å¤±è´¥ {ts_code} {end_date}ï¼Œç»§ç»­ä½¿ç”¨åŸºç¡€æ•°æ®: {e}")

            # æ·»åŠ å…ƒæ•°æ®
            df['ts_code'] = ts_code
            df['name'] = name
            df['t0_date'] = prediction_date  # é¢„æµ‹æ—¥æœŸä½œä¸ºT0
            df['label'] = 0  # é¢„æµ‹æ—¶æ ‡ç­¾ä¸º0
            df['unique_sample_id'] = 0  # ä¸´æ—¶ID

            # æ·»åŠ days_to_t1å­—æ®µ
            # æ³¨æ„ï¼šé¢„æµ‹æ—¶ï¼Œprediction_dateæ˜¯T0æ—¥æœŸï¼Œæˆ‘ä»¬éœ€è¦T0ä¹‹å‰çš„æ•°æ®
            df['trade_date_dt'] = pd.to_datetime(df['trade_date'])
            t0_dt = pd.to_datetime(str(prediction_date), format='%Y%m%d')
            df['days_to_t1'] = (df['trade_date_dt'] - t0_dt).dt.days

            # åªä¿ç•™T0å½“å¤©åŠä¹‹å‰çš„æ•°æ®ï¼ˆdays_to_t1 <= 0ï¼‰
            # å¯¹äºé¢„æµ‹åœºæ™¯ï¼Œæˆ‘ä»¬åªéœ€è¦T0ä¹‹å‰çš„å†å²æ•°æ®
            df_before_t0 = df[df['days_to_t1'] <= 0].copy()
            
            if len(df_before_t0) < 20:
                # è¯¦ç»†æ—¥å¿—ç”¨äºè°ƒè¯•
                if len(df) > 0:
                    min_days = df['days_to_t1'].min()
                    max_days = df['days_to_t1'].max()
                    log.debug(f"T0å‰æ•°æ®ä¸è¶³ {ts_code}: åŸå§‹{len(df)}å¤©ï¼ŒT0å‰{len(df_before_t0)}å¤©ï¼Œdays_to_t1èŒƒå›´: {min_days:.0f} åˆ° {max_days:.0f}, T0={prediction_date}")
                else:
                    log.debug(f"æ•°æ®ä¸ºç©º {ts_code}")
                return pd.DataFrame()
            
            # å–æœ€è¿‘çš„34å¤©æ•°æ®ï¼ˆT0å‰34å¤©ï¼‰
            df = df_before_t0.sort_values('days_to_t1', ascending=False).head(34).sort_values('days_to_t1').reset_index(drop=True)

            if len(df) < 20:
                log.debug(f"æœ€ç»ˆæ•°æ®ä¸è¶³ {ts_code}: åªæœ‰ {len(df)} å¤©")
                return pd.DataFrame()

            # ä½¿ç”¨ç‰¹å¾å·¥ç¨‹å™¨æå–æœ€ç»ˆç‰¹å¾
            try:
                features_df = self.feature_engineer.extract_features(df)
                if features_df.empty:
                    log.debug(f"ç‰¹å¾æå–è¿”å›ç©º {ts_code}")
                return features_df
            except Exception as e:
                log.debug(f"ç‰¹å¾æå–å¼‚å¸¸ {ts_code}: {e}")
                return pd.DataFrame()

        except Exception as e:
            log.debug(f"æå–è‚¡ç¥¨ {ts_code} ç‰¹å¾å¤±è´¥: {e}")
            return pd.DataFrame()

    def _get_market_stocks(self) -> pd.DataFrame:
        """
        è·å–å½“å‰å¸‚åœºè‚¡ç¥¨åˆ—è¡¨

        Returns:
            å¸‚åœºè‚¡ç¥¨DataFrame
        """
        try:
            # è·å–åŸºç¡€è‚¡ç¥¨åˆ—è¡¨
            stock_list = self.model.dm.get_stock_list()

            # åº”ç”¨ç­›é€‰æ¡ä»¶
            market_stocks = stock_list[
                # æ’é™¤STè‚¡ç¥¨
                (~stock_list['name'].str.contains('ST', na=False)) &
                (~stock_list['name'].str.contains('\\*ST', na=False)) &
                (~stock_list['name'].str.contains('SST', na=False)) &
                (~stock_list['name'].str.contains('S\\*ST', na=False)) &
                # æ’é™¤åŒ—äº¤æ‰€
                (~stock_list['ts_code'].str.endswith('.BJ', na=False)) &
                # ä¸Šå¸‚è¶…è¿‡åŠå¹´
                (stock_list['list_date'].notna())
            ].copy()

            # è®¡ç®—ä¸Šå¸‚å¤©æ•°
            current_date = datetime.now()
            market_stocks['list_date_dt'] = pd.to_datetime(market_stocks['list_date'], format='%Y%m%d', errors='coerce')
            market_stocks['listing_days'] = (current_date - market_stocks['list_date_dt']).dt.days
            market_stocks = market_stocks[market_stocks['listing_days'] > 180]

            # é€‰æ‹©éœ€è¦çš„åˆ—
            result = market_stocks[['ts_code', 'name', 'list_date']].reset_index(drop=True)

            return result

        except Exception as e:
            log.error(f"è·å–å¸‚åœºè‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return pd.DataFrame()

    def _apply_filters(
        self,
        predictions: pd.DataFrame,
        min_probability: float,
        top_n: int
    ) -> pd.DataFrame:
        """
        åº”ç”¨ç­›é€‰æ¡ä»¶

        Args:
            predictions: é¢„æµ‹ç»“æœ
            min_probability: æœ€å°æ¦‚ç‡
            top_n: å‰Nä¸ª

        Returns:
            ç­›é€‰åçš„ç»“æœ
        """
        try:
            # åº”ç”¨æ¦‚ç‡é˜ˆå€¼
            filtered = predictions[predictions['probability'] >= min_probability].copy()

            # é™åˆ¶æ•°é‡
            if len(filtered) > top_n:
                filtered = filtered.head(top_n)

            # é‡æ–°æ’åº
            filtered = filtered.reset_index(drop=True)
            filtered['final_rank'] = range(1, len(filtered) + 1)

            return filtered

        except Exception as e:
            log.error(f"åº”ç”¨ç­›é€‰æ¡ä»¶å¤±è´¥: {e}")
            return predictions

    def generate_prediction_report(
        self,
        predictions: pd.DataFrame,
        output_dir: str = None,
        include_market_analysis: bool = True,
        include_recommendations: bool = True,
        include_financial_info: bool = True
    ) -> str:
        """
        ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š

        Args:
            predictions: é¢„æµ‹ç»“æœDataFrame
            output_dir: è¾“å‡ºç›®å½•
            include_market_analysis: æ˜¯å¦åŒ…å«å¸‚åœºåˆ†æï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
            include_recommendations: æ˜¯å¦åŒ…å«æ¨èå»ºè®®ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
            include_financial_info: æ˜¯å¦åŒ…å«è´¢åŠ¡ä¿¡æ¯ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰

        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        if output_dir is None:
            # æœ€æ–°ç»“æœå­˜æ”¾åœ¨ data/result/{model_name}/
            output_dir = f"data/result/left_breakout"

        os.makedirs(output_dir, exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = os.path.join(output_dir, f"left_breakout_prediction_report_{timestamp}.txt")

        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("="*80 + "\n")
                f.write("ğŸ“ˆ å·¦ä¾§æ½œåŠ›ç‰›è‚¡é¢„æµ‹æŠ¥å‘Š\n")
                f.write("="*80 + "\n\n")

                # æŠ¥å‘ŠåŸºæœ¬ä¿¡æ¯
                prediction_date = predictions['prediction_date'].iloc[0] if not predictions.empty else datetime.now().strftime('%Y%m%d')
                f.write(f"ğŸ“… é¢„æµ‹æ—¥æœŸ: {prediction_date}\n")
                f.write(f"â° ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"ğŸ¯ æ¨¡å‹ç‰ˆæœ¬: {self.model.config['model']['version']}\n\n")

                if predictions.empty:
                    f.write("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨\n\n")
                    return report_file

                # åªæ˜¾ç¤ºæœ€å…³é”®çš„è‚¡ç¥¨è¯„åˆ†ä¿¡æ¯
                f.write(self._generate_stock_scores(predictions))

            log.info(f"é¢„æµ‹æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

            # ä¿å­˜CSVç»“æœ
            csv_file = os.path.join(output_dir, f"left_breakout_predictions_{timestamp}.csv")
            predictions.to_csv(csv_file, index=False, encoding='utf-8')
            log.info(f"é¢„æµ‹ç»“æœå·²ä¿å­˜: {csv_file}")

            return report_file

        except Exception as e:
            log.error(f"ç”Ÿæˆé¢„æµ‹æŠ¥å‘Šå¤±è´¥: {e}")
            return ""

    def _generate_stock_scores(self, predictions: pd.DataFrame) -> str:
        """ç”Ÿæˆè‚¡ç¥¨è¯„åˆ†ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼Œåªæ˜¾ç¤ºå…³é”®ä¿¡æ¯ï¼‰"""
        content = "ğŸ† Top 50 è‚¡ç¥¨è¯„åˆ†\n" + "="*80 + "\n\n"
        
        try:
            # è¡¨å¤´
            content += f"{'æ’å':<6} {'è‚¡ç¥¨ä»£ç ':<12} {'è‚¡ç¥¨åç§°':<15} {'é¢„æµ‹æ¦‚ç‡':<12} {'æ¨èåº¦':<10}\n"
            content += "-"*80 + "\n"
            
            # Top 50è‚¡ç¥¨åˆ—è¡¨
            top_50 = predictions.head(50)
            for i, (_, stock) in enumerate(top_50.iterrows(), 1):
                ts_code = stock.get('ts_code', 'N/A')
                name = stock.get('name', 'N/A')
                prob = stock.get('probability', 0)
                prob_pct = prob * 100
                
                # æ¨èåº¦æ ‡è¯†
                if i <= 3:
                    rank_icon = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰"
                else:
                    rank_icon = "â­"
                
                # æ ¼å¼åŒ–åç§°ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
                name_display = name[:12] if len(name) > 12 else name
                
                content += f"{rank_icon} {i:<4} {ts_code:<12} {name_display:<15} {prob_pct:>10.2f}% {rank_icon:<10}\n"
            
            content += "\n" + "="*80 + "\n\n"
            
            # ç»Ÿè®¡ä¿¡æ¯
            total = len(predictions)
            avg_prob = predictions['probability'].mean()
            high_prob = len(predictions[predictions['probability'] > 0.8])
            
            content += "ğŸ“Š ç»Ÿè®¡ä¿¡æ¯\n"
            content += f"â€¢ æ€»æ¨èæ•°é‡: {total} åª\n"
            content += f"â€¢ å¹³å‡é¢„æµ‹æ¦‚ç‡: {avg_prob*100:.2f}%\n"
            content += f"â€¢ é«˜æ¦‚ç‡è‚¡ç¥¨(>80%): {high_prob} åª\n"
            content += "\n"
            
        except Exception as e:
            log.error(f"ç”Ÿæˆè‚¡ç¥¨è¯„åˆ†å¤±è´¥: {e}")
            content += "ç”Ÿæˆè‚¡ç¥¨è¯„åˆ†å¤±è´¥\n\n"
        
        return content

    def _generate_market_analysis(self, predictions: pd.DataFrame) -> str:
        """ç”Ÿæˆå¸‚åœºåˆ†æéƒ¨åˆ†"""
        analysis = "ğŸ“Š å¸‚åœºåˆ†æ\n" + "-"*40 + "\n\n"

        try:
            total_stocks = len(predictions)
            avg_probability = predictions['probability'].mean()
            high_prob_stocks = len(predictions[predictions['probability'] > 0.7])

            analysis += f"â€¢ æ‰«æè‚¡ç¥¨æ€»æ•°: {total_stocks:,}\n"
            analysis += f"â€¢ å¹³å‡æ¦‚ç‡: {avg_probability:.4f}\n"
            analysis += f"â€¢ é«˜æ¦‚ç‡è‚¡ç¥¨(>0.7): {high_prob_stocks}\n\n"

            # æ¦‚ç‡åˆ†å¸ƒåˆ†æ
            prob_ranges = [
                (0.8, 1.0, "æé«˜"),
                (0.6, 0.8, "è¾ƒé«˜"),
                (0.4, 0.6, "ä¸­ç­‰"),
                (0.2, 0.4, "è¾ƒä½"),
                (0.0, 0.2, "æä½")
            ]

            analysis += "æ¦‚ç‡åˆ†å¸ƒ:\n"
            for min_prob, max_prob, level in prob_ranges:
                count = len(predictions[(predictions['probability'] >= min_prob) &
                                      (predictions['probability'] < max_prob)])
                if count > 0:
                    analysis += f"  â€¢ {level}æ¦‚ç‡({min_prob}-{max_prob}): {count} åª\n"
            analysis += "\n"

            # å¸‚åœºæƒ…ç»ªåˆ¤æ–­
            if avg_probability > 0.6:
                market_sentiment = "ä¹è§‚"
            elif avg_probability > 0.4:
                market_sentiment = "æ¸©å’Œ"
            elif avg_probability > 0.2:
                market_sentiment = "è°¨æ…"
            else:
                market_sentiment = "æ‚²è§‚"

            analysis += f"ğŸ§  å¸‚åœºæƒ…ç»ª: {market_sentiment}\n\n"

        except Exception as e:
            log.debug(f"ç”Ÿæˆå¸‚åœºåˆ†æå¤±è´¥: {e}")
            analysis += "å¸‚åœºåˆ†æç”Ÿæˆå¤±è´¥\n\n"

        return analysis

    def _generate_recommendations(self, predictions: pd.DataFrame) -> str:
        """ç”Ÿæˆæ¨èå»ºè®®éƒ¨åˆ†"""
        recommendations = "ğŸ¯ æŠ•èµ„æ¨è\n" + "-"*40 + "\n\n"

        try:
            # Top 10æ¨è
            top_10 = predictions.head(10)

            for i, (_, stock) in enumerate(top_10.iterrows(), 1):
                prob_pct = stock['probability'] * 100

                if prob_pct > 80:
                    risk_level = "ğŸ”´ é«˜é£é™©é«˜æ”¶ç›Š"
                elif prob_pct > 60:
                    risk_level = "ğŸŸ  ä¸­é«˜é£é™©ä¸­é«˜æ”¶ç›Š"
                elif prob_pct > 40:
                    risk_level = "ğŸŸ¡ ä¸­é£é™©ä¸­æ”¶ç›Š"
                else:
                    risk_level = "ğŸŸ¢ ä¸­ä½é£é™©ä¸­ä½æ”¶ç›Š"

                recommendations += f"   {risk_level} | æ¦‚ç‡: {prob_pct:.2f}%\n"

                # ä¸ºå‰3åæ·»åŠ è¯¦ç»†åˆ†æ
                if i <= 3:
                    recommendations += f"   ğŸ’¡ å·¦ä¾§äº¤æ˜“æœºä¼šï¼šè¯¥è‚¡æ˜¾ç¤ºå‡ºåº•éƒ¨éœ‡è¡+é¢„è½¬ä¿¡å·çš„ç‰¹å¾\n"
                    recommendations += f"   â° å»ºè®®è§‚å¯ŸæœŸï¼š1-2å‘¨ï¼Œç­‰å¾…æ›´æ˜ç¡®çš„ä¸Šçªç ´ä¿¡å·\n"
                    recommendations += f"   ğŸ“Š é£é™©æ§åˆ¶ï¼šè®¾ç½®2-3æˆä»“ä½ï¼Œè·Œç ´æ”¯æ’‘åŠæ—¶æ­¢æŸ\n\n"

        except Exception as e:
            log.debug(f"ç”Ÿæˆæ¨èå»ºè®®å¤±è´¥: {e}")
            recommendations += "æ¨èå»ºè®®ç”Ÿæˆå¤±è´¥\n\n"

        return recommendations

    def _generate_financial_info(self, predictions: pd.DataFrame) -> str:
        """ç”Ÿæˆè´¢åŠ¡ä¿¡æ¯éƒ¨åˆ†"""
        financial_info = "ğŸ’° è´¢åŠ¡ç­›é€‰å»ºè®®\n" + "-"*40 + "\n\n"

        try:
            financial_info += "âš ï¸  é‡è¦æé†’ï¼šå·¦ä¾§äº¤æ˜“æ›´æ³¨é‡æŠ€æœ¯é¢ï¼Œè´¢åŠ¡é¢ä½œä¸ºè¾…åŠ©ç­›é€‰\n\n"
            financial_info += "å»ºè®®é‡ç‚¹å…³æ³¨çš„è´¢åŠ¡æŒ‡æ ‡:\n"
            financial_info += "â€¢ è¥æ”¶ç¨³å®šæ€§ï¼šè¿ç»­3å¹´è¥æ”¶æ­£å¢é•¿\n"
            financial_info += "â€¢ ç›ˆåˆ©èƒ½åŠ›ï¼šè¿ç»­3å¹´å‡€åˆ©æ¶¦ä¸ºæ­£\n"
            financial_info += "â€¢ ç°é‡‘æµï¼šç»è¥ç°é‡‘æµå¥åº·\n"
            financial_info += "â€¢ ä¼°å€¼æ°´å¹³ï¼šç›¸å¯¹åˆç†ï¼Œä¸è¿‡åº¦é«˜ä¼°\n\n"

            financial_info += "è´¢åŠ¡é£é™©æç¤º:\n"
            financial_info += "â€¢ ä¼˜å…ˆé€‰æ‹©åŸºæœ¬é¢æ‰å®çš„å…¬å¸\n"
            financial_info += "â€¢ å…³æ³¨è¡Œä¸šæ™¯æ°”åº¦å’Œå…¬å¸ç«äº‰åœ°ä½\n"
            financial_info += "â€¢ å®šæœŸè·Ÿè¸ªè´¢åŠ¡æ•°æ®å˜åŒ–\n\n"

        except Exception as e:
            log.debug(f"ç”Ÿæˆè´¢åŠ¡ä¿¡æ¯å¤±è´¥: {e}")
            financial_info += "è´¢åŠ¡ä¿¡æ¯ç”Ÿæˆå¤±è´¥\n\n"

        return financial_info

    def _generate_risk_warnings(self) -> str:
        """ç”Ÿæˆé£é™©æç¤º"""
        warnings = "âš ï¸  é£é™©æç¤º\n" + "-"*40 + "\n\n"

        warnings += "ğŸš¨ å·¦ä¾§äº¤æ˜“é£é™©è¾ƒé«˜ï¼Œè¯·åŠ¡å¿…æ³¨æ„ï¼š\n\n"

        warnings += "1. ğŸ¯ å·¦ä¾§äº¤æ˜“ç‰¹æ€§\n"
        warnings += "   â€¢ æå‰å¸ƒå±€æœ‰é£é™©ï¼Œå­˜åœ¨åˆ¤æ–­é”™è¯¯å¯èƒ½\n"
        warnings += "   â€¢ éœ€è¦è¾ƒé•¿æ—¶é—´ç­‰å¾…ï¼Œè€ƒéªŒæŒè‚¡è€å¿ƒ\n"
        warnings += "   â€¢ å¸‚åœºç¯å¢ƒå˜åŒ–å¯èƒ½å¯¼è‡´é¢„æœŸè½ç©º\n\n"

        warnings += "2. ğŸ’° ä»“ä½ç®¡ç†\n"
        warnings += "   â€¢ å»ºè®®å•è‚¡ç¥¨ä¸è¶…è¿‡æ€»èµ„äº§çš„2-3%\n"
        warnings += "   â€¢ åˆ†æ•£æŠ•èµ„ï¼Œæ§åˆ¶æ•´ä½“é£é™©\n"
        warnings += "   â€¢ è®¾ç½®æ˜ç¡®çš„æ­¢æŸç‚¹å’Œæ­¢ç›ˆç‚¹\n\n"

        warnings += "3. ğŸ“Š æŠ€æœ¯åˆ†æå±€é™\n"
        warnings += "   â€¢ å†å²è§„å¾‹ä¸å¿…ç„¶é‡æ¼”\n"
        warnings += "   â€¢ æ¨¡å‹åŸºäºå†å²æ•°æ®ï¼Œæœªæ¥è¡¨ç°ä¸ä¿è¯\n"
        warnings += "   â€¢ çªå‘äº‹ä»¶å¯èƒ½å½±å“èµ°åŠ¿\n\n"

        warnings += "4. ğŸ¢ åŸºæœ¬é¢éªŒè¯\n"
        warnings += "   â€¢ æŠ€æœ¯ä¿¡å·ä»…ä¾›å‚è€ƒ\n"
        warnings += "   â€¢ å¿…é¡»ç»“åˆåŸºæœ¬é¢åˆ†æ\n"
        warnings += "   â€¢ å…³æ³¨è¡Œä¸šæ”¿ç­–å’Œå…¬å¸æ²»ç†\n\n"

        warnings += "5. ğŸ’¡ æŠ•èµ„å»ºè®®\n"
        warnings += "   â€¢ æŠ•èµ„å‰å……åˆ†äº†è§£é£é™©\n"
        warnings += "   â€¢ é€‚åˆæœ‰ç»éªŒçš„æŠ•èµ„è€…\n"
        warnings += "   â€¢ å»ºè®®ä»å°ä»“ä½å¼€å§‹è¯•æ°´\n\n"

        warnings += "ğŸ“ å…è´£å£°æ˜ï¼š\n"
        warnings += "æœ¬æŠ¥å‘Šä»…ä¾›å­¦ä¹ ç ”ç©¶ä½¿ç”¨ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚\n"
        warnings += "æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ï¼\n\n"

        return warnings

    def _generate_technical_notes(self) -> str:
        """ç”ŸæˆæŠ€æœ¯è¯´æ˜"""
        notes = "ğŸ”§ æŠ€æœ¯è¯´æ˜\n" + "-"*40 + "\n\n"

        notes += "ğŸ¤– æ¨¡å‹è¯´æ˜:\n"
        notes += "â€¢ åŸºäºXGBoostçš„æœºå™¨å­¦ä¹ æ¨¡å‹\n"
        notes += "â€¢ è®­ç»ƒæ•°æ®ï¼š2000å¹´ä»¥æ¥25å¹´å†å²æ•°æ®\n"
        notes += "â€¢ ç‰¹å¾æ•°é‡ï¼š50+æŠ€æœ¯æŒ‡æ ‡å’Œç»Ÿè®¡ç‰¹å¾\n"
        notes += "â€¢ ç›®æ ‡ï¼šè¯†åˆ«åº•éƒ¨éœ‡è¡+é¢„è½¬ä¿¡å·çš„è‚¡ç¥¨\n\n"

        notes += "ğŸ“ˆ å·¦ä¾§äº¤æ˜“ç­–ç•¥:\n"
        notes += "â€¢ è¯†åˆ«å³å°†èµ·çˆ†çš„æ½œåŠ›è‚¡\n"
        notes += "â€¢ æå‰1-2å‘¨å‘ç°æŠ•èµ„æœºä¼š\n"
        notes += "â€¢ å‡å°‘æ—¶é—´æˆæœ¬ï¼Œæé«˜èµ„é‡‘æ•ˆç‡\n\n"

        notes += "ğŸ¯ é€‰è‚¡æ ‡å‡†:\n"
        notes += "â€¢ è¿‡å»60å¤©ç´¯è®¡æ¶¨å¹… < 20%ï¼ˆåº•éƒ¨éœ‡è¡ï¼‰\n"
        notes += "â€¢ æœªæ¥45å¤©ç´¯è®¡æ¶¨å¹… > 50%ï¼ˆä¸Šæ¶¨ç›®æ ‡ï¼‰\n"
        notes += "â€¢ MACDé‡‘å‰ã€çªç ´MA20ç­‰é¢„è½¬ä¿¡å·\n"
        notes += "â€¢ é‡èƒ½æ¸©å’Œæ”¾å¤§ã€æŠ€æœ¯æŒ‡æ ‡å¥åº·\n\n"

        return notes
