"""
è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å·¥å…·
ç”¨äºæ–°è®­ç»ƒæ¡†æ¶ä¸‹çš„æ ·æœ¬è´¨é‡æ£€æŸ¥å’Œå› å­é‡è¦æ€§åˆ†æ
"""
import sys
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import pandas as pd
import numpy as np
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix
import json

from src.utils.logger import log


class TrainingVisualizer:
    """è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å™¨"""
    
    def __init__(self, output_dir: str = "data/training/charts"):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨
        
        Args:
            output_dir: å›¾è¡¨è¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        log.info(f"å¯è§†åŒ–å›¾è¡¨è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def visualize_sample_quality(self, df_samples: pd.DataFrame, save_prefix: str = "sample_quality"):
        """
        å¯è§†åŒ–æ ·æœ¬è´¨é‡
        
        Args:
            df_samples: æ ·æœ¬DataFrameï¼ˆåŒ…å«æ­£æ ·æœ¬æˆ–è´Ÿæ ·æœ¬ï¼‰
            save_prefix: ä¿å­˜æ–‡ä»¶å‰ç¼€
        """
        log.info("="*80)
        log.info("ç”Ÿæˆæ ·æœ¬è´¨é‡å¯è§†åŒ–å›¾è¡¨")
        log.info("="*80)
        
        if df_samples is None or len(df_samples) == 0:
            log.warning("æ ·æœ¬æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡å¯è§†åŒ–")
            return
        
        # 1. æ¶¨å¹…åˆ†å¸ƒç›´æ–¹å›¾
        if 'total_return' in df_samples.columns:
            self._plot_return_distribution(df_samples, save_prefix)
        
        # 2. æ—¶é—´åˆ†å¸ƒ
        if 't1_date' in df_samples.columns:
            self._plot_time_distribution(df_samples, save_prefix)
        
        # 3. æ¶¨å¹…ç»Ÿè®¡ç®±çº¿å›¾
        if 'total_return' in df_samples.columns and 'max_return' in df_samples.columns:
            self._plot_return_boxplot(df_samples, save_prefix)
        
        # 4. å¼‚å¸¸å€¼æ£€æµ‹å¯è§†åŒ–
        if 'total_return' in df_samples.columns:
            self._plot_anomaly_detection(df_samples, save_prefix)
        
        # 5. æ ·æœ¬è´¨é‡ç»¼åˆæŠ¥å‘Š
        self._generate_quality_report(df_samples, save_prefix)
        
        log.success(f"âœ“ æ ·æœ¬è´¨é‡å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆåˆ°: {self.output_dir}")
    
    def _plot_return_distribution(self, df: pd.DataFrame, prefix: str):
        """ç»˜åˆ¶æ¶¨å¹…åˆ†å¸ƒå›¾"""
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('æ€»æ¶¨å¹…åˆ†å¸ƒ', 'æœ€é«˜æ¶¨å¹…åˆ†å¸ƒ'),
            vertical_spacing=0.15
        )
        
        # æ€»æ¶¨å¹…åˆ†å¸ƒ
        fig.add_trace(
            go.Histogram(
                x=df['total_return'],
                nbinsx=50,
                name='æ€»æ¶¨å¹…',
                marker_color='#1f77b4',
                opacity=0.7
            ),
            row=1, col=1
        )
        
        # æœ€é«˜æ¶¨å¹…åˆ†å¸ƒ
        if 'max_return' in df.columns:
            fig.add_trace(
                go.Histogram(
                    x=df['max_return'],
                    nbinsx=50,
                    name='æœ€é«˜æ¶¨å¹…',
                    marker_color='#ff7f0e',
                    opacity=0.7
                ),
                row=2, col=1
            )
        
        fig.update_layout(
            height=800,
            title_text="æ ·æœ¬æ¶¨å¹…åˆ†å¸ƒåˆ†æ",
            showlegend=False
        )
        
        fig.update_xaxes(title_text="æ¶¨å¹… (%)", row=1, col=1)
        fig.update_xaxes(title_text="æ¶¨å¹… (%)", row=2, col=1)
        fig.update_yaxes(title_text="æ ·æœ¬æ•°", row=1, col=1)
        fig.update_yaxes(title_text="æ ·æœ¬æ•°", row=2, col=1)
        
        output_file = self.output_dir / f"{prefix}_return_distribution.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_time_distribution(self, df: pd.DataFrame, prefix: str):
        """ç»˜åˆ¶æ—¶é—´åˆ†å¸ƒå›¾"""
        df['t1_date'] = pd.to_datetime(df['t1_date'])
        df['year'] = df['t1_date'].dt.year
        df['month'] = df['t1_date'].dt.month
        
        # æŒ‰å¹´ä»½ç»Ÿè®¡
        year_counts = df['year'].value_counts().sort_index()
        
        fig = make_subplots(
            rows=2, cols=1,
            subplot_titles=('æŒ‰å¹´ä»½åˆ†å¸ƒ', 'æŒ‰æœˆä»½åˆ†å¸ƒï¼ˆæ‰€æœ‰å¹´ä»½ï¼‰'),
            vertical_spacing=0.15
        )
        
        # å¹´ä»½åˆ†å¸ƒ
        fig.add_trace(
            go.Bar(
                x=year_counts.index,
                y=year_counts.values,
                name='æ ·æœ¬æ•°',
                marker_color='#2ca02c',
                text=year_counts.values,
                textposition='outside'
            ),
            row=1, col=1
        )
        
        # æœˆä»½åˆ†å¸ƒ
        month_counts = df['month'].value_counts().sort_index()
        fig.add_trace(
            go.Bar(
                x=month_counts.index,
                y=month_counts.values,
                name='æ ·æœ¬æ•°',
                marker_color='#d62728',
                text=month_counts.values,
                textposition='outside'
            ),
            row=2, col=1
        )
        
        fig.update_layout(
            height=800,
            title_text="æ ·æœ¬æ—¶é—´åˆ†å¸ƒåˆ†æ",
            showlegend=False
        )
        
        fig.update_xaxes(title_text="å¹´ä»½", row=1, col=1)
        fig.update_xaxes(title_text="æœˆä»½", row=2, col=1)
        fig.update_yaxes(title_text="æ ·æœ¬æ•°", row=1, col=1)
        fig.update_yaxes(title_text="æ ·æœ¬æ•°", row=2, col=1)
        
        output_file = self.output_dir / f"{prefix}_time_distribution.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_return_boxplot(self, df: pd.DataFrame, prefix: str):
        """ç»˜åˆ¶æ¶¨å¹…ç®±çº¿å›¾"""
        fig = go.Figure()
        
        fig.add_trace(go.Box(
            y=df['total_return'],
            name='æ€»æ¶¨å¹…',
            marker_color='#1f77b4'
        ))
        
        if 'max_return' in df.columns:
            fig.add_trace(go.Box(
                y=df['max_return'],
                name='æœ€é«˜æ¶¨å¹…',
                marker_color='#ff7f0e'
            ))
        
        fig.update_layout(
            title="æ¶¨å¹…ç»Ÿè®¡ç®±çº¿å›¾",
            yaxis_title="æ¶¨å¹… (%)",
            height=500,
            boxmode='group'
        )
        
        output_file = self.output_dir / f"{prefix}_return_boxplot.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_anomaly_detection(self, df: pd.DataFrame, prefix: str):
        """ç»˜åˆ¶å¼‚å¸¸å€¼æ£€æµ‹å›¾"""
        # ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹å¼‚å¸¸å€¼
        Q1 = df['total_return'].quantile(0.25)
        Q3 = df['total_return'].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        df['is_outlier'] = (df['total_return'] < lower_bound) | (df['total_return'] > upper_bound)
        df['is_extreme'] = df['total_return'] > 200
        
        fig = go.Figure()
        
        # æ­£å¸¸å€¼
        normal = df[~df['is_outlier']]
        if len(normal) > 0:
            fig.add_trace(go.Scatter(
                x=normal.index,
                y=normal['total_return'],
                mode='markers',
                name='æ­£å¸¸å€¼',
                marker=dict(color='#2ca02c', size=5, opacity=0.6)
            ))
        
        # å¼‚å¸¸å€¼
        outliers = df[df['is_outlier'] & ~df['is_extreme']]
        if len(outliers) > 0:
            fig.add_trace(go.Scatter(
                x=outliers.index,
                y=outliers['total_return'],
                mode='markers',
                name='å¼‚å¸¸å€¼ (IQR)',
                marker=dict(color='#ff7f0e', size=8, opacity=0.8)
            ))
        
        # æç«¯å€¼
        extreme = df[df['is_extreme']]
        if len(extreme) > 0:
            fig.add_trace(go.Scatter(
                x=extreme.index,
                y=extreme['total_return'],
                mode='markers',
                name='æç«¯å€¼ (>200%)',
                marker=dict(color='#d62728', size=10, opacity=0.9)
            ))
        
        # æ·»åŠ é˜ˆå€¼çº¿
        fig.add_hline(y=50, line_dash="dash", line_color="blue", 
                     annotation_text="æœ€ä½é˜ˆå€¼ (50%)", annotation_position="right")
        fig.add_hline(y=upper_bound, line_dash="dash", line_color="orange",
                     annotation_text=f"å¼‚å¸¸å€¼ä¸Šç•Œ ({upper_bound:.1f}%)", annotation_position="right")
        
        fig.update_layout(
            title="å¼‚å¸¸å€¼æ£€æµ‹åˆ†æ",
            xaxis_title="æ ·æœ¬ç´¢å¼•",
            yaxis_title="æ¶¨å¹… (%)",
            height=600,
            hovermode='closest'
        )
        
        output_file = self.output_dir / f"{prefix}_anomaly_detection.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _generate_quality_report(self, df: pd.DataFrame, prefix: str):
        """ç”Ÿæˆæ ·æœ¬è´¨é‡ç»¼åˆæŠ¥å‘Š"""
        report = {
            'ç”Ÿæˆæ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'æ ·æœ¬æ€»æ•°': len(df),
            'è‚¡ç¥¨æ•°é‡': df['ts_code'].nunique() if 'ts_code' in df.columns else 0,
        }
        
        if 'total_return' in df.columns:
            report['æ€»æ¶¨å¹…ç»Ÿè®¡'] = {
                'å¹³å‡å€¼': f"{df['total_return'].mean():.2f}%",
                'ä¸­ä½æ•°': f"{df['total_return'].median():.2f}%",
                'æœ€å°å€¼': f"{df['total_return'].min():.2f}%",
                'æœ€å¤§å€¼': f"{df['total_return'].max():.2f}%",
                'æ ‡å‡†å·®': f"{df['total_return'].std():.2f}%"
            }
        
        if 'max_return' in df.columns:
            report['æœ€é«˜æ¶¨å¹…ç»Ÿè®¡'] = {
                'å¹³å‡å€¼': f"{df['max_return'].mean():.2f}%",
                'ä¸­ä½æ•°': f"{df['max_return'].median():.2f}%",
                'æœ€å°å€¼': f"{df['max_return'].min():.2f}%",
                'æœ€å¤§å€¼': f"{df['max_return'].max():.2f}%"
            }
        
        if 't1_date' in df.columns:
            df['t1_date'] = pd.to_datetime(df['t1_date'])
            report['æ—¶é—´èŒƒå›´'] = {
                'æœ€æ—©æ—¥æœŸ': df['t1_date'].min().strftime('%Y-%m-%d'),
                'æœ€æ™šæ—¥æœŸ': df['t1_date'].max().strftime('%Y-%m-%d')
            }
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        issues = []
        if df.isnull().sum().sum() > 0:
            issues.append(f"å­˜åœ¨ç©ºå€¼: {df.isnull().sum().sum()} ä¸ª")
        
        if 'total_return' in df.columns and 'max_return' in df.columns:
            invalid = len(df[df['total_return'] > df['max_return']])
            if invalid > 0:
                issues.append(f"é€»è¾‘é”™è¯¯: {invalid} ä¸ªæ ·æœ¬æ€»æ¶¨å¹… > æœ€é«˜æ¶¨å¹…")
        
        report['æ•°æ®è´¨é‡'] = {
            'é—®é¢˜æ•°é‡': len(issues),
            'é—®é¢˜åˆ—è¡¨': issues if issues else ['æ— é—®é¢˜']
        }
        
        # ä¿å­˜ä¸ºJSON
        import json
        report_file = self.output_dir / f"{prefix}_quality_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        log.info(f"âœ“ ç”Ÿæˆ: {report_file.name}")
    
    def visualize_feature_importance(
        self, 
        feature_importance: pd.DataFrame, 
        model_name: str = "model",
        top_n: int = 20
    ):
        """
        å¯è§†åŒ–å› å­é‡è¦æ€§
        
        Args:
            feature_importance: ç‰¹å¾é‡è¦æ€§DataFrameï¼ŒåŒ…å«'feature'å’Œ'importance'åˆ—
            model_name: æ¨¡å‹åç§°
            top_n: æ˜¾ç¤ºå‰Nä¸ªé‡è¦ç‰¹å¾
        """
        log.info("="*80)
        log.info("ç”Ÿæˆå› å­é‡è¦æ€§å¯è§†åŒ–å›¾è¡¨")
        log.info("="*80)
        
        if feature_importance is None or len(feature_importance) == 0:
            log.warning("ç‰¹å¾é‡è¦æ€§æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡å¯è§†åŒ–")
            return
        
        # æ’åºå¹¶å–Top N
        df_sorted = feature_importance.sort_values('importance', ascending=False).head(top_n)
        
        # 1. æ°´å¹³æ¡å½¢å›¾ï¼ˆTop Nï¼‰
        self._plot_importance_bar(df_sorted, model_name, top_n)
        
        # 2. ç‰¹å¾é‡è¦æ€§åˆ†å¸ƒ
        self._plot_importance_distribution(feature_importance, model_name)
        
        # 3. ç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾ï¼ˆæŒ‰ç±»åˆ«åˆ†ç»„ï¼‰
        self._plot_importance_heatmap(df_sorted, model_name)
        
        # 4. ç´¯ç§¯é‡è¦æ€§
        self._plot_cumulative_importance(feature_importance, model_name)
        
        log.success(f"âœ“ å› å­é‡è¦æ€§å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆåˆ°: {self.output_dir}")
    
    def _plot_importance_bar(self, df: pd.DataFrame, model_name: str, top_n: int):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾"""
        fig = go.Figure()
        
        # æŒ‰é‡è¦æ€§æ’åºï¼ˆä»å¤§åˆ°å°ï¼‰
        df_sorted = df.sort_values('importance', ascending=True)
        
        # ä½¿ç”¨æ¸å˜è‰²
        colors = px.colors.sequential.Viridis_r[:len(df_sorted)]
        
        fig.add_trace(go.Bar(
            x=df_sorted['importance'],
            y=df_sorted['feature'],
            orientation='h',
            marker=dict(
                color=colors,
                line=dict(color='rgba(0,0,0,0.3)', width=1)
            ),
            text=[f"{v:.4f}" for v in df_sorted['importance']],
            textposition='outside',
            hovertemplate='<b>%{y}</b><br>é‡è¦æ€§: %{x:.4f}<extra></extra>'
        ))
        
        fig.update_layout(
            title=f"ç‰¹å¾é‡è¦æ€§ Top {top_n}",
            xaxis_title="é‡è¦æ€§",
            yaxis_title="ç‰¹å¾",
            height=max(600, len(df_sorted) * 30),
            hovermode='closest',
            margin=dict(l=200, r=50, t=50, b=50)
        )
        
        output_file = self.output_dir / f"{model_name}_feature_importance_top{top_n}.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_importance_distribution(self, df: pd.DataFrame, model_name: str):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§åˆ†å¸ƒç›´æ–¹å›¾"""
        fig = go.Figure()
        
        fig.add_trace(go.Histogram(
            x=df['importance'],
            nbinsx=50,
            marker_color='#1f77b4',
            opacity=0.7,
            name='é‡è¦æ€§åˆ†å¸ƒ'
        ))
        
        # æ·»åŠ ç»Ÿè®¡çº¿
        mean_importance = df['importance'].mean()
        median_importance = df['importance'].median()
        
        fig.add_vline(
            x=mean_importance,
            line_dash="dash",
            line_color="red",
            annotation_text=f"å¹³å‡å€¼: {mean_importance:.4f}",
            annotation_position="top"
        )
        
        fig.add_vline(
            x=median_importance,
            line_dash="dash",
            line_color="orange",
            annotation_text=f"ä¸­ä½æ•°: {median_importance:.4f}",
            annotation_position="top"
        )
        
        fig.update_layout(
            title="ç‰¹å¾é‡è¦æ€§åˆ†å¸ƒ",
            xaxis_title="é‡è¦æ€§",
            yaxis_title="ç‰¹å¾æ•°é‡",
            height=500
        )
        
        output_file = self.output_dir / f"{model_name}_feature_importance_distribution.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_importance_heatmap(self, df: pd.DataFrame, model_name: str):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾ï¼ˆæŒ‰ç‰¹å¾ç±»åˆ«åˆ†ç»„ï¼‰"""
        # æ ¹æ®ç‰¹å¾åç§°æ¨æ–­ç±»åˆ«
        df['category'] = df['feature'].apply(self._categorize_feature)
        
        # æŒ‰ç±»åˆ«åˆ†ç»„ç»Ÿè®¡
        category_importance = df.groupby('category')['importance'].sum().sort_values(ascending=False)
        
        fig = go.Figure(data=go.Heatmap(
            z=[category_importance.values],
            x=category_importance.index,
            y=['é‡è¦æ€§æ€»å’Œ'],
            colorscale='Viridis',
            text=[[f"{v:.4f}" for v in category_importance.values]],
            texttemplate="%{text}",
            textfont={"size": 12},
            showscale=True
        ))
        
        fig.update_layout(
            title="ç‰¹å¾é‡è¦æ€§æŒ‰ç±»åˆ«æ±‡æ€»",
            xaxis_title="ç‰¹å¾ç±»åˆ«",
            yaxis_title="",
            height=300,
            margin=dict(l=100, r=50, t=50, b=100)
        )
        
        output_file = self.output_dir / f"{model_name}_feature_importance_heatmap.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_cumulative_importance(self, df: pd.DataFrame, model_name: str):
        """ç»˜åˆ¶ç´¯ç§¯é‡è¦æ€§å›¾"""
        df_sorted = df.sort_values('importance', ascending=False)
        df_sorted['cumulative'] = df_sorted['importance'].cumsum()
        df_sorted['cumulative_pct'] = df_sorted['cumulative'] / df_sorted['importance'].sum() * 100
        
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=list(range(1, len(df_sorted) + 1)),
            y=df_sorted['cumulative_pct'],
            mode='lines+markers',
            name='ç´¯ç§¯é‡è¦æ€§',
            line=dict(color='#1f77b4', width=3),
            marker=dict(size=5)
        ))
        
        # æ·»åŠ 80%å’Œ90%çº¿
        fig.add_hline(y=80, line_dash="dash", line_color="orange",
                     annotation_text="80%", annotation_position="right")
        fig.add_hline(y=90, line_dash="dash", line_color="red",
                     annotation_text="90%", annotation_position="right")
        
        # æ‰¾å‡ºè¾¾åˆ°80%å’Œ90%éœ€è¦çš„ç‰¹å¾æ•°
        n_80 = (df_sorted['cumulative_pct'] >= 80).idxmax() + 1 if (df_sorted['cumulative_pct'] >= 80).any() else len(df_sorted)
        n_90 = (df_sorted['cumulative_pct'] >= 90).idxmax() + 1 if (df_sorted['cumulative_pct'] >= 90).any() else len(df_sorted)
        
        fig.add_annotation(
            x=n_80, y=80,
            text=f"å‰{n_80}ä¸ªç‰¹å¾å 80%",
            showarrow=True,
            arrowhead=2,
            ax=0, ay=-40
        )
        
        fig.update_layout(
            title="ç‰¹å¾ç´¯ç§¯é‡è¦æ€§åˆ†æ",
            xaxis_title="ç‰¹å¾æ•°é‡ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰",
            yaxis_title="ç´¯ç§¯é‡è¦æ€§ (%)",
            height=600,
            hovermode='x unified'
        )
        
        output_file = self.output_dir / f"{model_name}_feature_cumulative_importance.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _categorize_feature(self, feature_name: str) -> str:
        """æ ¹æ®ç‰¹å¾åç§°æ¨æ–­ç±»åˆ«"""
        name_lower = feature_name.lower()
        
        if 'close' in name_lower or 'price' in name_lower:
            return 'ä»·æ ¼ç‰¹å¾'
        elif 'pct_chg' in name_lower or 'return' in name_lower or 'gain' in name_lower or 'loss' in name_lower:
            return 'æ¶¨è·Œå¹…ç‰¹å¾'
        elif 'volume' in name_lower:
            return 'æˆäº¤é‡ç‰¹å¾'
        elif 'macd' in name_lower:
            return 'MACDç‰¹å¾'
        elif 'ma' in name_lower:
            return 'å‡çº¿ç‰¹å¾'
        elif 'mv' in name_lower or 'å¸‚å€¼' in name_lower:
            return 'å¸‚å€¼ç‰¹å¾'
        elif 'momentum' in name_lower or 'trend' in name_lower:
            return 'åŠ¨é‡ç‰¹å¾'
        else:
            return 'å…¶ä»–ç‰¹å¾'
    
    def generate_index_page(self, model_name: str = "training"):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ç´¢å¼•é¡µé¢"""
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è®­ç»ƒå¯è§†åŒ–å›¾è¡¨ - {model_name}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        h1 {{
            color: #1f77b4;
            text-align: center;
            margin-bottom: 30px;
        }}
        .chart-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }}
        .chart-card {{
            background: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            transition: transform 0.2s;
        }}
        .chart-card:hover {{
            transform: translateY(-5px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }}
        .chart-card h3 {{
            color: #333;
            margin-top: 0;
        }}
        .chart-card p {{
            color: #666;
            margin: 10px 0;
        }}
        .chart-card a {{
            display: inline-block;
            background-color: #1f77b4;
            color: white;
            padding: 10px 20px;
            border-radius: 4px;
            text-decoration: none;
            margin-top: 10px;
        }}
        .chart-card a:hover {{
            background-color: #1557a0;
        }}
        .category {{
            margin-top: 40px;
        }}
        .category h2 {{
            color: #2ca02c;
            border-bottom: 2px solid #2ca02c;
            padding-bottom: 10px;
        }}
    </style>
</head>
<body>
    <h1>ğŸ“Š è®­ç»ƒå¯è§†åŒ–å›¾è¡¨ - {model_name}</h1>
    <p style="text-align: center; color: #666;">ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    
    <div class="category">
        <h2>ğŸ“ˆ æ ·æœ¬è´¨é‡åˆ†æ</h2>
        <div class="chart-grid">
            <div class="chart-card">
                <h3>æ¶¨å¹…åˆ†å¸ƒ</h3>
                <p>æ ·æœ¬æ¶¨å¹…çš„åˆ†å¸ƒæƒ…å†µï¼ŒåŒ…æ‹¬æ€»æ¶¨å¹…å’Œæœ€é«˜æ¶¨å¹…</p>
                <a href="sample_quality_return_distribution.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>æ—¶é—´åˆ†å¸ƒ</h3>
                <p>æ ·æœ¬åœ¨ä¸åŒå¹´ä»½å’Œæœˆä»½çš„åˆ†å¸ƒæƒ…å†µ</p>
                <a href="sample_quality_time_distribution.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>æ¶¨å¹…ç®±çº¿å›¾</h3>
                <p>æ¶¨å¹…çš„ç»Ÿè®¡åˆ†å¸ƒï¼ŒåŒ…æ‹¬ä¸­ä½æ•°ã€å››åˆ†ä½æ•°ç­‰</p>
                <a href="sample_quality_return_boxplot.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>å¼‚å¸¸å€¼æ£€æµ‹</h3>
                <p>ä½¿ç”¨IQRæ–¹æ³•æ£€æµ‹çš„å¼‚å¸¸å€¼å’Œæç«¯å€¼</p>
                <a href="sample_quality_anomaly_detection.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
        </div>
    </div>
    
    <div class="category">
        <h2>ğŸ” ç‰¹å¾è´¨é‡è¯„ä¼°</h2>
        <div class="chart-grid">
            <div class="chart-card">
                <h3>æ­£è´Ÿæ ·æœ¬ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”</h3>
                <p>Top 10ç‰¹å¾åœ¨æ­£è´Ÿæ ·æœ¬ä¸­çš„åˆ†å¸ƒå¯¹æ¯”</p>
                <a href="{model_name}_feature_distribution_comparison.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾</h3>
                <p>Top 20ç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§åˆ†æ</p>
                <a href="{model_name}_feature_correlation.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>ç‰¹å¾ç¼ºå¤±å€¼åˆ†æ</h3>
                <p>å„ç‰¹å¾çš„ç¼ºå¤±å€¼æƒ…å†µ</p>
                <a href="{model_name}_feature_missing_values.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯</h3>
                <p>Top 20ç‰¹å¾çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆå‡å€¼ã€æ ‡å‡†å·®ç­‰ï¼‰</p>
                <a href="{model_name}_feature_statistics.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
        </div>
    </div>
    
    <div class="category">
        <h2>ğŸ¯ å› å­é‡è¦æ€§åˆ†æ</h2>
        <div class="chart-grid">
            <div class="chart-card">
                <h3>Top 20 ç‰¹å¾é‡è¦æ€§</h3>
                <p>æœ€é‡è¦çš„20ä¸ªç‰¹å¾åŠå…¶é‡è¦æ€§å¾—åˆ†</p>
                <a href="{model_name}_feature_importance_top20.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>é‡è¦æ€§åˆ†å¸ƒ</h3>
                <p>æ‰€æœ‰ç‰¹å¾é‡è¦æ€§çš„åˆ†å¸ƒæƒ…å†µ</p>
                <a href="{model_name}_feature_importance_distribution.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>ç±»åˆ«æ±‡æ€»çƒ­åŠ›å›¾</h3>
                <p>æŒ‰ç‰¹å¾ç±»åˆ«æ±‡æ€»çš„é‡è¦æ€§</p>
                <a href="{model_name}_feature_importance_heatmap.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>ç´¯ç§¯é‡è¦æ€§</h3>
                <p>ç´¯ç§¯é‡è¦æ€§åˆ†æï¼Œæ˜¾ç¤ºéœ€è¦å¤šå°‘ç‰¹å¾è¾¾åˆ°80%/90%</p>
                <a href="{model_name}_feature_cumulative_importance.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
        </div>
    </div>
    
    <div class="category">
        <h2>ğŸ“ˆ æ¨¡å‹è®­ç»ƒè¿‡ç¨‹</h2>
        <div class="chart-grid">
            <div class="chart-card">
                <h3>è®­ç»ƒæ›²çº¿</h3>
                <p>æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å’ŒæŒ‡æ ‡å˜åŒ–</p>
                <a href="{model_name}_training_curves.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>å­¦ä¹ æ›²çº¿</h3>
                <p>ä¸åŒè®­ç»ƒé›†å¤§å°ä¸‹çš„æ¨¡å‹æ€§èƒ½</p>
                <a href="{model_name}_learning_curves.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
        </div>
    </div>
    
    <div class="category">
        <h2>ğŸ“Š æ¨¡å‹ç»“æœè¯„æµ‹</h2>
        <div class="chart-grid">
            <div class="chart-card">
                <h3>ROCæ›²çº¿</h3>
                <p>æ¥æ”¶è€…æ“ä½œç‰¹å¾æ›²çº¿ï¼Œè¯„ä¼°åˆ†ç±»æ€§èƒ½</p>
                <a href="{model_name}_roc_curve.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>PRæ›²çº¿</h3>
                <p>ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿</p>
                <a href="{model_name}_pr_curve.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>æ··æ·†çŸ©é˜µ</h3>
                <p>åˆ†ç±»ç»“æœçš„æ··æ·†çŸ©é˜µå¯è§†åŒ–</p>
                <a href="{model_name}_confusion_matrix.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ</h3>
                <p>æ­£è´Ÿæ ·æœ¬çš„é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒå¯¹æ¯”</p>
                <a href="{model_name}_prediction_distribution.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
            <div class="chart-card">
                <h3>é¢„æµ‹ç»“æœåˆ†æ</h3>
                <p>ä¸åŒé˜ˆå€¼ä¸‹çš„ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°</p>
                <a href="{model_name}_prediction_analysis.html" target="_blank">æŸ¥çœ‹å›¾è¡¨ â†’</a>
            </div>
        </div>
    </div>
    
    <footer style="text-align: center; margin-top: 50px; color: #666;">
        <p>AIQuant è®­ç»ƒå¯è§†åŒ– | ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    </footer>
</body>
</html>
        """
        
        index_file = self.output_dir / "index.html"
        with open(index_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        log.info(f"âœ“ ç”Ÿæˆç´¢å¼•é¡µé¢: {index_file}")
    
    def visualize_feature_quality(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        X_test: pd.DataFrame = None,
        y_test: pd.Series = None,
        model_name: str = "model"
    ):
        """
        å¯è§†åŒ–ç‰¹å¾è´¨é‡è¯„ä¼°
        
        Args:
            X_train: è®­ç»ƒé›†ç‰¹å¾
            y_train: è®­ç»ƒé›†æ ‡ç­¾
            X_test: æµ‹è¯•é›†ç‰¹å¾ï¼ˆå¯é€‰ï¼‰
            y_test: æµ‹è¯•é›†æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
            model_name: æ¨¡å‹åç§°
        """
        log.info("="*80)
        log.info("ç”Ÿæˆç‰¹å¾è´¨é‡å¯è§†åŒ–å›¾è¡¨")
        log.info("="*80)
        
        # 1. ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”ï¼ˆæ­£è´Ÿæ ·æœ¬ï¼‰
        self._plot_feature_distribution_comparison(X_train, y_train, model_name)
        
        # 2. ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾
        self._plot_feature_correlation(X_train, model_name)
        
        # 3. ç‰¹å¾ç¼ºå¤±å€¼åˆ†æ
        self._plot_missing_values(X_train, model_name)
        
        # 4. ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
        self._plot_feature_statistics(X_train, y_train, model_name)
        
        log.success(f"âœ“ ç‰¹å¾è´¨é‡å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆåˆ°: {self.output_dir}")
    
    def _plot_feature_distribution_comparison(self, X: pd.DataFrame, y: pd.Series, model_name: str):
        """ç»˜åˆ¶æ­£è´Ÿæ ·æœ¬ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”ï¼ˆTop 10ç‰¹å¾ï¼‰"""
        # é€‰æ‹©å‰10ä¸ªç‰¹å¾
        top_features = X.columns[:10].tolist()
        
        fig = make_subplots(
            rows=2, cols=5,
            subplot_titles=top_features,
            vertical_spacing=0.15,
            horizontal_spacing=0.1
        )
        
        for idx, feature in enumerate(top_features):
            row = (idx // 5) + 1
            col = (idx % 5) + 1
            
            # æ­£æ ·æœ¬åˆ†å¸ƒ
            pos_data = X[y == 1][feature].dropna()
            # è´Ÿæ ·æœ¬åˆ†å¸ƒ
            neg_data = X[y == 0][feature].dropna()
            
            if len(pos_data) > 0:
                fig.add_trace(
                    go.Histogram(
                        x=pos_data,
                        name='æ­£æ ·æœ¬',
                        marker_color='#2ca02c',
                        opacity=0.6,
                        nbinsx=30,
                        showlegend=(idx == 0)
                    ),
                    row=row, col=col
                )
            
            if len(neg_data) > 0:
                fig.add_trace(
                    go.Histogram(
                        x=neg_data,
                        name='è´Ÿæ ·æœ¬',
                        marker_color='#d62728',
                        opacity=0.6,
                        nbinsx=30,
                        showlegend=(idx == 0)
                    ),
                    row=row, col=col
                )
        
        fig.update_layout(
            height=800,
            title_text="æ­£è´Ÿæ ·æœ¬ç‰¹å¾åˆ†å¸ƒå¯¹æ¯”ï¼ˆTop 10ç‰¹å¾ï¼‰",
            showlegend=True
        )
        
        output_file = self.output_dir / f"{model_name}_feature_distribution_comparison.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_feature_correlation(self, X: pd.DataFrame, model_name: str):
        """ç»˜åˆ¶ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾"""
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µï¼ˆåªè®¡ç®—å‰20ä¸ªç‰¹å¾ï¼Œé¿å…å›¾è¡¨è¿‡å¤§ï¼‰
        top_features = X.columns[:20].tolist()
        corr_matrix = X[top_features].corr()
        
        fig = go.Figure(data=go.Heatmap(
            z=corr_matrix.values,
            x=corr_matrix.columns,
            y=corr_matrix.index,
            colorscale='RdBu',
            zmid=0,
            text=corr_matrix.values.round(2),
            texttemplate="%{text}",
            textfont={"size": 8},
            colorbar=dict(title="ç›¸å…³ç³»æ•°")
        ))
        
        fig.update_layout(
            title="ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾ï¼ˆTop 20ç‰¹å¾ï¼‰",
            height=800,
            width=1000,
            xaxis_title="ç‰¹å¾",
            yaxis_title="ç‰¹å¾"
        )
        
        output_file = self.output_dir / f"{model_name}_feature_correlation.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_missing_values(self, X: pd.DataFrame, model_name: str):
        """ç»˜åˆ¶ç‰¹å¾ç¼ºå¤±å€¼åˆ†æ"""
        missing_counts = X.isnull().sum()
        missing_pct = (missing_counts / len(X)) * 100
        
        # åªæ˜¾ç¤ºæœ‰ç¼ºå¤±å€¼çš„ç‰¹å¾
        missing_data = pd.DataFrame({
            'feature': missing_counts.index,
            'missing_count': missing_counts.values,
            'missing_pct': missing_pct.values
        })
        missing_data = missing_data[missing_data['missing_count'] > 0].sort_values('missing_count', ascending=False)
        
        if len(missing_data) == 0:
            log.info("âœ“ æ²¡æœ‰ç¼ºå¤±å€¼ï¼Œè·³è¿‡ç¼ºå¤±å€¼åˆ†æå›¾")
            return
        
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            x=missing_data['feature'],
            y=missing_data['missing_pct'],
            marker_color='#ff7f0e',
            text=[f"{v:.1f}%" for v in missing_data['missing_pct']],
            textposition='outside'
        ))
        
        fig.update_layout(
            title="ç‰¹å¾ç¼ºå¤±å€¼åˆ†æ",
            xaxis_title="ç‰¹å¾",
            yaxis_title="ç¼ºå¤±å€¼ç™¾åˆ†æ¯” (%)",
            height=600,
            xaxis_tickangle=-45
        )
        
        output_file = self.output_dir / f"{model_name}_feature_missing_values.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_feature_statistics(self, X: pd.DataFrame, y: pd.Series, model_name: str):
        """ç»˜åˆ¶ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯"""
        stats = []
        for col in X.columns[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ªç‰¹å¾
            stats.append({
                'feature': col,
                'mean': X[col].mean(),
                'std': X[col].std(),
                'min': X[col].min(),
                'max': X[col].max(),
                'median': X[col].median()
            })
        
        df_stats = pd.DataFrame(stats)
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('å‡å€¼', 'æ ‡å‡†å·®', 'æœ€å°å€¼', 'æœ€å¤§å€¼'),
            vertical_spacing=0.15
        )
        
        # å‡å€¼
        fig.add_trace(
            go.Bar(x=df_stats['feature'], y=df_stats['mean'], name='å‡å€¼', marker_color='#1f77b4'),
            row=1, col=1
        )
        
        # æ ‡å‡†å·®
        fig.add_trace(
            go.Bar(x=df_stats['feature'], y=df_stats['std'], name='æ ‡å‡†å·®', marker_color='#ff7f0e'),
            row=1, col=2
        )
        
        # æœ€å°å€¼
        fig.add_trace(
            go.Bar(x=df_stats['feature'], y=df_stats['min'], name='æœ€å°å€¼', marker_color='#2ca02c'),
            row=2, col=1
        )
        
        # æœ€å¤§å€¼
        fig.add_trace(
            go.Bar(x=df_stats['feature'], y=df_stats['max'], name='æœ€å¤§å€¼', marker_color='#d62728'),
            row=2, col=2
        )
        
        fig.update_layout(
            height=800,
            title_text="ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯ï¼ˆTop 20ç‰¹å¾ï¼‰",
            showlegend=False
        )
        
        fig.update_xaxes(tickangle=-45, row=1, col=1)
        fig.update_xaxes(tickangle=-45, row=1, col=2)
        fig.update_xaxes(tickangle=-45, row=2, col=1)
        fig.update_xaxes(tickangle=-45, row=2, col=2)
        
        output_file = self.output_dir / f"{model_name}_feature_statistics.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def visualize_training_process(
        self,
        model,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        X_test: pd.DataFrame,
        y_test: pd.Series,
        model_name: str = "model"
    ):
        """
        å¯è§†åŒ–æ¨¡å‹è®­ç»ƒè¿‡ç¨‹
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            X_train, y_train: è®­ç»ƒé›†
            X_test, y_test: æµ‹è¯•é›†
            model_name: æ¨¡å‹åç§°
        """
        log.info("="*80)
        log.info("ç”Ÿæˆæ¨¡å‹è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å›¾è¡¨")
        log.info("="*80)
        
        # 1. è®­ç»ƒæ›²çº¿ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
        if hasattr(model, 'evals_result_') and model.evals_result_:
            self._plot_training_curves(model, model_name)
        
        # 2. å­¦ä¹ æ›²çº¿ï¼ˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†æ€§èƒ½å¯¹æ¯”ï¼‰
        self._plot_learning_curves(model, X_train, y_train, X_test, y_test, model_name)
        
        log.success(f"âœ“ è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆåˆ°: {self.output_dir}")
    
    def _plot_training_curves(self, model, model_name: str):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        evals_result = model.evals_result_
        
        if not evals_result:
            return
        
        fig = go.Figure()
        
        # XGBoostçš„evals_result_ç»“æ„
        for eval_set_name, metrics_dict in evals_result.items():
            for metric_name, values in metrics_dict.items():
                fig.add_trace(go.Scatter(
                    x=list(range(len(values))),
                    y=values,
                    mode='lines+markers',
                    name=f"{eval_set_name} - {metric_name}",
                    line=dict(width=2)
                ))
        
        fig.update_layout(
            title="æ¨¡å‹è®­ç»ƒæ›²çº¿",
            xaxis_title="è¿­ä»£æ¬¡æ•°",
            yaxis_title="æŒ‡æ ‡å€¼",
            height=600,
            hovermode='x unified'
        )
        
        output_file = self.output_dir / f"{model_name}_training_curves.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_learning_curves(self, model, X_train, y_train, X_test, y_test, model_name: str):
        """ç»˜åˆ¶å­¦ä¹ æ›²çº¿ï¼ˆä¸åŒè®­ç»ƒé›†å¤§å°ä¸‹çš„æ€§èƒ½ï¼‰"""
        from sklearn.metrics import accuracy_score, roc_auc_score
        
        train_sizes = np.linspace(0.1, 1.0, 10)
        train_scores = []
        test_scores = []
        train_aucs = []
        test_aucs = []
        
        for size in train_sizes:
            n_samples = int(len(X_train) * size)
            X_train_subset = X_train.iloc[:n_samples]
            y_train_subset = y_train.iloc[:n_samples]
            
            # è®­ç»ƒæ¨¡å‹
            model_copy = type(model)(**model.get_params())
            model_copy.fit(X_train_subset, y_train_subset, verbose=False)
            
            # è¯„ä¼°
            train_pred = model_copy.predict(X_train_subset)
            train_prob = model_copy.predict_proba(X_train_subset)[:, 1]
            test_pred = model_copy.predict(X_test)
            test_prob = model_copy.predict_proba(X_test)[:, 1]
            
            train_scores.append(accuracy_score(y_train_subset, train_pred))
            test_scores.append(accuracy_score(y_test, test_pred))
            
            try:
                train_aucs.append(roc_auc_score(y_train_subset, train_prob))
                test_aucs.append(roc_auc_score(y_test, test_prob))
            except:
                train_aucs.append(0)
                test_aucs.append(0)
        
        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=('å‡†ç¡®ç‡å­¦ä¹ æ›²çº¿', 'AUCå­¦ä¹ æ›²çº¿')
        )
        
        # å‡†ç¡®ç‡
        fig.add_trace(
            go.Scatter(x=train_sizes, y=train_scores, name='è®­ç»ƒé›†å‡†ç¡®ç‡', 
                      mode='lines+markers', line=dict(color='#1f77b4', width=2)),
            row=1, col=1
        )
        fig.add_trace(
            go.Scatter(x=train_sizes, y=test_scores, name='æµ‹è¯•é›†å‡†ç¡®ç‡',
                      mode='lines+markers', line=dict(color='#ff7f0e', width=2)),
            row=1, col=1
        )
        
        # AUC
        fig.add_trace(
            go.Scatter(x=train_sizes, y=train_aucs, name='è®­ç»ƒé›†AUC',
                      mode='lines+markers', line=dict(color='#2ca02c', width=2)),
            row=1, col=2
        )
        fig.add_trace(
            go.Scatter(x=train_sizes, y=test_aucs, name='æµ‹è¯•é›†AUC',
                      mode='lines+markers', line=dict(color='#d62728', width=2)),
            row=1, col=2
        )
        
        fig.update_layout(
            height=500,
            title_text="æ¨¡å‹å­¦ä¹ æ›²çº¿",
            showlegend=True
        )
        
        fig.update_xaxes(title_text="è®­ç»ƒé›†æ¯”ä¾‹", row=1, col=1)
        fig.update_xaxes(title_text="è®­ç»ƒé›†æ¯”ä¾‹", row=1, col=2)
        fig.update_yaxes(title_text="å‡†ç¡®ç‡", row=1, col=1)
        fig.update_yaxes(title_text="AUC", row=1, col=2)
        
        output_file = self.output_dir / f"{model_name}_learning_curves.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def visualize_model_results(
        self,
        y_true: pd.Series,
        y_pred: np.ndarray,
        y_prob: np.ndarray,
        model_name: str = "model"
    ):
        """
        å¯è§†åŒ–æ¨¡å‹ç»“æœè¯„æµ‹
        
        Args:
            y_true: çœŸå®æ ‡ç­¾
            y_pred: é¢„æµ‹æ ‡ç­¾
            y_prob: é¢„æµ‹æ¦‚ç‡
            model_name: æ¨¡å‹åç§°
        """
        log.info("="*80)
        log.info("ç”Ÿæˆæ¨¡å‹ç»“æœè¯„æµ‹å¯è§†åŒ–å›¾è¡¨")
        log.info("="*80)
        
        # 1. ROCæ›²çº¿
        self._plot_roc_curve(y_true, y_prob, model_name)
        
        # 2. PRæ›²çº¿
        self._plot_pr_curve(y_true, y_prob, model_name)
        
        # 3. æ··æ·†çŸ©é˜µ
        self._plot_confusion_matrix(y_true, y_pred, model_name)
        
        # 4. é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
        self._plot_prediction_distribution(y_true, y_prob, model_name)
        
        # 5. é¢„æµ‹ç»“æœåˆ†æ
        self._plot_prediction_analysis(y_true, y_pred, y_prob, model_name)
        
        log.success(f"âœ“ æ¨¡å‹ç»“æœè¯„æµ‹å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆåˆ°: {self.output_dir}")
    
    def _plot_roc_curve(self, y_true, y_prob, model_name: str):
        """ç»˜åˆ¶ROCæ›²çº¿"""
        fpr, tpr, thresholds = roc_curve(y_true, y_prob)
        from sklearn.metrics import roc_auc_score
        auc = roc_auc_score(y_true, y_prob)
        
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=fpr,
            y=tpr,
            mode='lines',
            name=f'ROCæ›²çº¿ (AUC = {auc:.4f})',
            line=dict(color='#1f77b4', width=3)
        ))
        
        # å¯¹è§’çº¿ï¼ˆéšæœºåˆ†ç±»å™¨ï¼‰
        fig.add_trace(go.Scatter(
            x=[0, 1],
            y=[0, 1],
            mode='lines',
            name='éšæœºåˆ†ç±»å™¨',
            line=dict(color='red', width=2, dash='dash')
        ))
        
        fig.update_layout(
            title=f"ROCæ›²çº¿ (AUC = {auc:.4f})",
            xaxis_title="å‡æ­£ç‡ (FPR)",
            yaxis_title="çœŸæ­£ç‡ (TPR)",
            height=600,
            hovermode='x unified'
        )
        
        output_file = self.output_dir / f"{model_name}_roc_curve.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_pr_curve(self, y_true, y_prob, model_name: str):
        """ç»˜åˆ¶PRæ›²çº¿"""
        precision, recall, thresholds = precision_recall_curve(y_true, y_prob)
        from sklearn.metrics import average_precision_score
        ap = average_precision_score(y_true, y_prob)
        
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=recall,
            y=precision,
            mode='lines',
            name=f'PRæ›²çº¿ (AP = {ap:.4f})',
            line=dict(color='#2ca02c', width=3),
            fill='tozeroy'
        ))
        
        fig.update_layout(
            title=f"ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿ (AP = {ap:.4f})",
            xaxis_title="å¬å›ç‡ (Recall)",
            yaxis_title="ç²¾ç¡®ç‡ (Precision)",
            height=600,
            hovermode='x unified'
        )
        
        output_file = self.output_dir / f"{model_name}_pr_curve.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_confusion_matrix(self, y_true, y_pred, model_name: str):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        cm = confusion_matrix(y_true, y_pred)
        
        fig = go.Figure(data=go.Heatmap(
            z=cm,
            x=['é¢„æµ‹è´Ÿæ ·æœ¬', 'é¢„æµ‹æ­£æ ·æœ¬'],
            y=['å®é™…è´Ÿæ ·æœ¬', 'å®é™…æ­£æ ·æœ¬'],
            colorscale='Blues',
            text=cm,
            texttemplate="%{text}",
            textfont={"size": 16},
            colorbar=dict(title="æ ·æœ¬æ•°")
        ))
        
        fig.update_layout(
            title="æ··æ·†çŸ©é˜µ",
            height=400,
            width=600
        )
        
        output_file = self.output_dir / f"{model_name}_confusion_matrix.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_prediction_distribution(self, y_true, y_prob, model_name: str):
        """ç»˜åˆ¶é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ"""
        fig = make_subplots(
            rows=1, cols=2,
            subplot_titles=('æ­£æ ·æœ¬é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ', 'è´Ÿæ ·æœ¬é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ')
        )
        
        # æ­£æ ·æœ¬
        pos_probs = y_prob[y_true == 1]
        fig.add_trace(
            go.Histogram(
                x=pos_probs,
                nbinsx=50,
                name='æ­£æ ·æœ¬',
                marker_color='#2ca02c',
                opacity=0.7
            ),
            row=1, col=1
        )
        
        # è´Ÿæ ·æœ¬
        neg_probs = y_prob[y_true == 0]
        fig.add_trace(
            go.Histogram(
                x=neg_probs,
                nbinsx=50,
                name='è´Ÿæ ·æœ¬',
                marker_color='#d62728',
                opacity=0.7
            ),
            row=1, col=2
        )
        
        fig.update_layout(
            height=500,
            title_text="é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ",
            showlegend=False
        )
        
        fig.update_xaxes(title_text="é¢„æµ‹æ¦‚ç‡", row=1, col=1)
        fig.update_xaxes(title_text="é¢„æµ‹æ¦‚ç‡", row=1, col=2)
        fig.update_yaxes(title_text="æ ·æœ¬æ•°", row=1, col=1)
        fig.update_yaxes(title_text="æ ·æœ¬æ•°", row=1, col=2)
        
        output_file = self.output_dir / f"{model_name}_prediction_distribution.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")
    
    def _plot_prediction_analysis(self, y_true, y_pred, y_prob, model_name: str):
        """ç»˜åˆ¶é¢„æµ‹ç»“æœåˆ†æ"""
        # æŒ‰æ¦‚ç‡é˜ˆå€¼åˆ†æ
        thresholds = np.linspace(0, 1, 100)
        precisions = []
        recalls = []
        f1_scores = []
        
        for threshold in thresholds:
            y_pred_thresh = (y_prob >= threshold).astype(int)
            cm = confusion_matrix(y_true, y_pred_thresh)
            
            if cm.sum() > 0:
                tp = cm[1, 1] if cm.shape == (2, 2) else 0
                fp = cm[0, 1] if cm.shape == (2, 2) else 0
                fn = cm[1, 0] if cm.shape == (2, 2) else 0
                
                precision = tp / (tp + fp) if (tp + fp) > 0 else 0
                recall = tp / (tp + fn) if (tp + fn) > 0 else 0
                f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
                
                precisions.append(precision)
                recalls.append(recall)
                f1_scores.append(f1)
            else:
                precisions.append(0)
                recalls.append(0)
                f1_scores.append(0)
        
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=thresholds,
            y=precisions,
            mode='lines',
            name='ç²¾ç¡®ç‡',
            line=dict(color='#1f77b4', width=2)
        ))
        
        fig.add_trace(go.Scatter(
            x=thresholds,
            y=recalls,
            mode='lines',
            name='å¬å›ç‡',
            line=dict(color='#ff7f0e', width=2)
        ))
        
        fig.add_trace(go.Scatter(
            x=thresholds,
            y=f1_scores,
            mode='lines',
            name='F1åˆ†æ•°',
            line=dict(color='#2ca02c', width=2)
        ))
        
        fig.update_layout(
            title="ä¸åŒé˜ˆå€¼ä¸‹çš„æ€§èƒ½æŒ‡æ ‡",
            xaxis_title="æ¦‚ç‡é˜ˆå€¼",
            yaxis_title="æŒ‡æ ‡å€¼",
            height=600,
            hovermode='x unified'
        )
        
        output_file = self.output_dir / f"{model_name}_prediction_analysis.html"
        fig.write_html(str(output_file))
        log.info(f"âœ“ ç”Ÿæˆ: {output_file.name}")

